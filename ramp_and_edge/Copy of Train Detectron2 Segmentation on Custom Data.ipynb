{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZBUwM3tyFWS"
   },
   "source": [
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  2 09:05:24 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.85                 Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P8             16W /   40W |    1110MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4940      C   ...Daanish Mittal\\anaconda3\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MJ8SshpLaU3"
   },
   "source": [
    "## Install Detectron2 and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:27.100950Z",
     "start_time": "2024-06-25T07:59:43.324225Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51415,
     "status": "ok",
     "timestamp": 1719261763571,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "fM1JmUCQLdKp",
    "outputId": "cb684e1a-65eb-4798-eb32-28ef5b785883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to c:\\users\\daanish mittal\\appdata\\local\\temp\\pip-req-build-44wg59de\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Daanish Mittal\\AppData\\Local\\Temp\\pip-req-build-44wg59de\\setup.py\", line 10, in <module>\n",
      "        import torch\n",
      "    ModuleNotFoundError: No module named 'torch'\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Daanish Mittal\\AppData\\Local\\Temp\\pip-req-build-44wg59de\\\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V8w1ew59buh"
   },
   "source": [
    "Now is a good time to confirm that we have the right versions of the libraries at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4612,
     "status": "error",
     "timestamp": 1719261915922,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "sqCNglJXRro5",
    "outputId": "3f148ff1-b579-4dfa-c1f0-adb5bdda4c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: iopath<0.1.10,>=0.1.7 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: portalocker in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama; platform_system == \"Windows\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->iopath<0.1.10,>=0.1.7) (0.4.5)\n",
      "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.7\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->iopath<0.1.10,>=0.1.7) (5.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pywin32>=226; platform_system == \"Windows\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from portalocker->iopath<0.1.10,>=0.1.7) (305)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-resources; python_version < \"3.7\"->tqdm->iopath<0.1.10,>=0.1.7) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.105\n",
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"iopath<0.1.10,>=0.1.7\"\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "import pkg_resources\n",
    "print(\"detectron2:\", pkg_resources.get_distribution(\"detectron2\").version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:40.273497Z",
     "start_time": "2024-06-25T08:00:37.778861Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "error",
     "timestamp": 1719261789459,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "DIEKfPKFmW54",
    "outputId": "1eae8bc5-084a-4dd2-bcdd-00efdcfc6330"
   },
   "outputs": [],
   "source": [
    "# COMMON LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# TRAINING\n",
    "from detectron2.engine import DefaultTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOszeLVlErvk"
   },
   "source": [
    "## Run a Pre-trained Detectron2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:01:49.176003Z",
     "start_time": "2024-06-25T08:00:40.278498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 2681,
     "status": "ok",
     "timestamp": 1668002463033,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "T8sfLDV7FTYD",
    "outputId": "0e8eea7a-6407-4cb5-a7b8-6f4997bacde0"
   },
   "outputs": [],
   "source": [
    "# !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "# image = cv2.imread(\"./input.jpg\")\n",
    "# cv2.imshow('Display Window', image)  # 'Display Window' is the name of the window\n",
    "# cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "# cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:05.116019Z",
     "start_time": "2024-06-25T08:01:49.193280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Collecting torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement torch (from versions: )\n",
      "No matching distribution found for torch\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFkJOTWvxu6G"
   },
   "source": [
    "## COCO Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached https://files.pythonhosted.org/packages/99/f2/8349482b1cb7d408cd8673efaa1b51e7bd657f95b679de27f89e333f1388/roboflow-1.1.6-py3-none-any.whl\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl\n",
      "Collecting requests (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/61/08076519c80041bc0ffa1a8af0cbd3bf3e2b62af10435d269a9d0f40564d/requests-2.27.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Collecting urllib3>=1.26.6 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/6a/99eaaeae8becaa17a29aeb334a18e5d582d873b6f084c11f02581b8d7f7f/urllib3-1.26.19-py2.py3-none-any.whl\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (1.3.1)\n",
      "Collecting idna==2.10 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (4.64.1)\n",
      "Collecting supervision (from roboflow)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement supervision (from roboflow) (from versions: )\n",
      "No matching distribution found for supervision (from roboflow)\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:42.536499Z",
     "start_time": "2024-06-25T08:02:25.897211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14044,
     "status": "ok",
     "timestamp": 1668003461405,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "grFIdy8ynP-7",
    "outputId": "d05be873-4ac3-4d10-d88b-fa053a263c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in tank-and-ramp-1-1 to coco-segmentation:: 100%|██████████| 15955/15955 [00:04<00:00, 3511.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to tank-and-ramp-1-1 in coco-segmentation:: 100%|██████████| 354/354 [00:00<00:00, 1351.88it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"RovqaIFPpcekpUVWjRke\")\n",
    "project = rf.workspace(\"tank-5yib6\").project(\"tank-and-ramp-1\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco-segmentation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoB31yi4AoYs"
   },
   "source": [
    "### Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HopUGOyW853G"
   },
   "source": [
    "When you use Detectron2, before you actually train the model you need to [register it](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-coco-format-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:35.787965Z",
     "start_time": "2024-06-25T08:05:35.780944Z"
    },
    "id": "KbI2PNEZF3sU"
   },
   "outputs": [],
   "source": [
    "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
    "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:38.778124Z",
     "start_time": "2024-06-25T08:05:38.650598Z"
    },
    "id": "jntOI8GJG2ks"
   },
   "outputs": [],
   "source": [
    "# TRAIN SET\n",
    "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
    "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
    "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TRAIN_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# TEST SET\n",
    "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
    "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
    "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TEST_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# VALID SET\n",
    "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
    "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
    "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=VALID_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=VALID_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCY1UWNCtnq"
   },
   "source": [
    "We can now confirm that our custom dataset was correctly registered using [MetadataCatalog](https://detectron2.readthedocs.io/en/latest/modules/data.html#detectron2.data.MetadataCatalog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:42.883439Z",
     "start_time": "2024-06-25T08:05:42.865442Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1668003586610,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "LR8ha4EHCkA-",
    "outputId": "6506603a-3742-43ee-af5d-7f842426d25d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tank-and-ramp-1-train', 'tank-and-ramp-1-test', 'tank-and-ramp-1-valid']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    data_set\n",
    "    for data_set\n",
    "    in MetadataCatalog.list()\n",
    "    if data_set.startswith(DATA_SET_NAME)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpU2L3UL922"
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Bd_-oCA90a"
   },
   "source": [
    "Let's take a look at single entry from out train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:47.307052Z",
     "start_time": "2024-06-25T08:05:45.996186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1668003725711,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "eE0anblvMGJx",
    "outputId": "b5db94b3-faf0-4c64-9717-fa906c4b76db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "\n",
    "dataset_entry = dataset_train[0]\n",
    "image = cv2.imread(dataset_entry[\"file_name\"])\n",
    "\n",
    "visualizer = Visualizer(\n",
    "    image[:, :, ::-1],\n",
    "    metadata=metadata,\n",
    "    scale=0.5,\n",
    "    instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "\n",
    "out = visualizer.draw_dataset_dict(dataset_entry)\n",
    "cv2.imshow(\"visualize\",out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GavGRHy2M7Hb"
   },
   "source": [
    "## Train Model Using Custom COCO Format Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ3g-l56NMOY"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.228994Z",
     "start_time": "2024-06-25T08:03:04.203266Z"
    },
    "id": "krCm2L_lNC83"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "MAX_ITER = 2000\n",
    "EVAL_PERIOD = 200\n",
    "BASE_LR = 0.001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# OUTPUT DIRa\n",
    "OUTPUT_DIR_PATH = os.path.join(\n",
    "    DATA_SET_NAME,\n",
    "    ARCHITECTURE,\n",
    "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.291051Z",
     "start_time": "2024-06-25T08:03:04.233685Z"
    },
    "id": "lxQU8JrgOD73"
   },
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "# cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "# cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "# cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "# cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "# cfg.SOLVER.BASE_LR = BASE_LR\n",
    "# cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "# cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 # Default batch size per image\n",
    "\n",
    "# Adjusting batch size and image size for GPU with 6GB VRAM\n",
    "cfg.SOLVER.IMS_PER_BATCH = 3  # Overall batch size\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)  # Adjusted to fit memory constraints\n",
    "cfg.INPUT.MIN_SIZE_TEST = 800\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1333\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n",
    "\n",
    "# Save config for future reference\n",
    "with open(os.path.join(OUTPUT_DIR_PATH, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch-_5aCuXWj9"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:15.015389Z",
     "start_time": "2024-06-25T08:03:04.296073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961595,
     "status": "ok",
     "timestamp": 1668005381143,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "7S8y2W2AQvJq",
    "outputId": "36fe2d26-1118-4748-fff1-18a86d873970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/02 09:05:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:05:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:05:46 d2.data.datasets.coco]: \u001b[0mLoaded 303 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\train\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:05:46 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 303 images left.\n",
      "\u001b[32m[07/02 09:05:46 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| tank-and-ra.. | 0            |    ramp    | 264          |    tank    | 207          |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 471          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[07/02 09:05:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/02 09:05:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/02 09:05:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:05:46 d2.data.common]: \u001b[0mSerializing 303 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:05:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n",
      "\u001b[32m[07/02 09:05:46 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=3\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:05:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[07/02 09:05:46 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/02 09:05:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[07/02 09:06:12 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 19  total_loss: 2.168  loss_cls: 1.283  loss_box_reg: 0.1989  loss_mask: 0.6855  loss_rpn_cls: 0.002302  loss_rpn_loc: 0.006246    time: 0.9589  last_time: 0.8227  data_time: 0.3073  last_data_time: 0.0049   lr: 1.9981e-05  max_mem: 4567M\n",
      "\u001b[32m[07/02 09:06:41 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 39  total_loss: 1.595  loss_cls: 0.679  loss_box_reg: 0.2476  loss_mask: 0.6495  loss_rpn_cls: 0.006761  loss_rpn_loc: 0.007813    time: 0.9890  last_time: 1.1177  data_time: 0.0030  last_data_time: 0.0037   lr: 3.9961e-05  max_mem: 4567M\n",
      "\u001b[32m[07/02 09:07:01 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 59  total_loss: 1.045  loss_cls: 0.2537  loss_box_reg: 0.1728  loss_mask: 0.5878  loss_rpn_cls: 0.002625  loss_rpn_loc: 0.006455    time: 0.9964  last_time: 1.0807  data_time: 0.0031  last_data_time: 0.0030   lr: 5.9941e-05  max_mem: 4580M\n",
      "\u001b[32m[07/02 09:07:21 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 79  total_loss: 0.973  loss_cls: 0.2104  loss_box_reg: 0.2416  loss_mask: 0.5292  loss_rpn_cls: 0.001855  loss_rpn_loc: 0.007194    time: 0.9943  last_time: 1.1008  data_time: 0.0029  last_data_time: 0.0029   lr: 7.9921e-05  max_mem: 4580M\n",
      "\u001b[32m[07/02 09:07:41 d2.utils.events]: \u001b[0m eta: 0:31:05  iter: 99  total_loss: 0.8033  loss_cls: 0.1629  loss_box_reg: 0.1947  loss_mask: 0.4555  loss_rpn_cls: 0.0008006  loss_rpn_loc: 0.005098    time: 0.9964  last_time: 0.9653  data_time: 0.0029  last_data_time: 0.0026   lr: 9.9901e-05  max_mem: 4580M\n",
      "\u001b[32m[07/02 09:08:02 d2.utils.events]: \u001b[0m eta: 0:31:10  iter: 119  total_loss: 0.786  loss_cls: 0.1676  loss_box_reg: 0.2308  loss_mask: 0.3675  loss_rpn_cls: 0.0007392  loss_rpn_loc: 0.005089    time: 1.0015  last_time: 1.0959  data_time: 0.0029  last_data_time: 0.0035   lr: 0.00011988  max_mem: 4597M\n",
      "\u001b[32m[07/02 09:08:22 d2.utils.events]: \u001b[0m eta: 0:31:05  iter: 139  total_loss: 0.6944  loss_cls: 0.1494  loss_box_reg: 0.2353  loss_mask: 0.3162  loss_rpn_cls: 0.0009866  loss_rpn_loc: 0.004246    time: 1.0058  last_time: 1.0642  data_time: 0.0028  last_data_time: 0.0035   lr: 0.00013986  max_mem: 4597M\n",
      "\u001b[32m[07/02 09:08:42 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 159  total_loss: 0.5196  loss_cls: 0.1099  loss_box_reg: 0.1864  loss_mask: 0.2218  loss_rpn_cls: 0.0004342  loss_rpn_loc: 0.004039    time: 1.0024  last_time: 0.9528  data_time: 0.0029  last_data_time: 0.0025   lr: 0.00015984  max_mem: 4597M\n",
      "\u001b[32m[07/02 09:09:03 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 179  total_loss: 0.5886  loss_cls: 0.1216  loss_box_reg: 0.2378  loss_mask: 0.1958  loss_rpn_cls: 9.803e-05  loss_rpn_loc: 0.00491    time: 1.0072  last_time: 0.9298  data_time: 0.0030  last_data_time: 0.0028   lr: 0.00017982  max_mem: 4664M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:09:23 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:09:23 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:09:23 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| tank-and-ra.. | 0            |    ramp    | 11           |    tank    | 10           |\n",
      "|               |              |            |              |            |              |\n",
      "|     total     | 21           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[07/02 09:09:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:09:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:09:23 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:09:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:09:23 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:09:23 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 199  total_loss: 0.4933  loss_cls: 0.09999  loss_box_reg: 0.2479  loss_mask: 0.1441  loss_rpn_cls: 0.0006814  loss_rpn_loc: 0.005395    time: 1.0067  last_time: 1.0000  data_time: 0.0028  last_data_time: 0.0030   lr: 0.0001998  max_mem: 4679M\n",
      "\u001b[32m[07/02 09:09:43 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 219  total_loss: 0.4456  loss_cls: 0.0928  loss_box_reg: 0.2295  loss_mask: 0.1448  loss_rpn_cls: 0.000233  loss_rpn_loc: 0.004798    time: 1.0093  last_time: 1.0556  data_time: 0.0029  last_data_time: 0.0026   lr: 0.00021978  max_mem: 4679M\n",
      "\u001b[32m[07/02 09:10:03 d2.utils.events]: \u001b[0m eta: 0:29:26  iter: 239  total_loss: 0.4081  loss_cls: 0.07539  loss_box_reg: 0.21  loss_mask: 0.1051  loss_rpn_cls: 8.97e-05  loss_rpn_loc: 0.005501    time: 1.0057  last_time: 1.0425  data_time: 0.0029  last_data_time: 0.0026   lr: 0.00023976  max_mem: 4679M\n",
      "\u001b[32m[07/02 09:10:22 d2.utils.events]: \u001b[0m eta: 0:29:06  iter: 259  total_loss: 0.3315  loss_cls: 0.05832  loss_box_reg: 0.1482  loss_mask: 0.1018  loss_rpn_cls: 7.605e-05  loss_rpn_loc: 0.006474    time: 1.0037  last_time: 1.0763  data_time: 0.0030  last_data_time: 0.0028   lr: 0.00025974  max_mem: 4749M\n",
      "\u001b[32m[07/02 09:10:42 d2.utils.events]: \u001b[0m eta: 0:28:46  iter: 279  total_loss: 0.2829  loss_cls: 0.04922  loss_box_reg: 0.1093  loss_mask: 0.1036  loss_rpn_cls: 0.0001855  loss_rpn_loc: 0.005828    time: 1.0011  last_time: 0.8426  data_time: 0.0032  last_data_time: 0.0023   lr: 0.00027972  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:11:01 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 299  total_loss: 0.2134  loss_cls: 0.04404  loss_box_reg: 0.08495  loss_mask: 0.07856  loss_rpn_cls: 3.611e-05  loss_rpn_loc: 0.004958    time: 0.9993  last_time: 1.0515  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002997  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:11:21 d2.utils.events]: \u001b[0m eta: 0:28:00  iter: 319  total_loss: 0.2231  loss_cls: 0.03933  loss_box_reg: 0.08627  loss_mask: 0.08793  loss_rpn_cls: 1.536e-05  loss_rpn_loc: 0.003949    time: 0.9979  last_time: 0.9934  data_time: 0.0031  last_data_time: 0.0038   lr: 0.00031968  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:11:40 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 339  total_loss: 0.1597  loss_cls: 0.03138  loss_box_reg: 0.05565  loss_mask: 0.06849  loss_rpn_cls: 4.551e-05  loss_rpn_loc: 0.002989    time: 0.9954  last_time: 0.8385  data_time: 0.0033  last_data_time: 0.0032   lr: 0.00033966  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:12:00 d2.utils.events]: \u001b[0m eta: 0:27:17  iter: 359  total_loss: 0.1665  loss_cls: 0.03438  loss_box_reg: 0.06282  loss_mask: 0.06825  loss_rpn_cls: 4.603e-06  loss_rpn_loc: 0.00433    time: 0.9953  last_time: 1.0185  data_time: 0.0037  last_data_time: 0.0040   lr: 0.00035964  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:12:20 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 379  total_loss: 0.1458  loss_cls: 0.02656  loss_box_reg: 0.04873  loss_mask: 0.06076  loss_rpn_cls: 3.018e-05  loss_rpn_loc: 0.004447    time: 0.9949  last_time: 0.9339  data_time: 0.0037  last_data_time: 0.0033   lr: 0.00037962  max_mem: 4761M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:12:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:12:39 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:12:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:12:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:12:39 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:12:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:12:39 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:12:39 d2.utils.events]: \u001b[0m eta: 0:26:37  iter: 399  total_loss: 0.1383  loss_cls: 0.02866  loss_box_reg: 0.05051  loss_mask: 0.05214  loss_rpn_cls: 1.61e-05  loss_rpn_loc: 0.003378    time: 0.9947  last_time: 1.0161  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0003996  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:12:59 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 419  total_loss: 0.1405  loss_cls: 0.03005  loss_box_reg: 0.05114  loss_mask: 0.05441  loss_rpn_cls: 1.89e-05  loss_rpn_loc: 0.00393    time: 0.9944  last_time: 0.9553  data_time: 0.0032  last_data_time: 0.0049   lr: 0.00041958  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:13:19 d2.utils.events]: \u001b[0m eta: 0:25:54  iter: 439  total_loss: 0.126  loss_cls: 0.02717  loss_box_reg: 0.04841  loss_mask: 0.05021  loss_rpn_cls: 7.847e-06  loss_rpn_loc: 0.004382    time: 0.9933  last_time: 0.9003  data_time: 0.0029  last_data_time: 0.0019   lr: 0.00043956  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:13:38 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 459  total_loss: 0.1174  loss_cls: 0.02078  loss_box_reg: 0.04247  loss_mask: 0.04852  loss_rpn_cls: 2.723e-06  loss_rpn_loc: 0.003334    time: 0.9920  last_time: 0.9654  data_time: 0.0030  last_data_time: 0.0033   lr: 0.00045954  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:13:57 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 479  total_loss: 0.1241  loss_cls: 0.02337  loss_box_reg: 0.04864  loss_mask: 0.04852  loss_rpn_cls: 9.806e-06  loss_rpn_loc: 0.003863    time: 0.9908  last_time: 0.9158  data_time: 0.0033  last_data_time: 0.0035   lr: 0.00047952  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:14:16 d2.utils.events]: \u001b[0m eta: 0:24:46  iter: 499  total_loss: 0.1073  loss_cls: 0.02067  loss_box_reg: 0.0432  loss_mask: 0.04161  loss_rpn_cls: 5.232e-06  loss_rpn_loc: 0.003828    time: 0.9890  last_time: 0.8961  data_time: 0.0029  last_data_time: 0.0027   lr: 0.0004995  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:14:36 d2.utils.events]: \u001b[0m eta: 0:24:27  iter: 519  total_loss: 0.1062  loss_cls: 0.02062  loss_box_reg: 0.03929  loss_mask: 0.04291  loss_rpn_cls: 2.801e-06  loss_rpn_loc: 0.003456    time: 0.9889  last_time: 0.8256  data_time: 0.0047  last_data_time: 0.0036   lr: 0.00051948  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:14:55 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 539  total_loss: 0.1028  loss_cls: 0.02063  loss_box_reg: 0.03842  loss_mask: 0.04134  loss_rpn_cls: 3.313e-06  loss_rpn_loc: 0.00337    time: 0.9878  last_time: 0.8106  data_time: 0.0030  last_data_time: 0.0046   lr: 0.00053946  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:15:15 d2.utils.events]: \u001b[0m eta: 0:23:46  iter: 559  total_loss: 0.08823  loss_cls: 0.015  loss_box_reg: 0.02973  loss_mask: 0.04051  loss_rpn_cls: 3.753e-06  loss_rpn_loc: 0.003172    time: 0.9884  last_time: 0.9451  data_time: 0.0033  last_data_time: 0.0041   lr: 0.00055944  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:15:30 d2.utils.events]: \u001b[0m eta: 0:23:24  iter: 579  total_loss: 0.09951  loss_cls: 0.01907  loss_box_reg: 0.03719  loss_mask: 0.0372  loss_rpn_cls: 7.431e-06  loss_rpn_loc: 0.00306    time: 0.9808  last_time: 0.4973  data_time: 0.0027  last_data_time: 0.0023   lr: 0.00057942  max_mem: 4761M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:15:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:15:41 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:15:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:15:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:15:41 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:15:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:15:41 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:15:41 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 599  total_loss: 0.1058  loss_cls: 0.01898  loss_box_reg: 0.03982  loss_mask: 0.04162  loss_rpn_cls: 2.441e-06  loss_rpn_loc: 0.002899    time: 0.9648  last_time: 0.5587  data_time: 0.0024  last_data_time: 0.0030   lr: 0.0005994  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:15:51 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 619  total_loss: 0.09965  loss_cls: 0.01834  loss_box_reg: 0.03666  loss_mask: 0.03838  loss_rpn_cls: 1.765e-05  loss_rpn_loc: 0.00333    time: 0.9499  last_time: 0.5147  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00061938  max_mem: 4761M\n",
      "\u001b[32m[07/02 09:16:01 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 639  total_loss: 0.09883  loss_cls: 0.01798  loss_box_reg: 0.0366  loss_mask: 0.03571  loss_rpn_cls: 5.804e-06  loss_rpn_loc: 0.003019    time: 0.9361  last_time: 0.5144  data_time: 0.0024  last_data_time: 0.0021   lr: 0.00063936  max_mem: 4775M\n",
      "\u001b[32m[07/02 09:16:12 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 659  total_loss: 0.08779  loss_cls: 0.01541  loss_box_reg: 0.03405  loss_mask: 0.03485  loss_rpn_cls: 6.536e-06  loss_rpn_loc: 0.003292    time: 0.9241  last_time: 0.6341  data_time: 0.0030  last_data_time: 0.0071   lr: 0.00065934  max_mem: 4775M\n",
      "\u001b[32m[07/02 09:16:22 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 679  total_loss: 0.08952  loss_cls: 0.01832  loss_box_reg: 0.034  loss_mask: 0.03702  loss_rpn_cls: 4.352e-06  loss_rpn_loc: 0.002808    time: 0.9128  last_time: 0.5740  data_time: 0.0033  last_data_time: 0.0039   lr: 0.00067932  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:16:33 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 699  total_loss: 0.09294  loss_cls: 0.01594  loss_box_reg: 0.03749  loss_mask: 0.03555  loss_rpn_cls: 4.596e-06  loss_rpn_loc: 0.002845    time: 0.9017  last_time: 0.5253  data_time: 0.0031  last_data_time: 0.0026   lr: 0.0006993  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:16:43 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 719  total_loss: 0.08736  loss_cls: 0.0157  loss_box_reg: 0.03153  loss_mask: 0.03397  loss_rpn_cls: 8.291e-06  loss_rpn_loc: 0.002638    time: 0.8905  last_time: 0.4782  data_time: 0.0027  last_data_time: 0.0033   lr: 0.00071928  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:16:53 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 739  total_loss: 0.09348  loss_cls: 0.01808  loss_box_reg: 0.03496  loss_mask: 0.03698  loss_rpn_cls: 1.652e-06  loss_rpn_loc: 0.002317    time: 0.8802  last_time: 0.4357  data_time: 0.0030  last_data_time: 0.0025   lr: 0.00073926  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:17:03 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 759  total_loss: 0.08588  loss_cls: 0.01391  loss_box_reg: 0.0296  loss_mask: 0.03357  loss_rpn_cls: 4.076e-06  loss_rpn_loc: 0.002654    time: 0.8699  last_time: 0.5143  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00075924  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:17:13 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 779  total_loss: 0.07911  loss_cls: 0.01468  loss_box_reg: 0.0302  loss_mask: 0.03174  loss_rpn_cls: 3.242e-06  loss_rpn_loc: 0.002851    time: 0.8600  last_time: 0.5315  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00077922  max_mem: 4781M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:17:23 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:17:23 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:17:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:17:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:17:23 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:17:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:17:23 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:17:23 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 799  total_loss: 0.07684  loss_cls: 0.01488  loss_box_reg: 0.02617  loss_mask: 0.03343  loss_rpn_cls: 7.885e-06  loss_rpn_loc: 0.002802    time: 0.8507  last_time: 0.4836  data_time: 0.0025  last_data_time: 0.0021   lr: 0.0007992  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:17:32 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 819  total_loss: 0.082  loss_cls: 0.01403  loss_box_reg: 0.02989  loss_mask: 0.0359  loss_rpn_cls: 1.75e-06  loss_rpn_loc: 0.00254    time: 0.8421  last_time: 0.5068  data_time: 0.0023  last_data_time: 0.0019   lr: 0.00081918  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:17:42 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 839  total_loss: 0.07795  loss_cls: 0.01302  loss_box_reg: 0.02933  loss_mask: 0.0347  loss_rpn_cls: 9.599e-07  loss_rpn_loc: 0.002734    time: 0.8338  last_time: 0.4774  data_time: 0.0025  last_data_time: 0.0038   lr: 0.00083916  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:17:53 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 859  total_loss: 0.08094  loss_cls: 0.01632  loss_box_reg: 0.03187  loss_mask: 0.03152  loss_rpn_cls: 3.428e-06  loss_rpn_loc: 0.002829    time: 0.8264  last_time: 0.5573  data_time: 0.0027  last_data_time: 0.0031   lr: 0.00085914  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:18:03 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 879  total_loss: 0.07401  loss_cls: 0.01458  loss_box_reg: 0.029  loss_mask: 0.02993  loss_rpn_cls: 2.134e-06  loss_rpn_loc: 0.003184    time: 0.8195  last_time: 0.5122  data_time: 0.0028  last_data_time: 0.0034   lr: 0.00087912  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:18:13 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 899  total_loss: 0.08769  loss_cls: 0.01553  loss_box_reg: 0.03453  loss_mask: 0.03099  loss_rpn_cls: 4.423e-06  loss_rpn_loc: 0.003024    time: 0.8126  last_time: 0.5153  data_time: 0.0024  last_data_time: 0.0022   lr: 0.0008991  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:18:23 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 919  total_loss: 0.07869  loss_cls: 0.01427  loss_box_reg: 0.02899  loss_mask: 0.03058  loss_rpn_cls: 2.169e-06  loss_rpn_loc: 0.002748    time: 0.8058  last_time: 0.5182  data_time: 0.0025  last_data_time: 0.0021   lr: 0.00091908  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:18:33 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 939  total_loss: 0.07504  loss_cls: 0.01532  loss_box_reg: 0.02972  loss_mask: 0.02836  loss_rpn_cls: 3.646e-06  loss_rpn_loc: 0.002845    time: 0.7993  last_time: 0.5310  data_time: 0.0024  last_data_time: 0.0021   lr: 0.00093906  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:18:43 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 959  total_loss: 0.07628  loss_cls: 0.01298  loss_box_reg: 0.0264  loss_mask: 0.03335  loss_rpn_cls: 1.791e-06  loss_rpn_loc: 0.002136    time: 0.7930  last_time: 0.5244  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00095904  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:18:53 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 979  total_loss: 0.07371  loss_cls: 0.01042  loss_box_reg: 0.02608  loss_mask: 0.03067  loss_rpn_cls: 7.529e-06  loss_rpn_loc: 0.002298    time: 0.7868  last_time: 0.4817  data_time: 0.0025  last_data_time: 0.0021   lr: 0.00097902  max_mem: 4781M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:19:03 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:19:03 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:19:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:19:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:19:03 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:19:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:19:03 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:19:03 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 999  total_loss: 0.07763  loss_cls: 0.01338  loss_box_reg: 0.02881  loss_mask: 0.03325  loss_rpn_cls: 5.174e-06  loss_rpn_loc: 0.002543    time: 0.7809  last_time: 0.5130  data_time: 0.0026  last_data_time: 0.0033   lr: 0.000999  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:19:13 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 1019  total_loss: 0.07367  loss_cls: 0.01188  loss_box_reg: 0.02851  loss_mask: 0.03009  loss_rpn_cls: 9.274e-06  loss_rpn_loc: 0.00244    time: 0.7753  last_time: 0.5222  data_time: 0.0025  last_data_time: 0.0025   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:19:23 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 1039  total_loss: 0.08471  loss_cls: 0.01508  loss_box_reg: 0.03265  loss_mask: 0.03273  loss_rpn_cls: 4.663e-06  loss_rpn_loc: 0.002555    time: 0.7699  last_time: 0.5219  data_time: 0.0025  last_data_time: 0.0030   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:19:33 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 1059  total_loss: 0.06709  loss_cls: 0.01203  loss_box_reg: 0.02576  loss_mask: 0.02769  loss_rpn_cls: 4.578e-06  loss_rpn_loc: 0.002383    time: 0.7648  last_time: 0.5224  data_time: 0.0025  last_data_time: 0.0028   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:19:43 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 1079  total_loss: 0.06978  loss_cls: 0.01051  loss_box_reg: 0.02593  loss_mask: 0.02861  loss_rpn_cls: 1.28e-05  loss_rpn_loc: 0.002396    time: 0.7599  last_time: 0.4971  data_time: 0.0024  last_data_time: 0.0027   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:19:53 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 1099  total_loss: 0.07404  loss_cls: 0.01235  loss_box_reg: 0.02555  loss_mask: 0.03254  loss_rpn_cls: 3.218e-06  loss_rpn_loc: 0.002736    time: 0.7551  last_time: 0.4667  data_time: 0.0024  last_data_time: 0.0022   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:20:03 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 1119  total_loss: 0.07244  loss_cls: 0.01289  loss_box_reg: 0.02818  loss_mask: 0.02651  loss_rpn_cls: 8.76e-06  loss_rpn_loc: 0.002552    time: 0.7507  last_time: 0.5291  data_time: 0.0024  last_data_time: 0.0021   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:20:13 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1139  total_loss: 0.07159  loss_cls: 0.01122  loss_box_reg: 0.0266  loss_mask: 0.02941  loss_rpn_cls: 3.426e-06  loss_rpn_loc: 0.002743    time: 0.7462  last_time: 0.4617  data_time: 0.0025  last_data_time: 0.0026   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:20:23 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1159  total_loss: 0.06215  loss_cls: 0.01134  loss_box_reg: 0.02252  loss_mask: 0.02909  loss_rpn_cls: 1.221e-06  loss_rpn_loc: 0.001927    time: 0.7417  last_time: 0.4040  data_time: 0.0024  last_data_time: 0.0026   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:20:32 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 1179  total_loss: 0.06821  loss_cls: 0.0127  loss_box_reg: 0.02343  loss_mask: 0.02789  loss_rpn_cls: 5.808e-06  loss_rpn_loc: 0.002678    time: 0.7373  last_time: 0.4718  data_time: 0.0023  last_data_time: 0.0019   lr: 0.001  max_mem: 4781M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:20:42 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:20:42 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:20:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:20:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:20:42 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:20:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:20:42 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:20:42 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1199  total_loss: 0.06588  loss_cls: 0.01183  loss_box_reg: 0.02395  loss_mask: 0.02636  loss_rpn_cls: 4.22e-06  loss_rpn_loc: 0.002164    time: 0.7333  last_time: 0.4865  data_time: 0.0025  last_data_time: 0.0023   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:20:52 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 1219  total_loss: 0.06362  loss_cls: 0.01063  loss_box_reg: 0.02296  loss_mask: 0.02537  loss_rpn_cls: 5.602e-06  loss_rpn_loc: 0.001808    time: 0.7294  last_time: 0.4749  data_time: 0.0024  last_data_time: 0.0021   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:21:02 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 1239  total_loss: 0.06366  loss_cls: 0.01207  loss_box_reg: 0.02065  loss_mask: 0.02705  loss_rpn_cls: 3.601e-06  loss_rpn_loc: 0.001917    time: 0.7256  last_time: 0.5215  data_time: 0.0023  last_data_time: 0.0021   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:21:12 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 1259  total_loss: 0.07123  loss_cls: 0.01339  loss_box_reg: 0.02738  loss_mask: 0.02913  loss_rpn_cls: 1.875e-06  loss_rpn_loc: 0.002148    time: 0.7222  last_time: 0.5311  data_time: 0.0028  last_data_time: 0.0026   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:21:22 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1279  total_loss: 0.06927  loss_cls: 0.0127  loss_box_reg: 0.02549  loss_mask: 0.02534  loss_rpn_cls: 1.528e-05  loss_rpn_loc: 0.002238    time: 0.7188  last_time: 0.4982  data_time: 0.0023  last_data_time: 0.0025   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:21:32 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1299  total_loss: 0.06636  loss_cls: 0.01054  loss_box_reg: 0.02419  loss_mask: 0.02837  loss_rpn_cls: 1.409e-05  loss_rpn_loc: 0.002587    time: 0.7153  last_time: 0.4922  data_time: 0.0024  last_data_time: 0.0022   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:21:42 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1319  total_loss: 0.06237  loss_cls: 0.01007  loss_box_reg: 0.02404  loss_mask: 0.02639  loss_rpn_cls: 9.334e-06  loss_rpn_loc: 0.002194    time: 0.7118  last_time: 0.5102  data_time: 0.0024  last_data_time: 0.0026   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:21:52 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 1339  total_loss: 0.06812  loss_cls: 0.01046  loss_box_reg: 0.02617  loss_mask: 0.02652  loss_rpn_cls: 7.229e-06  loss_rpn_loc: 0.002267    time: 0.7085  last_time: 0.5180  data_time: 0.0024  last_data_time: 0.0030   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:22:02 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1359  total_loss: 0.06235  loss_cls: 0.009491  loss_box_reg: 0.02133  loss_mask: 0.02681  loss_rpn_cls: 3.189e-06  loss_rpn_loc: 0.002123    time: 0.7053  last_time: 0.5357  data_time: 0.0023  last_data_time: 0.0023   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:22:12 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1379  total_loss: 0.05908  loss_cls: 0.01178  loss_box_reg: 0.02264  loss_mask: 0.0282  loss_rpn_cls: 6.93e-06  loss_rpn_loc: 0.002337    time: 0.7023  last_time: 0.4620  data_time: 0.0026  last_data_time: 0.0027   lr: 0.001  max_mem: 4781M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:22:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:22:21 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:22:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:22:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:22:21 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:22:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:22:21 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:22:22 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1399  total_loss: 0.05776  loss_cls: 0.009652  loss_box_reg: 0.02016  loss_mask: 0.02545  loss_rpn_cls: 2.733e-06  loss_rpn_loc: 0.002089    time: 0.6993  last_time: 0.5044  data_time: 0.0025  last_data_time: 0.0023   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:22:31 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 1419  total_loss: 0.06203  loss_cls: 0.009243  loss_box_reg: 0.02114  loss_mask: 0.02689  loss_rpn_cls: 2.665e-06  loss_rpn_loc: 0.002126    time: 0.6964  last_time: 0.4925  data_time: 0.0024  last_data_time: 0.0022   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:22:41 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1439  total_loss: 0.05709  loss_cls: 0.01028  loss_box_reg: 0.02153  loss_mask: 0.0238  loss_rpn_cls: 2.995e-06  loss_rpn_loc: 0.001859    time: 0.6936  last_time: 0.5043  data_time: 0.0022  last_data_time: 0.0028   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:22:51 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 1459  total_loss: 0.06152  loss_cls: 0.01055  loss_box_reg: 0.02227  loss_mask: 0.02497  loss_rpn_cls: 6.598e-06  loss_rpn_loc: 0.00215    time: 0.6910  last_time: 0.5302  data_time: 0.0024  last_data_time: 0.0030   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:23:01 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 1479  total_loss: 0.05756  loss_cls: 0.007708  loss_box_reg: 0.01994  loss_mask: 0.02502  loss_rpn_cls: 2.196e-06  loss_rpn_loc: 0.002106    time: 0.6884  last_time: 0.5147  data_time: 0.0024  last_data_time: 0.0024   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:23:11 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1499  total_loss: 0.06964  loss_cls: 0.01297  loss_box_reg: 0.02729  loss_mask: 0.02808  loss_rpn_cls: 1.385e-05  loss_rpn_loc: 0.002641    time: 0.6858  last_time: 0.5082  data_time: 0.0025  last_data_time: 0.0025   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:23:21 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 1519  total_loss: 0.06091  loss_cls: 0.008596  loss_box_reg: 0.02232  loss_mask: 0.02682  loss_rpn_cls: 3.499e-06  loss_rpn_loc: 0.002072    time: 0.6832  last_time: 0.5017  data_time: 0.0023  last_data_time: 0.0019   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:23:31 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1539  total_loss: 0.05414  loss_cls: 0.01061  loss_box_reg: 0.01835  loss_mask: 0.02303  loss_rpn_cls: 5.691e-06  loss_rpn_loc: 0.001777    time: 0.6808  last_time: 0.4897  data_time: 0.0025  last_data_time: 0.0020   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:23:41 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 1559  total_loss: 0.05896  loss_cls: 0.01014  loss_box_reg: 0.01931  loss_mask: 0.02611  loss_rpn_cls: 5.882e-06  loss_rpn_loc: 0.002096    time: 0.6784  last_time: 0.4944  data_time: 0.0024  last_data_time: 0.0018   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:23:51 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 1579  total_loss: 0.05963  loss_cls: 0.009811  loss_box_reg: 0.02073  loss_mask: 0.02552  loss_rpn_cls: 4.312e-06  loss_rpn_loc: 0.001639    time: 0.6761  last_time: 0.5207  data_time: 0.0026  last_data_time: 0.0018   lr: 0.001  max_mem: 4781M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:24:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:24:00 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:24:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:24:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:24:00 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:24:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:24:00 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:24:00 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 1599  total_loss: 0.06091  loss_cls: 0.01101  loss_box_reg: 0.02141  loss_mask: 0.02325  loss_rpn_cls: 3.389e-06  loss_rpn_loc: 0.001888    time: 0.6736  last_time: 0.5056  data_time: 0.0024  last_data_time: 0.0032   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:24:10 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 1619  total_loss: 0.06743  loss_cls: 0.01107  loss_box_reg: 0.02444  loss_mask: 0.0259  loss_rpn_cls: 7.341e-06  loss_rpn_loc: 0.001686    time: 0.6713  last_time: 0.4886  data_time: 0.0023  last_data_time: 0.0022   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:24:20 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 1639  total_loss: 0.05729  loss_cls: 0.008128  loss_box_reg: 0.02153  loss_mask: 0.02545  loss_rpn_cls: 3.661e-06  loss_rpn_loc: 0.001908    time: 0.6691  last_time: 0.4751  data_time: 0.0023  last_data_time: 0.0023   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:24:30 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 1659  total_loss: 0.05534  loss_cls: 0.009161  loss_box_reg: 0.02039  loss_mask: 0.02236  loss_rpn_cls: 1.028e-05  loss_rpn_loc: 0.002081    time: 0.6669  last_time: 0.4611  data_time: 0.0023  last_data_time: 0.0018   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:24:40 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 1679  total_loss: 0.05755  loss_cls: 0.01115  loss_box_reg: 0.02269  loss_mask: 0.02696  loss_rpn_cls: 4.604e-06  loss_rpn_loc: 0.001978    time: 0.6649  last_time: 0.5372  data_time: 0.0025  last_data_time: 0.0026   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:24:50 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 1699  total_loss: 0.0565  loss_cls: 0.008983  loss_box_reg: 0.01782  loss_mask: 0.02444  loss_rpn_cls: 4.179e-06  loss_rpn_loc: 0.002022    time: 0.6629  last_time: 0.4546  data_time: 0.0023  last_data_time: 0.0023   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:24:59 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 1719  total_loss: 0.05822  loss_cls: 0.01033  loss_box_reg: 0.02103  loss_mask: 0.02394  loss_rpn_cls: 5.16e-06  loss_rpn_loc: 0.001816    time: 0.6610  last_time: 0.5123  data_time: 0.0023  last_data_time: 0.0027   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:25:09 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 1739  total_loss: 0.05335  loss_cls: 0.007924  loss_box_reg: 0.01817  loss_mask: 0.02664  loss_rpn_cls: 4.5e-06  loss_rpn_loc: 0.00165    time: 0.6588  last_time: 0.4847  data_time: 0.0023  last_data_time: 0.0022   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:25:19 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 1759  total_loss: 0.05726  loss_cls: 0.00875  loss_box_reg: 0.01932  loss_mask: 0.02501  loss_rpn_cls: 1.034e-05  loss_rpn_loc: 0.001888    time: 0.6570  last_time: 0.4736  data_time: 0.0026  last_data_time: 0.0020   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:25:29 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1779  total_loss: 0.06185  loss_cls: 0.01084  loss_box_reg: 0.02234  loss_mask: 0.02688  loss_rpn_cls: 1.233e-05  loss_rpn_loc: 0.001883    time: 0.6552  last_time: 0.5171  data_time: 0.0025  last_data_time: 0.0020   lr: 0.001  max_mem: 4781M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:25:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:25:39 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:25:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:25:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:25:39 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:25:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:25:39 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[07/02 09:25:39 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 1799  total_loss: 0.0577  loss_cls: 0.009906  loss_box_reg: 0.01917  loss_mask: 0.02345  loss_rpn_cls: 7.202e-06  loss_rpn_loc: 0.001926    time: 0.6535  last_time: 0.5259  data_time: 0.0023  last_data_time: 0.0024   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:25:49 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 1819  total_loss: 0.05939  loss_cls: 0.01061  loss_box_reg: 0.02079  loss_mask: 0.0231  loss_rpn_cls: 5.344e-06  loss_rpn_loc: 0.001817    time: 0.6518  last_time: 0.5141  data_time: 0.0026  last_data_time: 0.0026   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:25:59 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 1839  total_loss: 0.05757  loss_cls: 0.01067  loss_box_reg: 0.0202  loss_mask: 0.02454  loss_rpn_cls: 9.594e-06  loss_rpn_loc: 0.002062    time: 0.6500  last_time: 0.5368  data_time: 0.0025  last_data_time: 0.0028   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:26:09 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 1859  total_loss: 0.06168  loss_cls: 0.011  loss_box_reg: 0.02204  loss_mask: 0.02522  loss_rpn_cls: 1.064e-05  loss_rpn_loc: 0.002066    time: 0.6484  last_time: 0.5102  data_time: 0.0026  last_data_time: 0.0028   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:26:18 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 1879  total_loss: 0.05433  loss_cls: 0.00838  loss_box_reg: 0.01964  loss_mask: 0.02354  loss_rpn_cls: 7.174e-06  loss_rpn_loc: 0.001938    time: 0.6466  last_time: 0.5057  data_time: 0.0023  last_data_time: 0.0024   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:26:28 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 1899  total_loss: 0.04897  loss_cls: 0.007759  loss_box_reg: 0.01604  loss_mask: 0.02386  loss_rpn_cls: 2.705e-06  loss_rpn_loc: 0.001654    time: 0.6449  last_time: 0.4215  data_time: 0.0024  last_data_time: 0.0021   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:26:38 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 1919  total_loss: 0.05728  loss_cls: 0.01049  loss_box_reg: 0.02084  loss_mask: 0.02279  loss_rpn_cls: 3.111e-06  loss_rpn_loc: 0.001753    time: 0.6434  last_time: 0.4332  data_time: 0.0025  last_data_time: 0.0023   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:26:48 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 1939  total_loss: 0.05551  loss_cls: 0.008105  loss_box_reg: 0.02014  loss_mask: 0.02403  loss_rpn_cls: 3.967e-06  loss_rpn_loc: 0.001649    time: 0.6417  last_time: 0.4814  data_time: 0.0024  last_data_time: 0.0027   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:26:58 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 1959  total_loss: 0.05539  loss_cls: 0.009363  loss_box_reg: 0.02094  loss_mask: 0.02089  loss_rpn_cls: 8.533e-06  loss_rpn_loc: 0.001524    time: 0.6402  last_time: 0.4329  data_time: 0.0025  last_data_time: 0.0022   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:27:07 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 1979  total_loss: 0.05189  loss_cls: 0.009101  loss_box_reg: 0.02002  loss_mask: 0.02062  loss_rpn_cls: 3.527e-06  loss_rpn_loc: 0.001807    time: 0.6387  last_time: 0.4788  data_time: 0.0024  last_data_time: 0.0025   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:27:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.05477  loss_cls: 0.009082  loss_box_reg: 0.0181  loss_mask: 0.02352  loss_rpn_cls: 8.361e-06  loss_rpn_loc: 0.001626    time: 0.6372  last_time: 0.4545  data_time: 0.0023  last_data_time: 0.0024   lr: 0.001  max_mem: 4781M\n",
      "\u001b[32m[07/02 09:27:18 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:21:13 (0.6372 s / it)\n",
      "\u001b[32m[07/02 09:27:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:22 (0:00:09 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:27:18 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:27:18 d2.data.datasets.coco]: \u001b[0mLoaded 14 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[07/02 09:27:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 09:27:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 09:27:18 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 09:27:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:27:18 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2XMPKQ28GRna"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c5100a57b94b6e38\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c5100a57b94b6e38\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flInE1L-XTfx"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:30.387236Z",
     "start_time": "2024-06-25T08:07:28.649281Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2265,
     "status": "ok",
     "timestamp": 1668005909534,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "vsByFDFbQwLi",
    "outputId": "db8479c0-a286-4e83-e064-9ae4ebad3aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/02 09:27:33 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from tank-and-ramp-1\\mask_rcnn_R_101_FPN_3x\\2024-07-02-09-05-45\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:56.682926Z",
     "start_time": "2024-06-25T08:07:33.893951Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "hmAcBbpXX-Rh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 09:27:33 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 09:27:33 d2.data.datasets.coco]: \u001b[0mLoaded 29 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\ramp_and_edge\\tank-and-ramp-1-1\\valid\\_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data import DatasetCatalog\n",
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "\n",
    "# Assuming VALID_DATA_SET_NAME and predictor are already defined\n",
    "dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)\n",
    "\n",
    "for d in dataset_valid:\n",
    "    # Read the image\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    \n",
    "    # Get predictions\n",
    "    outputs = predictor(img)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    visualizer = Visualizer(\n",
    "        img[:, :, ::-1],  # Convert BGR to RGB\n",
    "        metadata=metadata,  # Metadata for visualization\n",
    "        scale=0.8,  # Scale of the image\n",
    "        instance_mode=ColorMode.IMAGE_BW  # Display mode\n",
    "    )\n",
    "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Show the image with predictions\n",
    "    cv2.imshow(\"validation\", out.get_image()[:, :, ::-1])  # Convert RGB back to BGR\n",
    "    cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Closes the window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Config file 'C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2/mask_rcnn_R_101_FPN_3x/2024-07-02-08-11-08/config.yaml' does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m weights_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2/mask_rcnn_R_101_FPN_3x/2024-07-02-08-11-08/model_final.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2-1/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 68\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m process_folder(predictor, input_folder)\n",
      "Cell \u001b[1;32mIn[39], line 14\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(config_file, weights_file)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(config_file, weights_file):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Load the configuration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mWEIGHTS \u001b[38;5;241m=\u001b[39m weights_file\n\u001b[0;32m     16\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mROI_HEADS\u001b[38;5;241m.\u001b[39mSCORE_THRESH_TEST \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.96\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Daanish Mittal\\anaconda3\\lib\\site-packages\\detectron2\\config\\config.py:45\u001b[0m, in \u001b[0;36mCfgNode.merge_from_file\u001b[1;34m(self, cfg_filename, allow_unsafe)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_from_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg_filename: \u001b[38;5;28mstr\u001b[39m, allow_unsafe: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    Load content from the given config file and merge it into self.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m        allow_unsafe: allow unsafe yaml syntax\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m PathManager\u001b[38;5;241m.\u001b[39misfile(cfg_filename), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m     loaded_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_yaml_with_base(cfg_filename, allow_unsafe\u001b[38;5;241m=\u001b[39mallow_unsafe)\n\u001b[0;32m     47\u001b[0m     loaded_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(loaded_cfg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Config file 'C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2/mask_rcnn_R_101_FPN_3x/2024-07-02-08-11-08/config.yaml' does not exist!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.96\n",
    "      # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Visualize the results\n",
    "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Display the image\n",
    "    result_image = out.get_image()[:, :, ::-1]\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # Display the frame\n",
    "        result_frame = out.get_image()[:, :, ::-1]\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2/mask_rcnn_R_101_FPN_3x/2024-07-02-08-11-08/config.yaml\"\n",
    "weights_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2/mask_rcnn_R_101_FPN_3x/2024-07-02-08-11-08/model_final.pth\"\n",
    "input_folder = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ramp_and_edge/tank-and-ramp-2-1/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1Wkuq4DLHD7MG5HgpEqiytvEjvNK2sYAx",
     "timestamp": 1719261218111
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
