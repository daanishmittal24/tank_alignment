{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless --upgrade\n",
    "!pip install ffmpeg-python --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reduce resolution\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from IPython.display import display, Image, clear_output\n",
    "import IPython.display\n",
    "\n",
    "# Replace with your IP cameras' RTSP URLs, including authentication\n",
    "ip_camera_url_1 = 'rtsp://admin:123456@192.168.1.33:554/stream1'\n",
    "ip_camera_url_2 = 'rtsp://admin:123456@192.168.1.32:554/stream1'\n",
    "\n",
    "# Create VideoCapture objects for both cameras\n",
    "cap1 = cv2.VideoCapture(ip_camera_url_1)\n",
    "cap2 = cv2.VideoCapture(ip_camera_url_2)\n",
    "\n",
    "# Check if the camera streams have opened successfully\n",
    "if not cap1.isOpened():\n",
    "    print(\"Error: Could not open video stream from camera 1.\")\n",
    "    exit()\n",
    "\n",
    "if not cap2.isOpened():\n",
    "    print(\"Error: Could not open video stream from camera 2.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture frame-by-frame from camera 1\n",
    "        ret1, frame1 = cap1.read()\n",
    "\n",
    "        if not ret1:\n",
    "            print(\"Failed to retrieve frame from camera 1.\")\n",
    "            break\n",
    "\n",
    "        # Display frame from camera 1\n",
    "        _, img1 = cv2.imencode('.jpeg', frame1)\n",
    "        display(Image(data=img1))\n",
    "        \n",
    "        # Clear the previous output to update the image\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Introduce a small delay to control frame rate\n",
    "        time.sleep(0.05)  # Adjust the delay as needed\n",
    "\n",
    "        # Capture frame-by-frame from camera 2\n",
    "        ret2, frame2 = cap2.read()\n",
    "\n",
    "        if not ret2:\n",
    "            print(\"Failed to retrieve frame from camera 2.\")\n",
    "            break\n",
    "\n",
    "        # Display frame from camera 2\n",
    "        _, img2 = cv2.imencode('.jpeg', frame2)\n",
    "        display(Image(data=img2))\n",
    "        \n",
    "        # Clear the previous output to update the image\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Introduce a small delay to control frame rate\n",
    "        time.sleep(0.05)  # Adjust the delay as needed\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted, stopping...\")\n",
    "\n",
    "finally:\n",
    "    # Release the captures and close windows\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:01:17.381805Z",
     "start_time": "2024-07-17T10:01:17.009782Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:31:18.052063Z",
     "start_time": "2024-07-17T10:29:27.416461Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# Replace with your IP cameras' RTSP URLs, including authentication\n",
    "ip_camera_url_1 = 'rtsp://admin:123456@192.168.1.32:554/stream1'\n",
    "ip_camera_url_2 = 'rtsp://admin:123456@192.168.1.33:554/stream1'\n",
    "\n",
    "# Create a directory to save captured photos and videos\n",
    "if not os.path.exists('captured_photos'):\n",
    "    os.makedirs('captured_photos')\n",
    "if not os.path.exists('recorded_videos'):\n",
    "    os.makedirs('recorded_videos')\n",
    "\n",
    "class CameraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"IP Camera Interface\")\n",
    "\n",
    "        self.cap1 = cv2.VideoCapture(ip_camera_url_1)\n",
    "        self.cap2 = cv2.VideoCapture(ip_camera_url_2)\n",
    "        \n",
    "        if not self.cap1.isOpened():\n",
    "            messagebox.showerror(\"Error\", \"Could not open video stream from camera 1.\")\n",
    "            self.root.destroy()\n",
    "            return\n",
    "\n",
    "        if not self.cap2.isOpened():\n",
    "            messagebox.showerror(\"Error\", \"Could not open video stream from camera 2.\")\n",
    "            self.root.destroy()\n",
    "            return\n",
    "\n",
    "        self.video_frame1 = tk.Label(self.root)\n",
    "        self.video_frame1.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.video_frame2 = tk.Label(self.root)\n",
    "        self.video_frame2.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.btn_capture = tk.Button(self.root, text=\"Capture Image\", command=self.capture_images)\n",
    "        self.btn_capture.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.btn_start_record = tk.Button(self.root, text=\"Start Recording\", command=self.start_recording)\n",
    "        self.btn_start_record.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.btn_stop_record = tk.Button(self.root, text=\"Stop Recording\", command=self.stop_recording)\n",
    "        self.btn_stop_record.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.recording = False\n",
    "        self.update_frames()\n",
    "\n",
    "    def update_frames(self):\n",
    "        ret1, frame1 = self.cap1.read()\n",
    "        ret2, frame2 = self.cap2.read()\n",
    "\n",
    "        if ret1:\n",
    "            self.photo1 = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)))\n",
    "            self.video_frame1.config(image=self.photo1)\n",
    "\n",
    "        if ret2:\n",
    "            self.photo2 = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)))\n",
    "            self.video_frame2.config(image=self.photo2)\n",
    "\n",
    "        if self.recording:\n",
    "            self.out1.write(frame1)\n",
    "            self.out2.write(frame2)\n",
    "\n",
    "        self.root.after(10, self.update_frames)\n",
    "\n",
    "    def capture_images(self):\n",
    "        ret1, frame1 = self.cap1.read()\n",
    "        ret2, frame2 = self.cap2.read()\n",
    "\n",
    "        if ret1:\n",
    "            self.save_image(frame1, 1)\n",
    "        if ret2:\n",
    "            self.save_image(frame2, 2)\n",
    "\n",
    "    def save_image(self, frame, camera_id):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'captured_photos/camera_{camera_id}_{timestamp}.jpg'\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f'Photo captured: {filename}')\n",
    "\n",
    "    def start_recording(self):\n",
    "        if not self.recording:\n",
    "            self.recording = True\n",
    "            self.start_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            self.out1 = cv2.VideoWriter(f'recorded_videos/camera_1_{self.start_time}.avi', fourcc, 20.0, (640, 480))\n",
    "            self.out2 = cv2.VideoWriter(f'recorded_videos/camera_2_{self.start_time}.avi', fourcc, 20.0, (640, 480))\n",
    "            print(\"Recording started\")\n",
    "\n",
    "    def stop_recording(self):\n",
    "        if self.recording:\n",
    "            self.recording = False\n",
    "            self.out1.release()\n",
    "            self.out2.release()\n",
    "            print(\"Recording stopped\")\n",
    "\n",
    "    def on_closing(self):\n",
    "        if self.recording:\n",
    "            self.stop_recording()\n",
    "        self.cap1.release()\n",
    "        self.cap2.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = CameraApp(root)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:35:16.664706Z",
     "start_time": "2024-07-17T10:34:15.446673Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {img_path}\")\n",
    "            else:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "folder_path = 'C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ipcam/captured_photos'\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Example usage\n",
    "print(f\"Loaded {len(images)} images.\")\n",
    "\n",
    "if len(images) < 2:\n",
    "    print(\"Need at least two images for this process.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Feature detection and extraction\n",
    "orb = cv.ORB_create()\n",
    "keypoints_list = []  # List to store keypoints\n",
    "descriptors_list = []  # List to store descriptors\n",
    "\n",
    "for img in images:\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    keypoints_list.append(keypoints)\n",
    "    descriptors_list.append(descriptors)\n",
    "\n",
    "# Step 3: Feature matching\n",
    "matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_BRUTEFORCE_HAMMING)\n",
    "matches_list = []  # List to store matches\n",
    "\n",
    "for i in range(len(images) - 1):\n",
    "    matches = matcher.match(descriptors_list[i], descriptors_list[i + 1], None)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)  # Sort matches by distance\n",
    "    matches_list.append(matches)\n",
    "\n",
    "# Step 4: Extract matched points\n",
    "def get_matched_points(kp1, kp2, matches):\n",
    "    points1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    points2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "    return points1, points2\n",
    "\n",
    "# Assuming you are only using the first two images for essential matrix calculation\n",
    "points1, points2 = get_matched_points(keypoints_list[0], keypoints_list[1], matches_list[0])\n",
    "\n",
    "# Step 5: Estimate camera motion (essential matrix)\n",
    "# Assuming a dummy camera matrix (identity matrix for simplicity)\n",
    "focal_length = 1.0  # Dummy focal length\n",
    "frame_width = images[0].shape[1]\n",
    "frame_height = images[0].shape[0]\n",
    "center = (frame_width / 2, frame_height / 2)\n",
    "camera_matrix = np.array([[focal_length, 0, center[0]],\n",
    "                          [0, focal_length, center[1]],\n",
    "                          [0, 0, 1]], dtype=\"double\")\n",
    "\n",
    "# Print camera matrix, focal point, frame width, and height\n",
    "print(\"Camera Matrix:\")\n",
    "print(camera_matrix)\n",
    "print(\"Focal Point:\")\n",
    "print(center)\n",
    "print(\"Frame Width:\", frame_width)\n",
    "print(\"Frame Height:\", frame_height)\n",
    "\n",
    "E, mask = cv.findEssentialMat(points1, points2, camera_matrix, method=cv.RANSAC, prob=0.999, threshold=1.0)\n",
    "\n",
    "# Step 6: Recover pose (rotation and translation)\n",
    "_, R, t, mask = cv.recoverPose(E, points1, points2, camera_matrix)\n",
    "\n",
    "# Step 7: Print essential matrix, rotation, and translation\n",
    "print(\"Essential Matrix:\")\n",
    "print(E)\n",
    "print(\"Rotation:\")\n",
    "print(R)\n",
    "print(\"Translation:\")\n",
    "print(t)\n",
    "\n",
    "# Optional: Undistort images (you need camera matrix and dist_coeffs, usually obtained from chessboard calibration)\n",
    "# For this example, using identity matrix for the camera matrix and zero distortion coefficients\n",
    "dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "# Print distortion coefficients\n",
    "print(\"Distortion Coefficients:\")\n",
    "print(dist_coeffs)\n",
    "\n",
    "# Undistort images\n",
    "undistorted_images = []\n",
    "for img in images:\n",
    "    undistorted_img = cv.undistort(img, camera_matrix, dist_coeffs)\n",
    "    undistorted_images.append(undistorted_img)\n",
    "\n",
    "# Step 8: Display undistorted images (for validation)\n",
    "for i, img in enumerate(undistorted_images):\n",
    "    cv.imshow(f'Undistorted Image {i}', img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:38:40.903967Z",
     "start_time": "2024-07-17T10:38:40.856971Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "CHESSBOARD_SIZE = (9, 6)\n",
    "CALIBRATION_IMAGES_DIR = 'C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/ipcam/captured_photos'\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "objp = np.zeros((CHESSBOARD_SIZE[0] * CHESSBOARD_SIZE[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESSBOARD_SIZE[0], 0:CHESSBOARD_SIZE[1]].T.reshape(-1, 2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "images = glob.glob(os.path.join(CALIBRATION_IMAGES_DIR, 'calib_*.jpg'))\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHESSBOARD_SIZE, None)\n",
    "\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, CHESSBOARD_SIZE, corners2, ret)\n",
    "        cv2.imshow('Chessboard', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix : \\n\")\n",
    "print(mtx)\n",
    "print(\"Distortion Coefficient : \\n\")\n",
    "print(dist)\n",
    "\n",
    "# Save the camera calibration results\n",
    "np.savez('camera_calib.npz', mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:44:50.885717Z",
     "start_time": "2024-07-17T10:41:39.813306Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Replace with your IP camera's RTSP URL\n",
    "ip_camera_url_1 = 'rtsp://admin:123456@192.168.1.32:554/stream1'\n",
    "\n",
    "# Create VideoCapture object for the camera\n",
    "cap = cv2.VideoCapture(ip_camera_url_1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream from camera.\")\n",
    "    exit()\n",
    "\n",
    "# Define parameters for chessboard detection\n",
    "CHESSBOARD_SIZE = (9, 6)  # Number of inner corners (columns, rows)\n",
    "CAPTURE_COUNT = 20  # Number of calibration images to capture\n",
    "calibration_images = []  # List to store captured images\n",
    "\n",
    "counter = 0\n",
    "\n",
    "while counter < CAPTURE_COUNT:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame.\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHESSBOARD_SIZE, None)\n",
    "\n",
    "    if ret:\n",
    "        cv2.drawChessboardCorners(frame, CHESSBOARD_SIZE, corners, ret)\n",
    "        cv2.imshow('Chessboard', frame)\n",
    "        filename = f'calibration_image_{counter}.jpg'\n",
    "        cv2.imwrite(filename, frame)\n",
    "        calibration_images.append(frame)\n",
    "        counter += 1\n",
    "        print(f'Captured {counter}/{CAPTURE_COUNT} images')\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    cv2.imshow('Chessboard', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Ensure all captured images are saved\n",
    "print(f'Saved {len(calibration_images)} calibration images.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onvif-zeep\n",
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T19:40:15.618638Z",
     "start_time": "2024-07-17T19:40:05.664194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onvif-zeep\n",
      "  Downloading onvif_zeep-0.2.12.tar.gz (163 kB)\n",
      "     ---------------------------------------- 0.0/163.1 kB ? eta -:--:--\n",
      "     --------- ----------------------------- 41.0/163.1 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------- ----------- 112.6/163.1 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 163.1/163.1 kB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: opencv-python in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Collecting zeep>=3.0.0 (from onvif-zeep)\n",
      "  Downloading zeep-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.3)\n",
      "Requirement already satisfied: attrs>=17.2.0 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (22.1.0)\n",
      "Collecting isodate>=0.5.4 (from zeep>=3.0.0->onvif-zeep)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: lxml>=4.6.0 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (4.9.1)\n",
      "Requirement already satisfied: platformdirs>=1.4.0 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (2.5.2)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (2.28.1)\n",
      "Requirement already satisfied: requests-toolbelt>=0.7.1 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (0.9.1)\n",
      "Requirement already satisfied: requests-file>=1.5.1 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (1.5.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from zeep>=3.0.0->onvif-zeep) (2022.7)\n",
      "Requirement already satisfied: six in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from isodate>=0.5.4->zeep>=3.0.0->onvif-zeep) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from requests>=2.7.0->zeep>=3.0.0->onvif-zeep) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from requests>=2.7.0->zeep>=3.0.0->onvif-zeep) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from requests>=2.7.0->zeep>=3.0.0->onvif-zeep) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages (from requests>=2.7.0->zeep>=3.0.0->onvif-zeep) (2022.12.7)\n",
      "Downloading zeep-4.2.1-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.2 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 92.2/101.2 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.2/101.2 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.7/41.7 kB 2.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: onvif-zeep\n",
      "  Building wheel for onvif-zeep (setup.py): started\n",
      "  Building wheel for onvif-zeep (setup.py): finished with status 'done'\n",
      "  Created wheel for onvif-zeep: filename=onvif_zeep-0.2.12-py3-none-any.whl size=192048 sha256=3a01269794aae89081ca36a6e1b62448a62f8485e51fddb6dc80760842459c04\n",
      "  Stored in directory: c:\\users\\daanish mittal\\appdata\\local\\pip\\cache\\wheels\\97\\4a\\8c\\06372489b655e734dba9f0b88cf51f77a5c5636e55043955b0\n",
      "Successfully built onvif-zeep\n",
      "Installing collected packages: isodate, zeep, onvif-zeep\n",
      "Successfully installed isodate-0.6.1 onvif-zeep-0.2.12 zeep-4.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onvif-zeep opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T19:40:29.761412Z",
     "start_time": "2024-07-17T19:40:28.076147Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement onvif-pyzeep (from versions: none)\n",
      "ERROR: No matching distribution found for onvif-pyzeep\n"
     ]
    }
   ],
   "source": [
    "!pip install onvif-pyzeep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T19:45:16.464047Z",
     "start_time": "2024-07-17T19:44:40.108803Z"
    }
   },
   "outputs": [],
   "source": [
    "from onvif import ONVIFCamera\n",
    "import cv2\n",
    "\n",
    "# Camera connection details\n",
    "camera_host = '192.168.1.32'\n",
    "camera_port = 80\n",
    "camera_user = 'admin'\n",
    "camera_pass = '123456'\n",
    "\n",
    "# Initialize the ONVIF camera\n",
    "camera = ONVIFCamera(camera_host, camera_port, camera_user, camera_pass)\n",
    "\n",
    "# Create media service\n",
    "media_service = camera.create_media_service()\n",
    "\n",
    "# Get the stream URI\n",
    "profiles = media_service.GetProfiles()\n",
    "stream_uri = media_service.GetStreamUri({'StreamSetup': {'Stream': 'RTP-Unicast', 'Transport': 'RTSP'}, 'ProfileToken': profiles[0].token}).Uri\n",
    "\n",
    "# Initialize the video capture object with the stream URI\n",
    "cap = cv2.VideoCapture(stream_uri)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open the camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame read is successful, display the frame\n",
    "    if ret:\n",
    "        cv2.imshow('Camera', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T19:41:22.929273Z",
     "start_time": "2024-07-17T19:41:19.535381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: onvif-zeep\n",
      "Version: 0.2.12\n",
      "Summary: Python Client for ONVIF Camera\n",
      "Home-page: http://github.com/quatanium/python-onvif\n",
      "Author: Cherish Chen\n",
      "Author-email: sinchb128@gmail.com\n",
      "License: MIT\n",
      "Location: c:\\users\\daanish mittal\\anaconda3\\lib\\site-packages\n",
      "Requires: zeep\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show onvif-zeep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T08:42:30.126270Z",
     "start_time": "2024-07-18T08:42:24.622390Z"
    }
   },
   "outputs": [],
   "source": [
    "from onvif import ONVIFCamera\n",
    "import cv2\n",
    "\n",
    "# Camera connection details\n",
    "camera_host = '192.168.1.32'\n",
    "camera_port = 80\n",
    "camera_user = 'admin'\n",
    "camera_pass = '123456'\n",
    "\n",
    "# Initialize the ONVIF camera\n",
    "camera = ONVIFCamera(camera_host, camera_port, camera_user, camera_pass)\n",
    "\n",
    "# Create media service\n",
    "media_service = camera.create_media_service()\n",
    "\n",
    "# Get the stream URI\n",
    "profiles = media_service.GetProfiles()\n",
    "stream_uri = media_service.GetStreamUri({\n",
    "    'StreamSetup': {'Stream': 'RTP-Unicast', 'Transport': {'Protocol': 'RTSP'}},\n",
    "    'ProfileToken': profiles[0].token\n",
    "}).Uri\n",
    "\n",
    "# Initialize the video capture object with the stream URI\n",
    "cap = cv2.VideoCapture(stream_uri)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open the camera\")\n",
    "    exit()\n",
    "\n",
    "# Desired frame width and height\n",
    "desired_width = 640\n",
    "desired_height = 480\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame read is successful, resize and display the frame\n",
    "    if ret:\n",
    "        # Resize the frame\n",
    "        resized_frame = cv2.resize(frame, (desired_width, desired_height))\n",
    "        # Display the resized frame\n",
    "        cv2.imshow('Camera', resized_frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T08:42:37.927647Z",
     "start_time": "2024-07-18T08:42:33.602275Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.checkpoint.detection_checkpoint:[DetectionCheckpointer] Loading from C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth ...\n",
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from c:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Attribute 'thing_classes' does not exist in the metadata of dataset 'loader.ramp-test': metadata is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Get metadata\u001b[39;00m\n\u001b[0;32m     23\u001b[0m metadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m ramp_index \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthing_classes\u001b[49m\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mramp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_polygon_angle\u001b[39m(contour):\n\u001b[0;32m     27\u001b[0m     rect \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mminAreaRect(contour)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\detectron2\\data\\catalog.py:131\u001b[0m, in \u001b[0;36mMetadata.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist in the metadata of dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Available \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys are \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m    129\u001b[0m     )\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist in the metadata of dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Attribute 'thing_classes' does not exist in the metadata of dataset 'loader.ramp-test': metadata is empty."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "# Configuration\n",
    "config_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/config.yaml\"\n",
    "weights_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth\"\n",
    "input_folder = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/test_army\"\n",
    "\n",
    "# Set up configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.MODEL.WEIGHTS = weights_file\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Get metadata\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "ramp_index = metadata.thing_classes.index('ramp')\n",
    "\n",
    "def calculate_polygon_angle(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    angle = rect[2]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    elif angle > 45:\n",
    "        angle = angle - 90\n",
    "    else:\n",
    "        angle = 90 - abs(angle)\n",
    "    return angle\n",
    "\n",
    "def mask_sides(image, mask_percentage=0.2):\n",
    "    h, w = image.shape[:2]\n",
    "    mask_width = int(w * mask_percentage)\n",
    "    \n",
    "    mask = np.ones(image.shape[:2], dtype=np.uint8)\n",
    "    mask[:, :mask_width] = 0\n",
    "    mask[:, -mask_width:] = 0\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    masked_image[:, :mask_width] = 0\n",
    "    masked_image[:, -mask_width:] = 0\n",
    "    \n",
    "    return masked_image, mask\n",
    "\n",
    "def point_line_distance(point, line_start, line_end):\n",
    "    line_vec = np.array(line_end) - np.array(line_start)\n",
    "    point_vec = np.array(point) - np.array(line_start)\n",
    "    line_len = np.linalg.norm(line_vec)\n",
    "    line_unitvec = line_vec / line_len\n",
    "    point_vec_scaled = point_vec / line_len\n",
    "    t = np.dot(line_unitvec, point_vec_scaled)\n",
    "    t = np.clip(t, 0, 1)\n",
    "    nearest = line_start + t * line_vec\n",
    "    dist = np.linalg.norm(point - nearest)\n",
    "    return dist\n",
    "\n",
    "def process_image(image_path):\n",
    "    frame = cv2.imread(image_path)\n",
    "    masked_frame, frame_mask = mask_sides(frame, 0.3)\n",
    "    \n",
    "    outputs = predictor(masked_frame)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    ramp_instances = instances[instances.pred_classes == ramp_index]\n",
    "    \n",
    "    draw_frame = masked_frame.copy()\n",
    "    \n",
    "    for i in range(len(ramp_instances)):\n",
    "        if ramp_instances.has(\"pred_masks\"):\n",
    "            mask = ramp_instances.pred_masks[i].numpy()\n",
    "            mask = cv2.bitwise_and(mask.astype(np.uint8), frame_mask)\n",
    "            \n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if contours:\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                \n",
    "                epsilon = 0.05 * cv2.arcLength(largest_contour, True)\n",
    "                approx_contour = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "                \n",
    "                if len(approx_contour) > 4:\n",
    "                    approx_contour = cv2.convexHull(approx_contour)\n",
    "                    approx_contour = cv2.approxPolyDP(approx_contour, epsilon, True)\n",
    "                \n",
    "                if len(approx_contour) > 4:\n",
    "                    approx_contour = cv2.approxPolyDP(approx_contour, epsilon * 2, True)\n",
    "                \n",
    "                if len(approx_contour) > 4:\n",
    "                    approx_contour = cv2.convexHull(approx_contour, returnPoints=False)\n",
    "                    approx_contour = cv2.approxPolyDP(approx_contour, epsilon * 3, True)\n",
    "                \n",
    "                approx_contour = approx_contour[:4]\n",
    "\n",
    "                cv2.drawContours(draw_frame, [approx_contour], 0, (128, 0, 128), 2)\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                cv2.rectangle(draw_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "                extension_length = 50\n",
    "                extended_edge_top_start = (x, y)\n",
    "                extended_edge_bottom_start = (x, y + h)\n",
    "                extended_edge_top_end = (x, y - extension_length)\n",
    "                extended_edge_bottom_end = (x, y + h + extension_length)\n",
    "                \n",
    "                cv2.line(draw_frame, extended_edge_top_start, extended_edge_bottom_start, (0, 0, 255), 2)\n",
    "                cv2.line(draw_frame, extended_edge_top_start, extended_edge_top_end, (0, 0, 255), 2)\n",
    "                cv2.line(draw_frame, extended_edge_bottom_start, extended_edge_bottom_end, (0, 0, 255), 2)\n",
    "                \n",
    "                ramp_edge_start = tuple(approx_contour[0][0])\n",
    "                ramp_edge_end = tuple(approx_contour[1][0])\n",
    "                \n",
    "                vector_extended = np.array([extended_edge_bottom_end[0] - extended_edge_top_end[0], extended_edge_bottom_end[1] - extended_edge_top_end[1]])\n",
    "                vector_ramp = np.array([ramp_edge_end[0] - ramp_edge_start[0], ramp_edge_end[1] - ramp_edge_start[1]])\n",
    "                \n",
    "                dot_product = np.dot(vector_extended, vector_ramp)\n",
    "                norm_extended = np.linalg.norm(vector_extended)\n",
    "                norm_ramp = np.linalg.norm(vector_ramp)\n",
    "                \n",
    "                cosine_angle = dot_product / (norm_extended * norm_ramp)\n",
    "                angle = np.arccos(cosine_angle)\n",
    "                angle_degrees = np.degrees(angle)\n",
    "                \n",
    "                cv2.putText(draw_frame, f\"Angle: {angle_degrees:.2f}\", (x, y - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "                \n",
    "                mid_x = draw_frame.shape[1] // 2\n",
    "                intersection_point = (mid_x, y + h)\n",
    "                \n",
    "                line_length = 200\n",
    "                end_x = int(intersection_point[0] + line_length * np.sin(np.radians(angle_degrees)))\n",
    "                end_y = int(intersection_point[1] - line_length * np.cos(np.radians(angle_degrees)))\n",
    "                \n",
    "                cv2.line(draw_frame, intersection_point, (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "                min_distance = float('inf')\n",
    "                for point in approx_contour:\n",
    "                    dist = point_line_distance(point[0], intersection_point, (end_x, end_y))\n",
    "                    if dist < min_distance:\n",
    "                        min_distance = dist\n",
    "                \n",
    "                if min_distance < 5:\n",
    "                    tint_color = (0, 255, 0)\n",
    "                elif min_distance < 20:\n",
    "                    tint_color = (0, 165, 255)\n",
    "                else:\n",
    "                    tint_color = (0, 0, 255)\n",
    "                \n",
    "                overlay = np.full(draw_frame.shape, tint_color, dtype=np.uint8)\n",
    "                alpha = 0.3\n",
    "                \n",
    "                draw_frame = cv2.addWeighted(overlay, alpha, draw_frame, 1 - alpha, 0)\n",
    "                cv2.line(draw_frame, intersection_point, (end_x, end_y), tint_color, 2)\n",
    "    \n",
    "    return draw_frame\n",
    "\n",
    "def process_and_show_images(input_folder, num_images=10):\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for i, image_file in enumerate(image_files[:num_images]):\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        processed_image = process_image(image_path)\n",
    "        \n",
    "        plt.figure(figsize=(20, 16))\n",
    "        plt.imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Image {i+1}: {image_file}\")\n",
    "        plt.show()\n",
    "\n",
    "# Run the function to process and show images\n",
    "process_and_show_images(input_folder, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T10:35:16.949604Z",
     "start_time": "2024-07-18T10:33:53.568871Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.94\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def calculate_polygon_angle(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    angle = rect[2]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    return angle\n",
    "\n",
    "def mask_sides(image, mask_percentage=0.2):\n",
    "    h, w = image.shape[:2]\n",
    "    mask_width = int(w * mask_percentage)\n",
    "    \n",
    "    mask = np.ones(image.shape[:2], dtype=np.uint8)\n",
    "    mask[:, :mask_width] = 0\n",
    "    mask[:, -mask_width:] = 0\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    masked_image[:, :mask_width] = 0\n",
    "    masked_image[:, -mask_width:] = 0\n",
    "    \n",
    "    return masked_image, mask\n",
    "\n",
    "def draw_quadrilaterals(image, outputs, deformation_threshold=0.05, alpha=0.5, max_angle=15):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    overlay = image.copy()\n",
    "    \n",
    "    for mask in masks:\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            epsilon = deformation_threshold * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                angle = calculate_polygon_angle(approx)\n",
    "                \n",
    "                if abs(angle) < max_angle:\n",
    "                    cv2.polylines(overlay, [approx], True, (0, 255, 0), 2)\n",
    "                    \n",
    "                    x, y, w, h = cv2.boundingRect(approx)\n",
    "                    cv2.rectangle(overlay, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                    \n",
    "                    extension_length = 50\n",
    "                    cv2.line(overlay, (x + w, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.line(overlay, (x + w, y), (x + w, y - extension_length), (0, 0, 255), 2)\n",
    "                    cv2.line(overlay, (x + w, y + h), (x + w, y + h + extension_length), (0, 0, 255), 2)\n",
    "                    \n",
    "                    cv2.putText(overlay, f\"Angle: {angle:.2f}\", (x, y - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "                    \n",
    "                    mid_x = overlay.shape[1] // 2\n",
    "                    intersection_point = (mid_x, y + h)\n",
    "                    line_length = 200\n",
    "                    end_x = int(intersection_point[0] - line_length * np.sin(np.radians(angle)))\n",
    "                    end_y = int(intersection_point[1] - line_length * np.cos(np.radians(angle)))\n",
    "                    cv2.line(overlay, intersection_point, (end_x, end_y), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "    return image\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    masked_image, _ = mask_sides(image, 0.2)\n",
    "    outputs = predictor(masked_image)\n",
    "    \n",
    "    result_image = draw_quadrilaterals(masked_image, outputs)\n",
    "    \n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path, frame_skip=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            masked_frame, _ = mask_sides(frame, 0.2)\n",
    "            outputs = predictor(masked_frame)\n",
    "            result_frame = draw_quadrilaterals(masked_frame, outputs)\n",
    "            resized_frame = resize_image(result_frame)\n",
    "            cv2.imshow(f'Result for a frame in {video_path}', resized_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "def resize_image(image, scale_percent=90):\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def process_folder(predictor, folder_path, frame_skip=2):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path, frame_skip)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/config.yaml\"\n",
    "weights_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth\"\n",
    "input_folder = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/test_army\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T09:35:17.531818Z",
     "start_time": "2024-07-18T09:35:13.128075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.checkpoint.detection_checkpoint:[DetectionCheckpointer] Loading from C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth ...\n",
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from c:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth ...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T10:43:02.769998Z",
     "start_time": "2024-07-18T10:41:01.349571Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.94\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def calculate_polygon_angle(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    angle = rect[2]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    return angle\n",
    "\n",
    "def mask_sides(image, mask_percentage=0.2):\n",
    "    h, w = image.shape[:2]\n",
    "    mask_width = int(w * mask_percentage)\n",
    "    \n",
    "    mask = np.ones(image.shape[:2], dtype=np.uint8)\n",
    "    mask[:, :mask_width] = 0\n",
    "    mask[:, -mask_width:] = 0\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    masked_image[:, :mask_width] = 0\n",
    "    masked_image[:, -mask_width:] = 0\n",
    "    \n",
    "    return masked_image, mask\n",
    "\n",
    "def draw_quadrilaterals(image, outputs, deformation_threshold=0.05, alpha=0.5, max_angle=15):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    overlay = image.copy()\n",
    "    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    for mask in masks:\n",
    "        # Ensure the mask is binary\n",
    "        mask = (mask > 0).astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "\n",
    "        for contour in contours:\n",
    "            # Filter small contours\n",
    "            if cv2.contourArea(contour) < 100:\n",
    "                continue\n",
    "\n",
    "            # Approximate the contour to a polygon\n",
    "            epsilon = deformation_threshold * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "            # Draw the mask on the mask_overlay\n",
    "            cv2.drawContours(mask_overlay, [contour], -1, (0, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "            # Ensure it's a quadrilateral (4 sides)\n",
    "            if len(approx) == 4:\n",
    "                angle = calculate_polygon_angle(approx)\n",
    "\n",
    "                # Filter based on the angle\n",
    "                if abs(angle) < max_angle:\n",
    "                    cv2.polylines(overlay, [approx], True, (0, 255, 0), 2)\n",
    "\n",
    "                    x, y, w, h = cv2.boundingRect(approx)\n",
    "                    cv2.rectangle(overlay, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                    extension_length = 50\n",
    "                    cv2.line(overlay, (x + w, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.line(overlay, (x + w, y), (x + w, y - extension_length), (0, 0, 255), 2)\n",
    "                    cv2.line(overlay, (x + w, y + h), (x + w, y + h + extension_length), (0, 0, 255), 2)\n",
    "\n",
    "                    cv2.putText(overlay, f\"Angle: {angle:.2f}\", (x, y - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "                    mid_x = overlay.shape[1] // 2\n",
    "                    intersection_point = (mid_x, y + h)\n",
    "                    line_length = 200\n",
    "                    end_x = int(intersection_point[0] - line_length * np.sin(np.radians(angle)))\n",
    "                    end_y = int(intersection_point[1] - line_length * np.cos(np.radians(angle)))\n",
    "                    cv2.line(overlay, intersection_point, (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "    # Combine the original image with the mask overlay\n",
    "    cv2.addWeighted(mask_overlay, alpha, overlay, 1 - alpha, 0, overlay)\n",
    "    return overlay\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    masked_image, _ = mask_sides(image, 0.2)\n",
    "    outputs = predictor(masked_image)\n",
    "    \n",
    "    result_image = draw_quadrilaterals(masked_image, outputs)\n",
    "    \n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path, frame_skip=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            masked_frame, _ = mask_sides(frame, 0.2)\n",
    "            outputs = predictor(masked_frame)\n",
    "            result_frame = draw_quadrilaterals(masked_frame, outputs)\n",
    "            resized_frame = resize_image(result_frame)\n",
    "            cv2.imshow(f'Result for a frame in {video_path}', resized_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def resize_image(image, scale_percent=50):\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def process_folder(predictor, folder_path, frame_skip=2):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path, frame_skip)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/config.yaml\"\n",
    "weights_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth\"\n",
    "input_folder = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/test_army\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T16:46:51.152288Z",
     "start_time": "2024-07-18T16:46:33.825665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daanish Mittal\\anaconda3\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.94\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def calculate_polygon_angle(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    angle = rect[2]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    return angle\n",
    "\n",
    "def mask_sides(image, mask_percentage=0.2):\n",
    "    h, w = image.shape[:2]\n",
    "    mask_width = int(w * mask_percentage)\n",
    "    \n",
    "    mask = np.ones(image.shape[:2], dtype=np.uint8)\n",
    "    mask[:, :mask_width] = 0\n",
    "    mask[:, -mask_width:] = 0\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    masked_image[:, :mask_width] = 0\n",
    "    masked_image[:, -mask_width:] = 0\n",
    "    \n",
    "    return masked_image, mask\n",
    "\n",
    "def draw_quadrilaterals(image, outputs, deformation_threshold=0.05, alpha=0.5, vertical_tolerance=50):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    overlay = image.copy()\n",
    "    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    for mask in masks:\n",
    "        mask = (mask > 0).astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 100:\n",
    "                continue\n",
    "\n",
    "            epsilon = deformation_threshold * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "            cv2.drawContours(mask_overlay, [contour], -1, (0, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "            if len(approx) == 4:\n",
    "                angle = calculate_polygon_angle(approx)\n",
    "\n",
    "                if abs(angle - 90) <= vertical_tolerance:\n",
    "                    cv2.polylines(overlay, [approx], True, (0, 255, 0), 2)\n",
    "\n",
    "                    x, y, w, h = cv2.boundingRect(approx)\n",
    "                    cv2.rectangle(overlay, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                    extension_length = 50\n",
    "                    cv2.line(overlay, (x + w, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.line(overlay, (x + w, y), (x + w, y - extension_length), (0, 0, 255), 2)\n",
    "                    cv2.line(overlay, (x + w, y + h), (x + w, y + h + extension_length), (0, 0, 255), 2)\n",
    "\n",
    "                    cv2.putText(overlay, f\"Angle: {angle:.2f}\", (x, y - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "                    # Draw the green middle line\n",
    "                    mid_x = overlay.shape[1] // 2\n",
    "                    mid_y = overlay.shape[0] // 2\n",
    "                    intersection_point = (mid_x, y + h)\n",
    "                    line_length = max(overlay.shape[0], overlay.shape[1])  # Use the larger dimension of the image\n",
    "\n",
    "                    # Calculate the rotated line endpoints\n",
    "                    angle_radians = np.radians(angle - 90)  # Subtract 90 to align with image coordinates\n",
    "                    end_x1 = int(intersection_point[0] - line_length * np.cos(angle_radians))\n",
    "                    end_y1 = int(intersection_point[1] - line_length * np.sin(angle_radians))\n",
    "                    end_x2 = int(intersection_point[0] + line_length * np.cos(angle_radians))\n",
    "                    end_y2 = int(intersection_point[1] + line_length * np.sin(angle_radians))\n",
    "\n",
    "                    # Draw the rotated green line\n",
    "                    cv2.line(overlay, (end_x1, end_y1), (end_x2, end_y2), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.addWeighted(mask_overlay, alpha, overlay, 1 - alpha, 0, overlay)\n",
    "    return overlay\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    masked_image, _ = mask_sides(image, 0.2)\n",
    "    outputs = predictor(masked_image)\n",
    "    \n",
    "    result_image = draw_quadrilaterals(masked_image, outputs)\n",
    "    \n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path, frame_skip=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            masked_frame, _ = mask_sides(frame, 0.2)\n",
    "            outputs = predictor(masked_frame)\n",
    "            result_frame = draw_quadrilaterals(masked_frame, outputs)\n",
    "            resized_frame = cv2.resize(result_frame, (0, 0), fx=0.5, fy=0.5)\n",
    "            cv2.imshow(f'Result for a frame in {video_path}', resized_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path, frame_skip=2):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path, frame_skip)\n",
    "\n",
    "# Paths and variables\n",
    "config_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/config.yaml\"\n",
    "weights_file = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/army_ramp/loader.ramp/mask_rcnn_R_101_FPN_3x/2024-07-09-01-55-42/model_final.pth\"\n",
    "input_folder = \"C:/Users/Daanish Mittal/OneDrive/Desktop/Tank_align/tank_alignment/test_army\"\n",
    "\n",
    "# Load the model\n",
    "predictor = load_model(config_file, weights_file)\n",
    "\n",
    "# Process the folder\n",
    "process_folder(predictor, input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T11:14:50.877739Z",
     "start_time": "2024-07-18T11:14:26.482831Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
