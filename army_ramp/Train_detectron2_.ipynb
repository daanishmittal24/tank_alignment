{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAeG440fB7y3"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_767SpEGD2zJ"
      },
      "source": [
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "**How to Train [Detectron2](https://github.com/facebookresearch/detectron2) Segmentation on a Custom Dataset**\n",
        "\n",
        "The notebook is based on official Detectron2 [colab notebook](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5) and it covers:\n",
        "- Python environment setup\n",
        "- Inference using pre-trained models\n",
        "- Download, register and visualize COCO Format Dataset\n",
        "- Configure, train and evaluate model using custom COCO Format Dataset\n",
        "\n",
        "**Preparing a Custom Dataset**\n",
        "\n",
        "In this tutorial, we will utilize an open source computer vision dataset from one of the 100,000+ available on [Roboflow Universe](https://universe.roboflow.com).\n",
        "\n",
        "If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 150k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to Detectron2), training, deploying, and improving their datasets/models.\n",
        "\n",
        "Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset. Make sure to select **Instance Segmentation** Option, If you want to create your own dataset on roboflow\n",
        "\n",
        "Useful Dataset Links\n",
        "\n",
        "* [Helmet Instace Segmentation ](https://universe.roboflow.com/computer-vision-hx9i9/helmet_polygon_v2/dataset/4)\n",
        "\n",
        "* [PCB Board Instance Segmentation](https://universe.roboflow.com/chip/pcb_segmentation_yolov7/dataset/17)\n",
        "\n",
        "* [Fire Segmentation Instance Segmentation](https://universe.roboflow.com/fire-instance-segmentation/fire-detection-pr6nj/dataset/1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DwluqC5ID2"
      },
      "source": [
        "## Before you start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZBUwM3tyFWS"
      },
      "source": [
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iil0J4nTHHb_",
        "outputId": "5cb62412-fd04-472f-cd51-c1327558c481"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MJ8SshpLaU3"
      },
      "source": [
        "## Install Detectron2 and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM1JmUCQLdKp",
        "outputId": "b9027f79-6b5d-4eb7-ef65-d5019ff6c74b"
      },
      "outputs": [],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V8w1ew59buh"
      },
      "source": [
        "Now is a good time to confirm that we have the right versions of the libraries at our disposal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqCNglJXRro5",
        "outputId": "0aa2b469-8b0b-4feb-c2ee-959cda50ea73"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIEKfPKFmW54"
      },
      "outputs": [],
      "source": [
        "# COMMON LIBRARIES\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# DATA SET PREPARATION AND LOADING\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# VISUALIZATION\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "# CONFIGURATION\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# EVALUATION\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# TRAINING\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOszeLVlErvk"
      },
      "source": [
        "## Run a Pre-trained Detectron2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L-N75aD_hlK"
      },
      "source": [
        "Before you start training, it's a good idea to check that everything is working properly. The best way to do this is to perform inference using a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "T8sfLDV7FTYD",
        "outputId": "0e8eea7a-6407-4cb5-a7b8-6f4997bacde0"
      },
      "outputs": [],
      "source": [
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
        "image = cv2.imread(\"./input.jpg\")\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha0Lkah6G1NB",
        "outputId": "2d64c447-680b-4503-da9a-5e5ff055e97c"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQVt8iKoJ8s_",
        "outputId": "2818d5df-4ad7-4bfc-b9a3-3aed92ea6f83"
      },
      "outputs": [],
      "source": [
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "4fDUddSmKM-W",
        "outputId": "eb5a013e-0534-4195-9b17-4efb886ad932"
      },
      "outputs": [],
      "source": [
        "visualizer = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFkJOTWvxu6G"
      },
      "source": [
        "## COCO Format Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP3vux5vnCVn"
      },
      "source": [
        "### Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaohq2orBkCC"
      },
      "source": [
        "We use `football-pitch-segmentation` dataset as example. Feel free to visit [Roboflow Universe](https://universe.roboflow.com/), and select any other Instance Segmentation dataset. Make sure to download the dataset in correct - `COCO Segmentation` format. \n",
        "\n",
        "Structure of your dataset should look like this:\n",
        "\n",
        "```\n",
        "dataset-directory/\n",
        "├─ README.dataset.txt\n",
        "├─ README.roboflow.txt\n",
        "├─ train\n",
        "│  ├─ train-image-1.jpg\n",
        "│  ├─ train-image-1.jpg\n",
        "│  ├─ ...\n",
        "│  └─ _annotations.coco.json\n",
        "├─ test\n",
        "│  ├─ test-image-1.jpg\n",
        "│  ├─ test-image-1.jpg\n",
        "│  ├─ ...\n",
        "│  └─ _annotations.coco.json\n",
        "└─ valid\n",
        "   ├─ valid-image-1.jpg\n",
        "   ├─ valid-image-1.jpg\n",
        "   ├─ ...\n",
        "   └─ _annotations.coco.json\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grFIdy8ynP-7",
        "outputId": "d05be873-4ac3-4d10-d88b-fa053a263c90"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"RovqaIFPpcekpUVWjRke\")\n",
        "project = rf.workspace(\"tank-5yib6\").project(\"loader.ramp\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"coco-segmentation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoB31yi4AoYs"
      },
      "source": [
        "### Register"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HopUGOyW853G"
      },
      "source": [
        "When you use Detectron2, before you actually train the model you need to [register it](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-coco-format-dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbI2PNEZF3sU"
      },
      "outputs": [],
      "source": [
        "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jntOI8GJG2ks"
      },
      "outputs": [],
      "source": [
        "# TRAIN SET\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# TEST SET\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
        "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
        "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TEST_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=TEST_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# VALID SET\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=VALID_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=VALID_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOCY1UWNCtnq"
      },
      "source": [
        "We can now confirm that our custom dataset was correctly registered using [MetadataCatalog](https://detectron2.readthedocs.io/en/latest/modules/data.html#detectron2.data.MetadataCatalog)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR8ha4EHCkA-",
        "outputId": "6506603a-3742-43ee-af5d-7f842426d25d"
      },
      "outputs": [],
      "source": [
        "[\n",
        "    data_set\n",
        "    for data_set\n",
        "    in MetadataCatalog.list()\n",
        "    if data_set.startswith(DATA_SET_NAME)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDpU2L3UL922"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Bd_-oCA90a"
      },
      "source": [
        "Let's take a look at single entry from out train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "eE0anblvMGJx",
        "outputId": "b5db94b3-faf0-4c64-9717-fa906c4b76db"
      },
      "outputs": [],
      "source": [
        "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "\n",
        "dataset_entry = dataset_train[0]\n",
        "image = cv2.imread(dataset_entry[\"file_name\"])\n",
        "\n",
        "visualizer = Visualizer(\n",
        "    image[:, :, ::-1],\n",
        "    metadata=metadata, \n",
        "    scale=0.8, \n",
        "    instance_mode=ColorMode.IMAGE_BW\n",
        ")\n",
        "\n",
        "out = visualizer.draw_dataset_dict(dataset_entry)\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GavGRHy2M7Hb"
      },
      "source": [
        "## Train Model Using Custom COCO Format Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ3g-l56NMOY"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krCm2L_lNC83"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
        "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
        "MAX_ITER = 2000\n",
        "EVAL_PERIOD = 200\n",
        "BASE_LR = 0.001\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# OUTPUT DIR\n",
        "OUTPUT_DIR_PATH = os.path.join(\n",
        "    DATA_SET_NAME, \n",
        "    ARCHITECTURE, \n",
        "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        ")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxQU8JrgOD73"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
        "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
        "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.INPUT.MASK_FORMAT='bitmask'\n",
        "cfg.SOLVER.BASE_LR = BASE_LR\n",
        "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
        "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch-_5aCuXWj9"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S8y2W2AQvJq",
        "outputId": "36fe2d26-1118-4748-fff1-18a86d873970"
      },
      "outputs": [],
      "source": [
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XMPKQ28GRna"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $OUTPUT_DIR_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flInE1L-XTfx"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsByFDFbQwLi"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hmAcBbpXX-Rh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)\n",
        "\n",
        "for d in dataset_valid:\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(img)\n",
        "    \n",
        "    visualizer = Visualizer(\n",
        "        img[:, :, ::-1],\n",
        "        metadata=metadata, \n",
        "        scale=0.8, \n",
        "        instance_mode=ColorMode.IMAGE_BW\n",
        "    )\n",
        "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYGk-zJz4mQF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
