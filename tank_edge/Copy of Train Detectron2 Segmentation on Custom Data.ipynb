{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZBUwM3tyFWS"
   },
   "source": [
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 30 16:19:35 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.85                 Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P0             26W /  100W |       0MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MJ8SshpLaU3"
   },
   "source": [
    "## Install Detectron2 and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:27.100950Z",
     "start_time": "2024-06-25T07:59:43.324225Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51415,
     "status": "ok",
     "timestamp": 1719261763571,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "fM1JmUCQLdKp",
    "outputId": "cb684e1a-65eb-4798-eb32-28ef5b785883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to c:\\users\\daanish mittal\\appdata\\local\\temp\\pip-req-build-2bh46ino\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Daanish Mittal\\AppData\\Local\\Temp\\pip-req-build-2bh46ino\\setup.py\", line 10, in <module>\n",
      "        import torch\n",
      "    ModuleNotFoundError: No module named 'torch'\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Daanish Mittal\\AppData\\Local\\Temp\\pip-req-build-2bh46ino\\\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V8w1ew59buh"
   },
   "source": [
    "Now is a good time to confirm that we have the right versions of the libraries at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4612,
     "status": "error",
     "timestamp": 1719261915922,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "sqCNglJXRro5",
    "outputId": "3f148ff1-b579-4dfa-c1f0-adb5bdda4c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: iopath<0.1.10,>=0.1.7 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: portalocker in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: pywin32>=226; platform_system == \"Windows\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from portalocker->iopath<0.1.10,>=0.1.7) (305)\n",
      "Requirement already satisfied, skipping upgrade: colorama; platform_system == \"Windows\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->iopath<0.1.10,>=0.1.7) (0.4.5)\n",
      "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.7\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->iopath<0.1.10,>=0.1.7) (5.4.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-resources; python_version < \"3.7\"->tqdm->iopath<0.1.10,>=0.1.7) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.105\n",
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"iopath<0.1.10,>=0.1.7\"\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "import pkg_resources\n",
    "print(\"detectron2:\", pkg_resources.get_distribution(\"detectron2\").version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:40.273497Z",
     "start_time": "2024-06-25T08:00:37.778861Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "error",
     "timestamp": 1719261789459,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "DIEKfPKFmW54",
    "outputId": "1eae8bc5-084a-4dd2-bcdd-00efdcfc6330"
   },
   "outputs": [],
   "source": [
    "# COMMON LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# TRAINING\n",
    "from detectron2.engine import DefaultTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOszeLVlErvk"
   },
   "source": [
    "## Run a Pre-trained Detectron2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:01:49.176003Z",
     "start_time": "2024-06-25T08:00:40.278498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 2681,
     "status": "ok",
     "timestamp": 1668002463033,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "T8sfLDV7FTYD",
    "outputId": "0e8eea7a-6407-4cb5-a7b8-6f4997bacde0"
   },
   "outputs": [],
   "source": [
    "# !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "# image = cv2.imread(\"./input.jpg\")\n",
    "# cv2.imshow('Display Window', image)  # 'Display Window' is the name of the window\n",
    "# cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "# cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:05.116019Z",
     "start_time": "2024-06-25T08:01:49.193280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Collecting torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement torch (from versions: )\n",
      "No matching distribution found for torch\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFkJOTWvxu6G"
   },
   "source": [
    "## COCO Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:42.536499Z",
     "start_time": "2024-06-25T08:02:25.897211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14044,
     "status": "ok",
     "timestamp": 1668003461405,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "grFIdy8ynP-7",
    "outputId": "d05be873-4ac3-4d10-d88b-fa053a263c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached https://files.pythonhosted.org/packages/99/f2/8349482b1cb7d408cd8673efaa1b51e7bd657f95b679de27f89e333f1388/roboflow-1.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (4.64.1)\n",
      "Collecting supervision (from roboflow)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement supervision (from roboflow) (from versions: )\n",
      "No matching distribution found for supervision (from roboflow)\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"RovqaIFPpcekpUVWjRke\")\n",
    "project = rf.workspace(\"tank-5yib6\").project(\"tank_edges\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco-segmentation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoB31yi4AoYs"
   },
   "source": [
    "### Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HopUGOyW853G"
   },
   "source": [
    "When you use Detectron2, before you actually train the model you need to [register it](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-coco-format-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:35.787965Z",
     "start_time": "2024-06-25T08:05:35.780944Z"
    },
    "id": "KbI2PNEZF3sU"
   },
   "outputs": [],
   "source": [
    "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
    "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:38.778124Z",
     "start_time": "2024-06-25T08:05:38.650598Z"
    },
    "id": "jntOI8GJG2ks"
   },
   "outputs": [],
   "source": [
    "# TRAIN SET\n",
    "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
    "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
    "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TRAIN_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# TEST SET\n",
    "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
    "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
    "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TEST_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# VALID SET\n",
    "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
    "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
    "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=VALID_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=VALID_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCY1UWNCtnq"
   },
   "source": [
    "We can now confirm that our custom dataset was correctly registered using [MetadataCatalog](https://detectron2.readthedocs.io/en/latest/modules/data.html#detectron2.data.MetadataCatalog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:42.883439Z",
     "start_time": "2024-06-25T08:05:42.865442Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1668003586610,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "LR8ha4EHCkA-",
    "outputId": "6506603a-3742-43ee-af5d-7f842426d25d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tank_edges-train', 'tank_edges-test', 'tank_edges-valid']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    data_set\n",
    "    for data_set\n",
    "    in MetadataCatalog.list()\n",
    "    if data_set.startswith(DATA_SET_NAME)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpU2L3UL922"
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Bd_-oCA90a"
   },
   "source": [
    "Let's take a look at single entry from out train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:47.307052Z",
     "start_time": "2024-06-25T08:05:45.996186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1668003725711,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "eE0anblvMGJx",
    "outputId": "b5db94b3-faf0-4c64-9717-fa906c4b76db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "\n",
    "dataset_entry = dataset_train[0]\n",
    "image = cv2.imread(dataset_entry[\"file_name\"])\n",
    "\n",
    "visualizer = Visualizer(\n",
    "    image[:, :, ::-1],\n",
    "    metadata=metadata,\n",
    "    scale=0.5,\n",
    "    instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "\n",
    "out = visualizer.draw_dataset_dict(dataset_entry)\n",
    "cv2.imshow(\"visualize\",out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GavGRHy2M7Hb"
   },
   "source": [
    "## Train Model Using Custom COCO Format Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ3g-l56NMOY"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.228994Z",
     "start_time": "2024-06-25T08:03:04.203266Z"
    },
    "id": "krCm2L_lNC83"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "MAX_ITER = 3000\n",
    "EVAL_PERIOD = 200\n",
    "BASE_LR = 0.0001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# OUTPUT DIRa\n",
    "OUTPUT_DIR_PATH = os.path.join(\n",
    "    DATA_SET_NAME,\n",
    "    ARCHITECTURE,\n",
    "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.291051Z",
     "start_time": "2024-06-25T08:03:04.233685Z"
    },
    "id": "lxQU8JrgOD73"
   },
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "# cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "# cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "# cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "# cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "# cfg.SOLVER.BASE_LR = BASE_LR\n",
    "# cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "# cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 # Default batch size per image\n",
    "\n",
    "# Adjusting batch size and image size for GPU with 6GB VRAM\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # Overall batch size\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)  # Adjusted to fit memory constraints\n",
    "cfg.INPUT.MIN_SIZE_TEST = 800\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1333\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.DATALOADER.NUM_WORKERS = 3\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n",
    "\n",
    "# Save config for future reference\n",
    "with open(os.path.join(OUTPUT_DIR_PATH, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch-_5aCuXWj9"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:15.015389Z",
     "start_time": "2024-06-25T08:03:04.296073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961595,
     "status": "ok",
     "timestamp": 1668005381143,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "7S8y2W2AQvJq",
    "outputId": "36fe2d26-1118-4748-fff1-18a86d873970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/30 17:35:25 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:35:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:35:25 d2.data.datasets.coco]: \u001b[0mLoaded 180 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\train\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:35:25 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 180 images left.\n",
      "\u001b[32m[06/30 17:35:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[06/30 17:35:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[06/30 17:35:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:35:25 d2.data.common]: \u001b[0mSerializing 180 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:35:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[32m[06/30 17:35:25 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:35:25 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[06/30 17:35:26 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/30 17:35:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[06/30 17:35:45 d2.utils.events]: \u001b[0m eta: 0:38:48  iter: 19  total_loss: 2.363  loss_cls: 1.528  loss_box_reg: 0.1288  loss_mask: 0.6882  loss_rpn_cls: 0.004117  loss_rpn_loc: 0.002746    time: 0.7355  last_time: 0.8767  data_time: 0.1628  last_data_time: 0.0014   lr: 1.9981e-06  max_mem: 4921M\n",
      "\u001b[32m[06/30 17:35:59 d2.utils.events]: \u001b[0m eta: 0:37:24  iter: 39  total_loss: 2.264  loss_cls: 1.468  loss_box_reg: 0.1211  loss_mask: 0.6761  loss_rpn_cls: 0.002349  loss_rpn_loc: 0.002399    time: 0.7238  last_time: 0.7751  data_time: 0.0017  last_data_time: 0.0026   lr: 3.9961e-06  max_mem: 4921M\n",
      "\u001b[32m[06/30 17:36:13 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 59  total_loss: 2.053  loss_cls: 1.285  loss_box_reg: 0.1116  loss_mask: 0.6493  loss_rpn_cls: 0.001093  loss_rpn_loc: 0.002969    time: 0.7161  last_time: 0.4074  data_time: 0.0018  last_data_time: 0.0016   lr: 5.9941e-06  max_mem: 4921M\n",
      "\u001b[32m[06/30 17:36:26 d2.utils.events]: \u001b[0m eta: 0:36:18  iter: 79  total_loss: 1.789  loss_cls: 1.028  loss_box_reg: 0.111  loss_mask: 0.6067  loss_rpn_cls: 0.005326  loss_rpn_loc: 0.003031    time: 0.7029  last_time: 0.9046  data_time: 0.0019  last_data_time: 0.0015   lr: 7.9921e-06  max_mem: 4921M\n",
      "\u001b[32m[06/30 17:36:47 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 99  total_loss: 1.486  loss_cls: 0.8272  loss_box_reg: 0.1045  loss_mask: 0.5674  loss_rpn_cls: 0.002615  loss_rpn_loc: 0.002988    time: 0.7717  last_time: 1.2493  data_time: 0.0026  last_data_time: 0.0018   lr: 9.9901e-06  max_mem: 4921M\n",
      "\u001b[32m[06/30 17:37:07 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 119  total_loss: 1.285  loss_cls: 0.6203  loss_box_reg: 0.1251  loss_mask: 0.5235  loss_rpn_cls: 0.002663  loss_rpn_loc: 0.003716    time: 0.8147  last_time: 0.5485  data_time: 0.0016  last_data_time: 0.0011   lr: 1.1988e-05  max_mem: 4954M\n",
      "\u001b[32m[06/30 17:37:25 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 139  total_loss: 1.048  loss_cls: 0.4462  loss_box_reg: 0.1198  loss_mask: 0.4863  loss_rpn_cls: 0.002586  loss_rpn_loc: 0.002985    time: 0.8209  last_time: 0.7661  data_time: 0.0018  last_data_time: 0.0017   lr: 1.3986e-05  max_mem: 4954M\n",
      "\u001b[32m[06/30 17:37:43 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 159  total_loss: 0.8528  loss_cls: 0.2858  loss_box_reg: 0.1184  loss_mask: 0.4336  loss_rpn_cls: 0.002879  loss_rpn_loc: 0.002251    time: 0.8354  last_time: 0.9822  data_time: 0.0019  last_data_time: 0.0017   lr: 1.5984e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:38:02 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 179  total_loss: 0.7538  loss_cls: 0.2411  loss_box_reg: 0.1212  loss_mask: 0.3874  loss_rpn_cls: 0.00234  loss_rpn_loc: 0.002549    time: 0.8439  last_time: 0.6656  data_time: 0.0016  last_data_time: 0.0015   lr: 1.7982e-05  max_mem: 4968M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:38:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:38:22 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:38:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:38:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:38:22 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:38:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:38:22 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:38:22 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 199  total_loss: 0.6583  loss_cls: 0.1858  loss_box_reg: 0.1272  loss_mask: 0.3305  loss_rpn_cls: 0.000749  loss_rpn_loc: 0.00199    time: 0.8623  last_time: 0.5991  data_time: 0.0018  last_data_time: 0.0013   lr: 1.998e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:38:41 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 219  total_loss: 0.6234  loss_cls: 0.175  loss_box_reg: 0.1225  loss_mask: 0.3129  loss_rpn_cls: 0.002019  loss_rpn_loc: 0.002127    time: 0.8698  last_time: 0.9867  data_time: 0.0016  last_data_time: 0.0016   lr: 2.1978e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:39:00 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 239  total_loss: 0.5759  loss_cls: 0.1445  loss_box_reg: 0.1424  loss_mask: 0.2872  loss_rpn_cls: 0.001727  loss_rpn_loc: 0.00222    time: 0.8749  last_time: 0.5613  data_time: 0.0017  last_data_time: 0.0028   lr: 2.3976e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:39:19 d2.utils.events]: \u001b[0m eta: 0:41:46  iter: 259  total_loss: 0.5353  loss_cls: 0.1294  loss_box_reg: 0.128  loss_mask: 0.2763  loss_rpn_cls: 0.0009362  loss_rpn_loc: 0.002597    time: 0.8821  last_time: 0.9776  data_time: 0.0016  last_data_time: 0.0021   lr: 2.5974e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:39:39 d2.utils.events]: \u001b[0m eta: 0:43:26  iter: 279  total_loss: 0.4728  loss_cls: 0.1234  loss_box_reg: 0.1177  loss_mask: 0.2356  loss_rpn_cls: 0.000605  loss_rpn_loc: 0.002306    time: 0.8890  last_time: 0.9897  data_time: 0.0016  last_data_time: 0.0016   lr: 2.7972e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:39:58 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 299  total_loss: 0.4452  loss_cls: 0.1178  loss_box_reg: 0.115  loss_mask: 0.1989  loss_rpn_cls: 0.0008675  loss_rpn_loc: 0.001688    time: 0.8945  last_time: 0.9744  data_time: 0.0020  last_data_time: 0.0015   lr: 2.997e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:40:13 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 319  total_loss: 0.4371  loss_cls: 0.1097  loss_box_reg: 0.132  loss_mask: 0.1754  loss_rpn_cls: 0.0003658  loss_rpn_loc: 0.001623    time: 0.8857  last_time: 0.4799  data_time: 0.0019  last_data_time: 0.0021   lr: 3.1968e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:40:28 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 339  total_loss: 0.3819  loss_cls: 0.09899  loss_box_reg: 0.1237  loss_mask: 0.146  loss_rpn_cls: 0.0006995  loss_rpn_loc: 0.002062    time: 0.8768  last_time: 0.3555  data_time: 0.0017  last_data_time: 0.0019   lr: 3.3966e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:40:43 d2.utils.events]: \u001b[0m eta: 0:38:28  iter: 359  total_loss: 0.369  loss_cls: 0.08798  loss_box_reg: 0.1357  loss_mask: 0.1439  loss_rpn_cls: 0.0008564  loss_rpn_loc: 0.001766    time: 0.8694  last_time: 0.4398  data_time: 0.0016  last_data_time: 0.0016   lr: 3.5964e-05  max_mem: 4968M\n",
      "\u001b[32m[06/30 17:40:56 d2.utils.events]: \u001b[0m eta: 0:37:33  iter: 379  total_loss: 0.3358  loss_cls: 0.08244  loss_box_reg: 0.1291  loss_mask: 0.1218  loss_rpn_cls: 0.0009758  loss_rpn_loc: 0.001544    time: 0.8588  last_time: 0.3680  data_time: 0.0016  last_data_time: 0.0013   lr: 3.7962e-05  max_mem: 4968M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:41:10 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:41:10 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:41:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:41:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:41:10 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:41:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:41:10 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:41:11 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 399  total_loss: 0.3217  loss_cls: 0.08005  loss_box_reg: 0.1186  loss_mask: 0.1158  loss_rpn_cls: 0.001008  loss_rpn_loc: 0.002257    time: 0.8519  last_time: 0.7776  data_time: 0.0017  last_data_time: 0.0015   lr: 3.996e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:41:26 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 419  total_loss: 0.3203  loss_cls: 0.07341  loss_box_reg: 0.131  loss_mask: 0.1056  loss_rpn_cls: 0.0003777  loss_rpn_loc: 0.002003    time: 0.8486  last_time: 0.8686  data_time: 0.0017  last_data_time: 0.0016   lr: 4.1958e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:41:40 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 439  total_loss: 0.2984  loss_cls: 0.0676  loss_box_reg: 0.1345  loss_mask: 0.08811  loss_rpn_cls: 0.0003766  loss_rpn_loc: 0.002257    time: 0.8422  last_time: 0.7350  data_time: 0.0018  last_data_time: 0.0013   lr: 4.3956e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:41:55 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 459  total_loss: 0.2905  loss_cls: 0.06298  loss_box_reg: 0.1316  loss_mask: 0.08954  loss_rpn_cls: 0.0004992  loss_rpn_loc: 0.001975    time: 0.8381  last_time: 0.7416  data_time: 0.0018  last_data_time: 0.0016   lr: 4.5954e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:42:09 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 479  total_loss: 0.2593  loss_cls: 0.05218  loss_box_reg: 0.1314  loss_mask: 0.07205  loss_rpn_cls: 0.0001706  loss_rpn_loc: 0.002393    time: 0.8316  last_time: 0.4516  data_time: 0.0016  last_data_time: 0.0013   lr: 4.7952e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:42:23 d2.utils.events]: \u001b[0m eta: 0:34:27  iter: 499  total_loss: 0.25  loss_cls: 0.05153  loss_box_reg: 0.1241  loss_mask: 0.06605  loss_rpn_cls: 0.0003951  loss_rpn_loc: 0.002078    time: 0.8272  last_time: 0.7678  data_time: 0.0016  last_data_time: 0.0015   lr: 4.995e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:42:37 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 519  total_loss: 0.2532  loss_cls: 0.04618  loss_box_reg: 0.1312  loss_mask: 0.06882  loss_rpn_cls: 8.278e-05  loss_rpn_loc: 0.002567    time: 0.8212  last_time: 0.7803  data_time: 0.0016  last_data_time: 0.0015   lr: 5.1948e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:42:50 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 539  total_loss: 0.234  loss_cls: 0.04425  loss_box_reg: 0.1283  loss_mask: 0.0609  loss_rpn_cls: 0.0001483  loss_rpn_loc: 0.002355    time: 0.8150  last_time: 0.7591  data_time: 0.0016  last_data_time: 0.0018   lr: 5.3946e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:43:05 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 559  total_loss: 0.2218  loss_cls: 0.0372  loss_box_reg: 0.1214  loss_mask: 0.05633  loss_rpn_cls: 0.0001258  loss_rpn_loc: 0.002505    time: 0.8122  last_time: 0.8779  data_time: 0.0016  last_data_time: 0.0015   lr: 5.5944e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:43:18 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 579  total_loss: 0.2063  loss_cls: 0.03481  loss_box_reg: 0.1121  loss_mask: 0.05199  loss_rpn_cls: 0.0001142  loss_rpn_loc: 0.002155    time: 0.8074  last_time: 0.7590  data_time: 0.0016  last_data_time: 0.0017   lr: 5.7942e-05  max_mem: 5003M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:43:32 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:43:32 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:43:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:43:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:43:32 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:43:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:43:32 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:43:32 d2.utils.events]: \u001b[0m eta: 0:30:59  iter: 599  total_loss: 0.2042  loss_cls: 0.0296  loss_box_reg: 0.1147  loss_mask: 0.05459  loss_rpn_cls: 8.781e-05  loss_rpn_loc: 0.002411    time: 0.8034  last_time: 0.7555  data_time: 0.0016  last_data_time: 0.0016   lr: 5.994e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:43:46 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 619  total_loss: 0.2024  loss_cls: 0.03022  loss_box_reg: 0.1072  loss_mask: 0.05645  loss_rpn_cls: 3.929e-05  loss_rpn_loc: 0.002225    time: 0.7994  last_time: 0.4144  data_time: 0.0017  last_data_time: 0.0014   lr: 6.1938e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:44:00 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 639  total_loss: 0.1694  loss_cls: 0.02316  loss_box_reg: 0.0938  loss_mask: 0.04881  loss_rpn_cls: 2.842e-05  loss_rpn_loc: 0.002321    time: 0.7975  last_time: 0.7602  data_time: 0.0016  last_data_time: 0.0013   lr: 6.3936e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:44:14 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 659  total_loss: 0.1737  loss_cls: 0.02607  loss_box_reg: 0.09126  loss_mask: 0.05012  loss_rpn_cls: 5.503e-05  loss_rpn_loc: 0.003285    time: 0.7938  last_time: 0.3511  data_time: 0.0016  last_data_time: 0.0019   lr: 6.5934e-05  max_mem: 5003M\n",
      "\u001b[32m[06/30 17:44:29 d2.utils.events]: \u001b[0m eta: 0:29:51  iter: 679  total_loss: 0.1517  loss_cls: 0.02212  loss_box_reg: 0.07899  loss_mask: 0.04837  loss_rpn_cls: 3.028e-05  loss_rpn_loc: 0.002433    time: 0.7921  last_time: 0.8773  data_time: 0.0016  last_data_time: 0.0014   lr: 6.7932e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:44:43 d2.utils.events]: \u001b[0m eta: 0:29:31  iter: 699  total_loss: 0.1355  loss_cls: 0.01803  loss_box_reg: 0.06668  loss_mask: 0.04657  loss_rpn_cls: 2.786e-05  loss_rpn_loc: 0.002832    time: 0.7895  last_time: 0.7379  data_time: 0.0016  last_data_time: 0.0020   lr: 6.993e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:44:56 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 719  total_loss: 0.1192  loss_cls: 0.01733  loss_box_reg: 0.05837  loss_mask: 0.04628  loss_rpn_cls: 1.88e-05  loss_rpn_loc: 0.002722    time: 0.7857  last_time: 0.8689  data_time: 0.0015  last_data_time: 0.0015   lr: 7.1928e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:45:11 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 739  total_loss: 0.1177  loss_cls: 0.01727  loss_box_reg: 0.05619  loss_mask: 0.04167  loss_rpn_cls: 4.404e-05  loss_rpn_loc: 0.002864    time: 0.7850  last_time: 0.9139  data_time: 0.0016  last_data_time: 0.0016   lr: 7.3926e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:45:25 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 759  total_loss: 0.1165  loss_cls: 0.01583  loss_box_reg: 0.0471  loss_mask: 0.0482  loss_rpn_cls: 2.971e-05  loss_rpn_loc: 0.003071    time: 0.7832  last_time: 0.8686  data_time: 0.0016  last_data_time: 0.0019   lr: 7.5924e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:45:39 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 779  total_loss: 0.105  loss_cls: 0.01839  loss_box_reg: 0.0406  loss_mask: 0.04153  loss_rpn_cls: 2.188e-05  loss_rpn_loc: 0.002715    time: 0.7812  last_time: 0.8673  data_time: 0.0016  last_data_time: 0.0015   lr: 7.7922e-05  max_mem: 5013M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:45:53 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:45:53 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:45:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:45:53 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:45:53 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:45:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:45:53 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:45:53 d2.utils.events]: \u001b[0m eta: 0:28:07  iter: 799  total_loss: 0.09717  loss_cls: 0.0134  loss_box_reg: 0.03935  loss_mask: 0.04178  loss_rpn_cls: 3.054e-05  loss_rpn_loc: 0.002447    time: 0.7790  last_time: 0.7417  data_time: 0.0017  last_data_time: 0.0015   lr: 7.992e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:46:09 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 819  total_loss: 0.09794  loss_cls: 0.01365  loss_box_reg: 0.03644  loss_mask: 0.04607  loss_rpn_cls: 3.054e-05  loss_rpn_loc: 0.002596    time: 0.7787  last_time: 0.4197  data_time: 0.0016  last_data_time: 0.0014   lr: 8.1918e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:46:23 d2.utils.events]: \u001b[0m eta: 0:27:37  iter: 839  total_loss: 0.09117  loss_cls: 0.01157  loss_box_reg: 0.03311  loss_mask: 0.04426  loss_rpn_cls: 1.413e-05  loss_rpn_loc: 0.002068    time: 0.7772  last_time: 0.8513  data_time: 0.0017  last_data_time: 0.0014   lr: 8.3916e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:46:37 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 859  total_loss: 0.08507  loss_cls: 0.01381  loss_box_reg: 0.03133  loss_mask: 0.03848  loss_rpn_cls: 3.542e-05  loss_rpn_loc: 0.002371    time: 0.7752  last_time: 0.4434  data_time: 0.0015  last_data_time: 0.0013   lr: 8.5914e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:46:51 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 879  total_loss: 0.07969  loss_cls: 0.01255  loss_box_reg: 0.03201  loss_mask: 0.03635  loss_rpn_cls: 5.139e-05  loss_rpn_loc: 0.00229    time: 0.7743  last_time: 0.7748  data_time: 0.0016  last_data_time: 0.0014   lr: 8.7912e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:47:06 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 899  total_loss: 0.07804  loss_cls: 0.008958  loss_box_reg: 0.02818  loss_mask: 0.03515  loss_rpn_cls: 1.682e-05  loss_rpn_loc: 0.002498    time: 0.7735  last_time: 0.4779  data_time: 0.0016  last_data_time: 0.0014   lr: 8.991e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:47:21 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 919  total_loss: 0.08457  loss_cls: 0.01286  loss_box_reg: 0.0261  loss_mask: 0.03954  loss_rpn_cls: 1.776e-05  loss_rpn_loc: 0.002373    time: 0.7727  last_time: 0.8600  data_time: 0.0016  last_data_time: 0.0016   lr: 9.1908e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:47:36 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 939  total_loss: 0.07671  loss_cls: 0.01102  loss_box_reg: 0.02592  loss_mask: 0.03656  loss_rpn_cls: 4.394e-06  loss_rpn_loc: 0.002    time: 0.7720  last_time: 0.7720  data_time: 0.0016  last_data_time: 0.0020   lr: 9.3906e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:47:51 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 959  total_loss: 0.08268  loss_cls: 0.01253  loss_box_reg: 0.02767  loss_mask: 0.03872  loss_rpn_cls: 5.444e-06  loss_rpn_loc: 0.001961    time: 0.7715  last_time: 0.9079  data_time: 0.0015  last_data_time: 0.0014   lr: 9.5904e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:48:05 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 979  total_loss: 0.07898  loss_cls: 0.01199  loss_box_reg: 0.0273  loss_mask: 0.03673  loss_rpn_cls: 1.77e-05  loss_rpn_loc: 0.002958    time: 0.7705  last_time: 0.7880  data_time: 0.0016  last_data_time: 0.0020   lr: 9.7902e-05  max_mem: 5013M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:48:19 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:48:19 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:48:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:48:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:48:19 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:48:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:48:19 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:48:19 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 999  total_loss: 0.07276  loss_cls: 0.01095  loss_box_reg: 0.02527  loss_mask: 0.03241  loss_rpn_cls: 1.095e-05  loss_rpn_loc: 0.002117    time: 0.7692  last_time: 0.4348  data_time: 0.0016  last_data_time: 0.0015   lr: 9.99e-05  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:48:33 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 1019  total_loss: 0.07842  loss_cls: 0.01187  loss_box_reg: 0.02373  loss_mask: 0.03876  loss_rpn_cls: 4.047e-06  loss_rpn_loc: 0.00206    time: 0.7680  last_time: 0.7706  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:48:48 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 1039  total_loss: 0.06778  loss_cls: 0.009186  loss_box_reg: 0.02463  loss_mask: 0.03456  loss_rpn_cls: 9.04e-06  loss_rpn_loc: 0.001747    time: 0.7671  last_time: 0.7399  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:49:02 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 1059  total_loss: 0.06661  loss_cls: 0.009856  loss_box_reg: 0.02332  loss_mask: 0.03618  loss_rpn_cls: 8.356e-06  loss_rpn_loc: 0.001842    time: 0.7660  last_time: 0.4490  data_time: 0.0015  last_data_time: 0.0013   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:49:17 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 1079  total_loss: 0.07217  loss_cls: 0.01285  loss_box_reg: 0.02084  loss_mask: 0.03835  loss_rpn_cls: 2.331e-06  loss_rpn_loc: 0.00203    time: 0.7652  last_time: 0.8518  data_time: 0.0017  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:49:31 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 1099  total_loss: 0.07022  loss_cls: 0.01205  loss_box_reg: 0.02398  loss_mask: 0.03259  loss_rpn_cls: 8.89e-06  loss_rpn_loc: 0.001605    time: 0.7643  last_time: 0.7705  data_time: 0.0016  last_data_time: 0.0012   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:49:43 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 1119  total_loss: 0.07219  loss_cls: 0.01064  loss_box_reg: 0.02157  loss_mask: 0.03477  loss_rpn_cls: 5.84e-06  loss_rpn_loc: 0.00188    time: 0.7618  last_time: 0.4607  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:49:57 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 1139  total_loss: 0.07421  loss_cls: 0.01085  loss_box_reg: 0.02105  loss_mask: 0.03679  loss_rpn_cls: 4.399e-06  loss_rpn_loc: 0.001819    time: 0.7605  last_time: 0.7808  data_time: 0.0015  last_data_time: 0.0016   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:50:11 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 1159  total_loss: 0.06451  loss_cls: 0.01065  loss_box_reg: 0.01882  loss_mask: 0.03104  loss_rpn_cls: 1.96e-05  loss_rpn_loc: 0.001579    time: 0.7596  last_time: 0.8362  data_time: 0.0015  last_data_time: 0.0014   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:50:25 d2.utils.events]: \u001b[0m eta: 0:23:10  iter: 1179  total_loss: 0.06699  loss_cls: 0.009914  loss_box_reg: 0.01873  loss_mask: 0.03413  loss_rpn_cls: 5.718e-06  loss_rpn_loc: 0.001951    time: 0.7585  last_time: 0.8571  data_time: 0.0015  last_data_time: 0.0017   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:50:40 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:50:40 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:50:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:50:40 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:50:40 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:50:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:50:40 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:50:40 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 1199  total_loss: 0.07342  loss_cls: 0.01186  loss_box_reg: 0.02325  loss_mask: 0.03098  loss_rpn_cls: 2.814e-06  loss_rpn_loc: 0.002022    time: 0.7580  last_time: 0.4428  data_time: 0.0015  last_data_time: 0.0013   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:50:55 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 1219  total_loss: 0.06938  loss_cls: 0.01097  loss_box_reg: 0.01918  loss_mask: 0.03628  loss_rpn_cls: 7.204e-06  loss_rpn_loc: 0.0017    time: 0.7580  last_time: 0.7491  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:51:08 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 1239  total_loss: 0.06218  loss_cls: 0.01091  loss_box_reg: 0.01865  loss_mask: 0.03098  loss_rpn_cls: 2.594e-06  loss_rpn_loc: 0.00172    time: 0.7564  last_time: 0.4121  data_time: 0.0016  last_data_time: 0.0019   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:51:22 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 1259  total_loss: 0.07062  loss_cls: 0.01052  loss_box_reg: 0.02064  loss_mask: 0.03799  loss_rpn_cls: 6.389e-06  loss_rpn_loc: 0.001529    time: 0.7553  last_time: 0.7597  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:51:36 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 1279  total_loss: 0.07239  loss_cls: 0.01084  loss_box_reg: 0.02147  loss_mask: 0.03801  loss_rpn_cls: 8.89e-06  loss_rpn_loc: 0.001609    time: 0.7546  last_time: 0.7367  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:51:49 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 1299  total_loss: 0.06221  loss_cls: 0.0112  loss_box_reg: 0.01965  loss_mask: 0.03016  loss_rpn_cls: 3.442e-06  loss_rpn_loc: 0.001547    time: 0.7529  last_time: 0.7796  data_time: 0.0016  last_data_time: 0.0019   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:52:03 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 1319  total_loss: 0.06366  loss_cls: 0.01152  loss_box_reg: 0.01796  loss_mask: 0.03217  loss_rpn_cls: 8.046e-06  loss_rpn_loc: 0.001769    time: 0.7523  last_time: 0.8683  data_time: 0.0015  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:52:18 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 1339  total_loss: 0.06416  loss_cls: 0.0109  loss_box_reg: 0.01812  loss_mask: 0.03293  loss_rpn_cls: 1.825e-06  loss_rpn_loc: 0.001631    time: 0.7521  last_time: 0.7768  data_time: 0.0017  last_data_time: 0.0026   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:52:32 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 1359  total_loss: 0.06405  loss_cls: 0.01103  loss_box_reg: 0.01913  loss_mask: 0.03125  loss_rpn_cls: 3.019e-06  loss_rpn_loc: 0.002013    time: 0.7512  last_time: 0.8687  data_time: 0.0015  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:52:46 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 1379  total_loss: 0.06242  loss_cls: 0.01063  loss_box_reg: 0.01783  loss_mask: 0.03272  loss_rpn_cls: 3.209e-06  loss_rpn_loc: 0.001611    time: 0.7508  last_time: 0.7717  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:53:02 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:53:02 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:53:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:53:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:53:02 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:53:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:53:02 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:53:02 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 1399  total_loss: 0.06682  loss_cls: 0.011  loss_box_reg: 0.01615  loss_mask: 0.03507  loss_rpn_cls: 4.886e-06  loss_rpn_loc: 0.001829    time: 0.7511  last_time: 0.7409  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:53:15 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 1419  total_loss: 0.05908  loss_cls: 0.01021  loss_box_reg: 0.01867  loss_mask: 0.02921  loss_rpn_cls: 4.256e-06  loss_rpn_loc: 0.001536    time: 0.7501  last_time: 0.7403  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:53:29 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 1439  total_loss: 0.05437  loss_cls: 0.01026  loss_box_reg: 0.01609  loss_mask: 0.02504  loss_rpn_cls: 3.908e-06  loss_rpn_loc: 0.001836    time: 0.7490  last_time: 0.7361  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:53:43 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 1459  total_loss: 0.05578  loss_cls: 0.01019  loss_box_reg: 0.01507  loss_mask: 0.02724  loss_rpn_cls: 2.757e-06  loss_rpn_loc: 0.001495    time: 0.7486  last_time: 0.8675  data_time: 0.0015  last_data_time: 0.0014   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:53:56 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 1479  total_loss: 0.0598  loss_cls: 0.008727  loss_box_reg: 0.01804  loss_mask: 0.03186  loss_rpn_cls: 1.25e-06  loss_rpn_loc: 0.001634    time: 0.7469  last_time: 0.3692  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:54:10 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 1499  total_loss: 0.05847  loss_cls: 0.009822  loss_box_reg: 0.01599  loss_mask: 0.02992  loss_rpn_cls: 1.98e-06  loss_rpn_loc: 0.001392    time: 0.7466  last_time: 0.8432  data_time: 0.0015  last_data_time: 0.0016   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:54:25 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 1519  total_loss: 0.05828  loss_cls: 0.009608  loss_box_reg: 0.01554  loss_mask: 0.0301  loss_rpn_cls: 2.149e-06  loss_rpn_loc: 0.001291    time: 0.7465  last_time: 0.8696  data_time: 0.0017  last_data_time: 0.0015   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:54:40 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 1539  total_loss: 0.06282  loss_cls: 0.008794  loss_box_reg: 0.01661  loss_mask: 0.03313  loss_rpn_cls: 8.539e-06  loss_rpn_loc: 0.001894    time: 0.7466  last_time: 0.8500  data_time: 0.0016  last_data_time: 0.0018   lr: 0.0001  max_mem: 5013M\n",
      "\u001b[32m[06/30 17:54:55 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 1559  total_loss: 0.06066  loss_cls: 0.00927  loss_box_reg: 0.01719  loss_mask: 0.03266  loss_rpn_cls: 2.35e-06  loss_rpn_loc: 0.001657    time: 0.7464  last_time: 0.8786  data_time: 0.0017  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:55:09 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 1579  total_loss: 0.06065  loss_cls: 0.0102  loss_box_reg: 0.01714  loss_mask: 0.03166  loss_rpn_cls: 1.163e-06  loss_rpn_loc: 0.00142    time: 0.7459  last_time: 0.7497  data_time: 0.0015  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:55:23 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:55:23 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:55:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:55:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:55:23 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:55:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:55:23 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:55:23 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 1599  total_loss: 0.05301  loss_cls: 0.0103  loss_box_reg: 0.01695  loss_mask: 0.02744  loss_rpn_cls: 1.643e-06  loss_rpn_loc: 0.001447    time: 0.7453  last_time: 0.4506  data_time: 0.0015  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:55:36 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 1619  total_loss: 0.05971  loss_cls: 0.009299  loss_box_reg: 0.01455  loss_mask: 0.03194  loss_rpn_cls: 1.228e-06  loss_rpn_loc: 0.001509    time: 0.7439  last_time: 0.3671  data_time: 0.0015  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:55:51 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 1639  total_loss: 0.05469  loss_cls: 0.009931  loss_box_reg: 0.01487  loss_mask: 0.02764  loss_rpn_cls: 2.42e-06  loss_rpn_loc: 0.001304    time: 0.7441  last_time: 0.7854  data_time: 0.0015  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:56:04 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 1659  total_loss: 0.05418  loss_cls: 0.009663  loss_box_reg: 0.01488  loss_mask: 0.02849  loss_rpn_cls: 3.488e-06  loss_rpn_loc: 0.001315    time: 0.7430  last_time: 0.7445  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:56:18 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 1679  total_loss: 0.05501  loss_cls: 0.009842  loss_box_reg: 0.01537  loss_mask: 0.02868  loss_rpn_cls: 2.259e-06  loss_rpn_loc: 0.001485    time: 0.7426  last_time: 0.4509  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:56:30 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 1699  total_loss: 0.06099  loss_cls: 0.007976  loss_box_reg: 0.01619  loss_mask: 0.03542  loss_rpn_cls: 1.191e-06  loss_rpn_loc: 0.001377    time: 0.7410  last_time: 0.4744  data_time: 0.0016  last_data_time: 0.0022   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:56:44 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 1719  total_loss: 0.0541  loss_cls: 0.008651  loss_box_reg: 0.01553  loss_mask: 0.02935  loss_rpn_cls: 2.761e-06  loss_rpn_loc: 0.001262    time: 0.7407  last_time: 0.4457  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:56:58 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 1739  total_loss: 0.05515  loss_cls: 0.01001  loss_box_reg: 0.01799  loss_mask: 0.02651  loss_rpn_cls: 1.681e-06  loss_rpn_loc: 0.001784    time: 0.7398  last_time: 0.4412  data_time: 0.0016  last_data_time: 0.0021   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:57:13 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 1759  total_loss: 0.05524  loss_cls: 0.01099  loss_box_reg: 0.01492  loss_mask: 0.02675  loss_rpn_cls: 6.002e-07  loss_rpn_loc: 0.001404    time: 0.7402  last_time: 0.8476  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:57:28 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 1779  total_loss: 0.05491  loss_cls: 0.007593  loss_box_reg: 0.01535  loss_mask: 0.03103  loss_rpn_cls: 2.532e-06  loss_rpn_loc: 0.001558    time: 0.7400  last_time: 0.7345  data_time: 0.0016  last_data_time: 0.0026   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:57:43 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 17:57:43 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 17:57:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 17:57:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 17:57:43 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 17:57:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 17:57:43 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 17:57:43 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 1799  total_loss: 0.05895  loss_cls: 0.01011  loss_box_reg: 0.01596  loss_mask: 0.03103  loss_rpn_cls: 1.731e-06  loss_rpn_loc: 0.00147    time: 0.7401  last_time: 0.8666  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:57:56 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 1819  total_loss: 0.05176  loss_cls: 0.00735  loss_box_reg: 0.01427  loss_mask: 0.02693  loss_rpn_cls: 7.205e-07  loss_rpn_loc: 0.001517    time: 0.7392  last_time: 0.8411  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:58:09 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 1839  total_loss: 0.0589  loss_cls: 0.008348  loss_box_reg: 0.01787  loss_mask: 0.02801  loss_rpn_cls: 1.255e-06  loss_rpn_loc: 0.001382    time: 0.7384  last_time: 0.4698  data_time: 0.0015  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:58:23 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 1859  total_loss: 0.05794  loss_cls: 0.008703  loss_box_reg: 0.01496  loss_mask: 0.03199  loss_rpn_cls: 4.15e-06  loss_rpn_loc: 0.001471    time: 0.7380  last_time: 0.3710  data_time: 0.0015  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:58:37 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 1879  total_loss: 0.05553  loss_cls: 0.009895  loss_box_reg: 0.01662  loss_mask: 0.02906  loss_rpn_cls: 1.222e-06  loss_rpn_loc: 0.001375    time: 0.7376  last_time: 0.4752  data_time: 0.0015  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:58:51 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 1899  total_loss: 0.05163  loss_cls: 0.008447  loss_box_reg: 0.01381  loss_mask: 0.02563  loss_rpn_cls: 2.579e-06  loss_rpn_loc: 0.001373    time: 0.7373  last_time: 0.8518  data_time: 0.0017  last_data_time: 0.0022   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:59:05 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 1919  total_loss: 0.04812  loss_cls: 0.007674  loss_box_reg: 0.01378  loss_mask: 0.02458  loss_rpn_cls: 1.358e-06  loss_rpn_loc: 0.001171    time: 0.7369  last_time: 0.8642  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:59:19 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 1939  total_loss: 0.05729  loss_cls: 0.008656  loss_box_reg: 0.01493  loss_mask: 0.03131  loss_rpn_cls: 3.421e-06  loss_rpn_loc: 0.001414    time: 0.7361  last_time: 0.4373  data_time: 0.0016  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:59:34 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 1959  total_loss: 0.05371  loss_cls: 0.009315  loss_box_reg: 0.01479  loss_mask: 0.02636  loss_rpn_cls: 2.494e-06  loss_rpn_loc: 0.001275    time: 0.7364  last_time: 0.7604  data_time: 0.0017  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 17:59:47 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 1979  total_loss: 0.05557  loss_cls: 0.008549  loss_box_reg: 0.01503  loss_mask: 0.03003  loss_rpn_cls: 1.112e-06  loss_rpn_loc: 0.001368    time: 0.7357  last_time: 0.7417  data_time: 0.0017  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:00:02 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:00:02 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 18:00:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 18:00:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 18:00:02 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 18:00:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:00:02 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 18:00:02 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 1999  total_loss: 0.05146  loss_cls: 0.008676  loss_box_reg: 0.01257  loss_mask: 0.02673  loss_rpn_cls: 1.075e-06  loss_rpn_loc: 0.001307    time: 0.7355  last_time: 0.7645  data_time: 0.0017  last_data_time: 0.0022   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:00:16 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 2019  total_loss: 0.05373  loss_cls: 0.007995  loss_box_reg: 0.01466  loss_mask: 0.0298  loss_rpn_cls: 1.695e-06  loss_rpn_loc: 0.001398    time: 0.7356  last_time: 0.8426  data_time: 0.0015  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:00:29 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 2039  total_loss: 0.0508  loss_cls: 0.009554  loss_box_reg: 0.01493  loss_mask: 0.02525  loss_rpn_cls: 3.488e-06  loss_rpn_loc: 0.001384    time: 0.7348  last_time: 0.7497  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:00:44 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 2059  total_loss: 0.0573  loss_cls: 0.008646  loss_box_reg: 0.01442  loss_mask: 0.03141  loss_rpn_cls: 3.565e-06  loss_rpn_loc: 0.001376    time: 0.7346  last_time: 0.8531  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:00:59 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 2079  total_loss: 0.05442  loss_cls: 0.007999  loss_box_reg: 0.01467  loss_mask: 0.02828  loss_rpn_cls: 2.117e-06  loss_rpn_loc: 0.001352    time: 0.7346  last_time: 0.8386  data_time: 0.0017  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:01:13 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 2099  total_loss: 0.0508  loss_cls: 0.008845  loss_box_reg: 0.01361  loss_mask: 0.02961  loss_rpn_cls: 1.861e-06  loss_rpn_loc: 0.00117    time: 0.7345  last_time: 0.7563  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:01:28 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 2119  total_loss: 0.04961  loss_cls: 0.008211  loss_box_reg: 0.01393  loss_mask: 0.02659  loss_rpn_cls: 1.118e-06  loss_rpn_loc: 0.001365    time: 0.7346  last_time: 0.3392  data_time: 0.0017  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:01:42 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 2139  total_loss: 0.049  loss_cls: 0.008574  loss_box_reg: 0.01262  loss_mask: 0.02623  loss_rpn_cls: 8.902e-07  loss_rpn_loc: 0.00123    time: 0.7345  last_time: 0.9061  data_time: 0.0016  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:01:57 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 2159  total_loss: 0.04977  loss_cls: 0.008331  loss_box_reg: 0.01463  loss_mask: 0.02509  loss_rpn_cls: 2.669e-07  loss_rpn_loc: 0.001342    time: 0.7346  last_time: 0.8854  data_time: 0.0017  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:02:12 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 2179  total_loss: 0.04735  loss_cls: 0.007362  loss_box_reg: 0.01295  loss_mask: 0.02607  loss_rpn_cls: 3.259e-06  loss_rpn_loc: 0.001324    time: 0.7344  last_time: 0.4645  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:02:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:02:25 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 18:02:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 18:02:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 18:02:25 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 18:02:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:02:25 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 18:02:25 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 2199  total_loss: 0.0532  loss_cls: 0.008126  loss_box_reg: 0.01288  loss_mask: 0.02942  loss_rpn_cls: 9.614e-07  loss_rpn_loc: 0.001274    time: 0.7340  last_time: 0.7532  data_time: 0.0016  last_data_time: 0.0024   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:02:40 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 2219  total_loss: 0.04111  loss_cls: 0.008486  loss_box_reg: 0.01268  loss_mask: 0.0209  loss_rpn_cls: 1.823e-06  loss_rpn_loc: 0.001232    time: 0.7338  last_time: 0.8386  data_time: 0.0016  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:02:53 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 2239  total_loss: 0.05139  loss_cls: 0.006789  loss_box_reg: 0.01282  loss_mask: 0.02806  loss_rpn_cls: 1.613e-06  loss_rpn_loc: 0.001507    time: 0.7334  last_time: 0.7792  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:03:09 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 2259  total_loss: 0.05367  loss_cls: 0.00846  loss_box_reg: 0.01463  loss_mask: 0.02816  loss_rpn_cls: 3.93e-06  loss_rpn_loc: 0.001424    time: 0.7339  last_time: 0.7501  data_time: 0.0017  last_data_time: 0.0020   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:03:24 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 2279  total_loss: 0.04654  loss_cls: 0.007528  loss_box_reg: 0.01216  loss_mask: 0.02384  loss_rpn_cls: 1.947e-06  loss_rpn_loc: 0.001309    time: 0.7339  last_time: 0.8662  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:03:38 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 2299  total_loss: 0.05135  loss_cls: 0.007461  loss_box_reg: 0.01382  loss_mask: 0.03191  loss_rpn_cls: 3.662e-06  loss_rpn_loc: 0.001145    time: 0.7335  last_time: 0.7766  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:03:52 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 2319  total_loss: 0.04622  loss_cls: 0.007142  loss_box_reg: 0.01367  loss_mask: 0.02361  loss_rpn_cls: 1.026e-06  loss_rpn_loc: 0.001453    time: 0.7331  last_time: 0.8434  data_time: 0.0017  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:04:06 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 2339  total_loss: 0.05162  loss_cls: 0.007498  loss_box_reg: 0.01249  loss_mask: 0.02899  loss_rpn_cls: 1.944e-06  loss_rpn_loc: 0.00125    time: 0.7329  last_time: 0.7430  data_time: 0.0015  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:04:19 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 2359  total_loss: 0.05147  loss_cls: 0.007225  loss_box_reg: 0.01359  loss_mask: 0.02947  loss_rpn_cls: 1.41e-06  loss_rpn_loc: 0.001353    time: 0.7325  last_time: 0.4480  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:04:33 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 2379  total_loss: 0.04918  loss_cls: 0.006945  loss_box_reg: 0.01275  loss_mask: 0.02638  loss_rpn_cls: 3.399e-07  loss_rpn_loc: 0.001272    time: 0.7319  last_time: 0.4461  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:04:47 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:04:47 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 18:04:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 18:04:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 18:04:47 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 18:04:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:04:47 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 18:04:47 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 2399  total_loss: 0.0494  loss_cls: 0.007171  loss_box_reg: 0.01174  loss_mask: 0.02764  loss_rpn_cls: 2.043e-06  loss_rpn_loc: 0.001165    time: 0.7318  last_time: 0.7691  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:05:01 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 2419  total_loss: 0.0448  loss_cls: 0.007401  loss_box_reg: 0.01257  loss_mask: 0.02427  loss_rpn_cls: 1.026e-06  loss_rpn_loc: 0.001164    time: 0.7315  last_time: 0.7631  data_time: 0.0016  last_data_time: 0.0012   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:05:16 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 2439  total_loss: 0.05445  loss_cls: 0.009834  loss_box_reg: 0.01375  loss_mask: 0.02756  loss_rpn_cls: 2.091e-06  loss_rpn_loc: 0.001186    time: 0.7317  last_time: 0.8855  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:05:30 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 2459  total_loss: 0.05083  loss_cls: 0.007716  loss_box_reg: 0.01409  loss_mask: 0.02649  loss_rpn_cls: 3.762e-07  loss_rpn_loc: 0.00134    time: 0.7313  last_time: 0.8761  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:05:43 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 2479  total_loss: 0.04466  loss_cls: 0.006504  loss_box_reg: 0.0116  loss_mask: 0.02497  loss_rpn_cls: 4.752e-06  loss_rpn_loc: 0.001296    time: 0.7309  last_time: 0.8421  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:05:57 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 2499  total_loss: 0.04955  loss_cls: 0.008395  loss_box_reg: 0.01233  loss_mask: 0.02815  loss_rpn_cls: 6.303e-07  loss_rpn_loc: 0.001164    time: 0.7305  last_time: 0.7835  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:06:11 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2519  total_loss: 0.04913  loss_cls: 0.007756  loss_box_reg: 0.01167  loss_mask: 0.02745  loss_rpn_cls: 1.856e-06  loss_rpn_loc: 0.001129    time: 0.7304  last_time: 0.7402  data_time: 0.0016  last_data_time: 0.0018   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:06:27 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 2539  total_loss: 0.04605  loss_cls: 0.008509  loss_box_reg: 0.01096  loss_mask: 0.02597  loss_rpn_cls: 1.336e-06  loss_rpn_loc: 0.001197    time: 0.7306  last_time: 0.8519  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:06:40 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 2559  total_loss: 0.0484  loss_cls: 0.006596  loss_box_reg: 0.01301  loss_mask: 0.02518  loss_rpn_cls: 9.081e-07  loss_rpn_loc: 0.001157    time: 0.7301  last_time: 0.8771  data_time: 0.0016  last_data_time: 0.0021   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:06:54 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 2579  total_loss: 0.04192  loss_cls: 0.006305  loss_box_reg: 0.01099  loss_mask: 0.0235  loss_rpn_cls: 1.224e-06  loss_rpn_loc: 0.00127    time: 0.7301  last_time: 0.7389  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:07:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:07:09 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 18:07:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 18:07:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 18:07:09 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 18:07:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:07:09 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 18:07:09 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 2599  total_loss: 0.05298  loss_cls: 0.007665  loss_box_reg: 0.01339  loss_mask: 0.02846  loss_rpn_cls: 1.805e-06  loss_rpn_loc: 0.001108    time: 0.7302  last_time: 0.7851  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:07:24 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 2619  total_loss: 0.05108  loss_cls: 0.008388  loss_box_reg: 0.01254  loss_mask: 0.02717  loss_rpn_cls: 1.79e-06  loss_rpn_loc: 0.001235    time: 0.7301  last_time: 0.8444  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:07:37 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 2639  total_loss: 0.05103  loss_cls: 0.006943  loss_box_reg: 0.01338  loss_mask: 0.02741  loss_rpn_cls: 1.069e-06  loss_rpn_loc: 0.001067    time: 0.7297  last_time: 0.3641  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:07:51 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 2659  total_loss: 0.04836  loss_cls: 0.006584  loss_box_reg: 0.01164  loss_mask: 0.02423  loss_rpn_cls: 1.657e-06  loss_rpn_loc: 0.00121    time: 0.7293  last_time: 0.7994  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:08:06 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 2679  total_loss: 0.04343  loss_cls: 0.00686  loss_box_reg: 0.01119  loss_mask: 0.02287  loss_rpn_cls: 3.008e-06  loss_rpn_loc: 0.001192    time: 0.7297  last_time: 0.8644  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:08:22 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2699  total_loss: 0.04591  loss_cls: 0.008159  loss_box_reg: 0.01201  loss_mask: 0.02465  loss_rpn_cls: 1.226e-06  loss_rpn_loc: 0.001083    time: 0.7300  last_time: 0.8751  data_time: 0.0016  last_data_time: 0.0019   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:08:35 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2719  total_loss: 0.04576  loss_cls: 0.006336  loss_box_reg: 0.01207  loss_mask: 0.02575  loss_rpn_cls: 1.591e-06  loss_rpn_loc: 0.001251    time: 0.7296  last_time: 0.4519  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:08:50 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 2739  total_loss: 0.05168  loss_cls: 0.007321  loss_box_reg: 0.01177  loss_mask: 0.02756  loss_rpn_cls: 3.019e-07  loss_rpn_loc: 0.001225    time: 0.7296  last_time: 0.7580  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:09:05 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2759  total_loss: 0.0487  loss_cls: 0.006426  loss_box_reg: 0.01105  loss_mask: 0.02796  loss_rpn_cls: 1.049e-06  loss_rpn_loc: 0.001187    time: 0.7297  last_time: 0.7295  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:09:19 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 2779  total_loss: 0.04504  loss_cls: 0.006425  loss_box_reg: 0.01035  loss_mask: 0.02674  loss_rpn_cls: 1.715e-06  loss_rpn_loc: 0.001037    time: 0.7297  last_time: 0.7411  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:09:34 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:09:34 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 18:09:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 18:09:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 18:09:34 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 18:09:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:09:34 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 18:09:34 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 2799  total_loss: 0.04538  loss_cls: 0.007141  loss_box_reg: 0.01155  loss_mask: 0.02296  loss_rpn_cls: 2.813e-06  loss_rpn_loc: 0.001318    time: 0.7297  last_time: 0.7443  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:09:47 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 2819  total_loss: 0.04806  loss_cls: 0.006315  loss_box_reg: 0.01267  loss_mask: 0.02709  loss_rpn_cls: 6.228e-07  loss_rpn_loc: 0.001131    time: 0.7293  last_time: 0.7385  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:10:02 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 2839  total_loss: 0.04545  loss_cls: 0.006843  loss_box_reg: 0.01294  loss_mask: 0.0251  loss_rpn_cls: 1.492e-06  loss_rpn_loc: 0.001041    time: 0.7292  last_time: 0.8687  data_time: 0.0015  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:10:16 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 2859  total_loss: 0.0474  loss_cls: 0.00677  loss_box_reg: 0.01337  loss_mask: 0.02774  loss_rpn_cls: 1.097e-06  loss_rpn_loc: 0.001059    time: 0.7290  last_time: 0.4399  data_time: 0.0016  last_data_time: 0.0019   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:10:30 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 2879  total_loss: 0.04687  loss_cls: 0.007121  loss_box_reg: 0.01143  loss_mask: 0.02492  loss_rpn_cls: 1.172e-06  loss_rpn_loc: 0.001166    time: 0.7288  last_time: 0.3586  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:10:45 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 2899  total_loss: 0.04279  loss_cls: 0.006166  loss_box_reg: 0.01038  loss_mask: 0.02472  loss_rpn_cls: 1.342e-06  loss_rpn_loc: 0.001162    time: 0.7289  last_time: 0.7874  data_time: 0.0016  last_data_time: 0.0015   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:10:58 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 2919  total_loss: 0.0438  loss_cls: 0.007125  loss_box_reg: 0.009863  loss_mask: 0.02469  loss_rpn_cls: 6.621e-07  loss_rpn_loc: 0.001006    time: 0.7285  last_time: 0.8450  data_time: 0.0016  last_data_time: 0.0016   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:11:13 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 2939  total_loss: 0.04648  loss_cls: 0.006297  loss_box_reg: 0.01065  loss_mask: 0.0262  loss_rpn_cls: 1.271e-06  loss_rpn_loc: 0.001319    time: 0.7285  last_time: 0.7594  data_time: 0.0016  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:11:26 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 2959  total_loss: 0.04511  loss_cls: 0.006271  loss_box_reg: 0.01315  loss_mask: 0.02401  loss_rpn_cls: 9.419e-07  loss_rpn_loc: 0.001383    time: 0.7282  last_time: 0.7544  data_time: 0.0015  last_data_time: 0.0014   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:11:40 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2979  total_loss: 0.0436  loss_cls: 0.00633  loss_box_reg: 0.01058  loss_mask: 0.02482  loss_rpn_cls: 1.809e-06  loss_rpn_loc: 0.001204    time: 0.7280  last_time: 0.7511  data_time: 0.0016  last_data_time: 0.0028   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:11:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.04414  loss_cls: 0.006515  loss_box_reg: 0.01097  loss_mask: 0.02493  loss_rpn_cls: 1.953e-07  loss_rpn_loc: 0.001125    time: 0.7277  last_time: 0.8423  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0001  max_mem: 5017M\n",
      "\u001b[32m[06/30 18:11:55 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:36:21 (0.7277 s / it)\n",
      "\u001b[32m[06/30 18:11:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:36:23 (0:00:01 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:11:55 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:11:55 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 18:11:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 18:11:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 18:11:55 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 18:11:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:11:55 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2XMPKQ28GRna"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fc7e3847c0c45229\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fc7e3847c0c45229\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flInE1L-XTfx"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:30.387236Z",
     "start_time": "2024-06-25T08:07:28.649281Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2265,
     "status": "ok",
     "timestamp": 1668005909534,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "vsByFDFbQwLi",
    "outputId": "db8479c0-a286-4e83-e064-9ae4ebad3aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/30 18:55:55 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from tank_edges\\mask_rcnn_R_101_FPN_3x\\2024-06-30-17-35-19\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:56.682926Z",
     "start_time": "2024-06-25T08:07:33.893951Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "hmAcBbpXX-Rh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 18:55:57 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 18:55:57 d2.data.datasets.coco]: \u001b[0mLoaded 17 images in COCO format from c:\\Users\\Daanish Mittal\\OneDrive\\Desktop\\Tank_align\\tank_alignment\\tank_edge\\tank_edges-1\\valid\\_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)\n",
    "\n",
    "for d in dataset_valid:\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "\n",
    "    visualizer = Visualizer(\n",
    "\n",
    "        img[:, :, ::-1],\n",
    "        metadata=metadata,\n",
    "        scale=0.8,\n",
    "        instance_mode=ColorMode.IMAGE_BW\n",
    "    )\n",
    "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(\"validation\",out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Config file 'D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml' does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 71\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/config.yaml\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/model_final.pth\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/path_detect/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 71\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m process_folder(predictor, input_folder)\n",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(config_file, weights_file)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(config_file, weights_file):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Load the configuration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mWEIGHTS \u001b[38;5;241m=\u001b[39m weights_file\n\u001b[0;32m     16\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mROI_HEADS\u001b[38;5;241m.\u001b[39mSCORE_THRESH_TEST \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.97\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Daanish Mittal\\anaconda3\\lib\\site-packages\\detectron2\\config\\config.py:45\u001b[0m, in \u001b[0;36mCfgNode.merge_from_file\u001b[1;34m(self, cfg_filename, allow_unsafe)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_from_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg_filename: \u001b[38;5;28mstr\u001b[39m, allow_unsafe: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    Load content from the given config file and merge it into self.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m        allow_unsafe: allow unsafe yaml syntax\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m PathManager\u001b[38;5;241m.\u001b[39misfile(cfg_filename), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m     loaded_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_yaml_with_base(cfg_filename, allow_unsafe\u001b[38;5;241m=\u001b[39mallow_unsafe)\n\u001b[0;32m     47\u001b[0m     loaded_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(loaded_cfg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Config file 'D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml' does not exist!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.97\n",
    "      # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Visualize the results\n",
    "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Display the image\n",
    "    result_image = out.get_image()[:, :, ::-1]\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # Display the frame\n",
    "        result_frame = out.get_image()[:, :, ::-1]\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "# config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/config.yaml\"\n",
    "# weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_quadrilaterals_and_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/path_detect/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m predictor \u001b[38;5;241m=\u001b[39m load_model(config_file, weights_file)\n\u001b[1;32m---> 88\u001b[0m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 77\u001b[0m, in \u001b[0;36mprocess_folder\u001b[1;34m(predictor, folder_path)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m---> 77\u001b[0m         \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mov\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     79\u001b[0m         process_video(predictor, file_path)\n",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(predictor, image_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m predictor(image)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Draw quadrilaterals and masks on the image\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m result_image \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_quadrilaterals_and_masks\u001b[49m(image, outputs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[0;32m     51\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, result_image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'draw_quadrilaterals_and_masks' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import numpy as np\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.97  # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def draw_quadrilaterals(image, outputs, deformation_threshold=0.05):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    for mask in masks:\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a quadrilateral\n",
    "            epsilon = deformation_threshold * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Ensure it's a quadrilateral (4 sides)\n",
    "            if len(approx) == 4:\n",
    "                # Draw the quadrilateral\n",
    "                cv2.polylines(image, [approx], True, (0, 255, 0), 2)\n",
    "                \n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Draw quadrilaterals and masks on the image\n",
    "    result_image = draw_quadrilaterals_and_masks(image, outputs)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        result_frame = draw_quadrilaterals_and_masks(frame, outputs)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daanish Mittal\\anaconda3\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved result for D:/path_detect/test\\IMG1551952615468_jpg.rf.18ba64b8924724efc330d01981c585bd.jpg to D:/path_detect/output\\IMG1551952615468_jpg.rf.18ba64b8924724efc330d01981c585bd.jpg\n",
      "Saved result for D:/path_detect/test\\IMG1554039051734_jpg.rf.347e3b8c0f42e174cf14976b3a98d14c.jpg to D:/path_detect/output\\IMG1554039051734_jpg.rf.347e3b8c0f42e174cf14976b3a98d14c.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-25 at 23.15.50_4d2547a6.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-25 at 23.15.50_4d2547a6.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-25 at 23.43.27_aa0561da.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-25 at 23.43.27_aa0561da.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-25 at 23.49.54_963bf197.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-25 at 23.49.54_963bf197.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-28 at 16.00.55_072c0a4e.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-28 at 16.00.55_072c0a4e.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-28 at 16.01.12_0993b44b.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-28 at 16.01.12_0993b44b.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Video 2024-06-16 at 3.26.mp4 to D:/path_detect/output\\WhatsApp Video 2024-06-16 at 3.26.mp4\n",
      "Saved result for D:/path_detect/test\\WhatsApp Video 2024-06-26 at 13.39.29_71c34361.mp4 to D:/path_detect/output\\WhatsApp Video 2024-06-26 at 13.39.29_71c34361.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import numpy as np\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.95  # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def draw_quadrilaterals(image, outputs):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    for mask in masks:\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a quadrilateral\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Calculate the area of the mask and the quadrilateral\n",
    "            mask_area = cv2.contourArea(contour)\n",
    "            quad_area = cv2.contourArea(approx)\n",
    "            \n",
    "            # Check if mask_area is zero (handle edge case)\n",
    "            if mask_area <= 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the percentage of the mask area outside the quadrilateral\n",
    "            outside_area = mask_area - quad_area\n",
    "            outside_percentage = outside_area / mask_area if mask_area > 0 else 0\n",
    "            \n",
    "            # Determine the color of the quadrilateral\n",
    "            color = (0, 255, 0) if outside_percentage <= 0.12 else (0, 0, 255)\n",
    "            \n",
    "            if len(approx) >= 4:\n",
    "                cv2.polylines(image, [approx], True, color, 2)\n",
    "                \n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image(predictor, image_path, output_folder):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Draw quadrilaterals on the image\n",
    "    result_image = draw_quadrilaterals(image, outputs)\n",
    "    \n",
    "    # Save the result image\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "    print(f'Saved result for {image_path} to {output_path}')\n",
    "\n",
    "def process_video(predictor, video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_path = os.path.join(output_folder, os.path.basename(video_path))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        result_frame = draw_quadrilaterals(frame, outputs)\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(result_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f'Saved result for {video_path} to {output_path}')\n",
    "\n",
    "def process_folder(predictor, folder_path, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path, output_folder)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path, output_folder)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "output_folder = \"D:/path_detect/output\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ramp_edges(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 300, 250, apertureSize=3)\n",
    "\n",
    "    # Create a mask to remove boundary edges\n",
    "    height, width = edges.shape\n",
    "    mask = np.ones_like(edges)\n",
    "    border = 10  # Adjust this value to change the border size\n",
    "    mask[:border, :] = 0\n",
    "    mask[-border:, :] = 0\n",
    "    mask[:, :border] = 0\n",
    "    mask[:, -border:] = 0\n",
    "\n",
    "    # Apply the mask to remove boundary edges\n",
    "    edges = cv2.bitwise_and(edges, edges, mask=mask)\n",
    "\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1.1, np.pi / 180,200)\n",
    "\n",
    "\n",
    "    return lines\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    # Draw the lines on the image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def process_video(video_source=0):\n",
    "    # Open the video source (0 for webcam, or a filename)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect ramp edges\n",
    "        lines = detect_ramp_edges(frame)\n",
    "\n",
    "        # Draw detected lines on the frame\n",
    "        frame_with_lines = draw_lines(frame, lines)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Detected Ramp Edges', frame_with_lines)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('D:/path_detect/video1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ramp_edges(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 100, 200, apertureSize=3)\n",
    "\n",
    "    # Create a mask to remove boundary edges\n",
    "    height, width = edges.shape\n",
    "    mask = np.ones_like(edges)\n",
    "    border = 10  # Adjust this value to change the border size\n",
    "    mask[:border, :] = 0\n",
    "    mask[-border:, :] = 0\n",
    "    mask[:, :border] = 0\n",
    "    mask[:, -border:] = 0\n",
    "\n",
    "    # Apply the mask to remove boundary edges\n",
    "    edges = cv2.bitwise_and(edges, edges, mask=mask)\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1.1, np.pi / 180, 200)\n",
    "\n",
    "    return lines\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    # Draw the lines on the image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def process_video(video_source=0):\n",
    "    # Open the video source (0 for webcam, or a filename)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect ramp edges\n",
    "        lines = detect_ramp_edges(frame)\n",
    "\n",
    "        # Draw detected lines on the frame\n",
    "        frame_with_lines = draw_lines(frame, lines)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Detected Ramp Edges', frame_with_lines)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video()  # Default is the webcam, pass a video file path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1Wkuq4DLHD7MG5HgpEqiytvEjvNK2sYAx",
     "timestamp": 1719261218111
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
