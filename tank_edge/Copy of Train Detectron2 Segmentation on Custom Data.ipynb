{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZBUwM3tyFWS"
   },
   "source": [
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 30 00:41:42 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.85                 Driver Version: 555.85         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P8             10W /  105W |    4866MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4904      C   ...Daanish Mittal\\anaconda3\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     26116      C   ...Daanish Mittal\\anaconda3\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MJ8SshpLaU3"
   },
   "source": [
    "## Install Detectron2 and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:27.100950Z",
     "start_time": "2024-06-25T07:59:43.324225Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51415,
     "status": "ok",
     "timestamp": 1719261763571,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "fM1JmUCQLdKp",
    "outputId": "cb684e1a-65eb-4798-eb32-28ef5b785883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to c:\\users\\daanish mittal\\appdata\\local\\temp\\pip-req-build-w6nilpdy\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Daanish Mittal\\AppData\\Local\\Temp\\pip-req-build-w6nilpdy\\setup.py\", line 10, in <module>\n",
      "        import torch\n",
      "    ModuleNotFoundError: No module named 'torch'\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Daanish Mittal\\AppData\\Local\\Temp\\pip-req-build-w6nilpdy\\\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V8w1ew59buh"
   },
   "source": [
    "Now is a good time to confirm that we have the right versions of the libraries at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4612,
     "status": "error",
     "timestamp": 1719261915922,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "sqCNglJXRro5",
    "outputId": "3f148ff1-b579-4dfa-c1f0-adb5bdda4c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: iopath<0.1.10,>=0.1.7 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: portalocker in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from iopath<0.1.10,>=0.1.7) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: pywin32>=226; platform_system == \"Windows\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from portalocker->iopath<0.1.10,>=0.1.7) (305)\n",
      "Requirement already satisfied, skipping upgrade: colorama; platform_system == \"Windows\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->iopath<0.1.10,>=0.1.7) (0.4.5)\n",
      "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.7\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->iopath<0.1.10,>=0.1.7) (5.4.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-resources; python_version < \"3.7\"->tqdm->iopath<0.1.10,>=0.1.7) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.105\n",
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"iopath<0.1.10,>=0.1.7\"\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "import pkg_resources\n",
    "print(\"detectron2:\", pkg_resources.get_distribution(\"detectron2\").version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:40.273497Z",
     "start_time": "2024-06-25T08:00:37.778861Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "error",
     "timestamp": 1719261789459,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "DIEKfPKFmW54",
    "outputId": "1eae8bc5-084a-4dd2-bcdd-00efdcfc6330"
   },
   "outputs": [],
   "source": [
    "# COMMON LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# TRAINING\n",
    "from detectron2.engine import DefaultTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOszeLVlErvk"
   },
   "source": [
    "## Run a Pre-trained Detectron2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:01:49.176003Z",
     "start_time": "2024-06-25T08:00:40.278498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 2681,
     "status": "ok",
     "timestamp": 1668002463033,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "T8sfLDV7FTYD",
    "outputId": "0e8eea7a-6407-4cb5-a7b8-6f4997bacde0"
   },
   "outputs": [],
   "source": [
    "# !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "# image = cv2.imread(\"./input.jpg\")\n",
    "# cv2.imshow('Display Window', image)  # 'Display Window' is the name of the window\n",
    "# cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "# cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:05.116019Z",
     "start_time": "2024-06-25T08:01:49.193280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Collecting torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement torch (from versions: )\n",
      "No matching distribution found for torch\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFkJOTWvxu6G"
   },
   "source": [
    "## COCO Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:42.536499Z",
     "start_time": "2024-06-25T08:02:25.897211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14044,
     "status": "ok",
     "timestamp": 1668003461405,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "grFIdy8ynP-7",
    "outputId": "d05be873-4ac3-4d10-d88b-fa053a263c90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement supervision (from roboflow) (from versions: )\n",
      "No matching distribution found for supervision (from roboflow)\n",
      "You are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached https://files.pythonhosted.org/packages/99/f2/8349482b1cb7d408cd8673efaa1b51e7bd657f95b679de27f89e333f1388/roboflow-1.1.6-py3-none-any.whl\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e4/73/b46073efb9ab0e07dae64d5b0229825eb19cc393d9f5ba8ec9d693e4e5f3/opencv-python-headless-4.8.0.74.tar.gz\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting certifi==2022.12.7 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/4c/3db2b8021bd6f2f0ceb0e088d6b2d49147671f25832fb17970e9b583d742/certifi-2022.12.7-py3-none-any.whl\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl\n",
      "Collecting idna==2.10 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Collecting requests (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/61/08076519c80041bc0ffa1a8af0cbd3bf3e2b62af10435d269a9d0f40564d/requests-2.27.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (4.64.1)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/30/5f/2e5c564bd86349fe6b82ca840f46acf6f4bb76d79ba9057fce3d3e008864/python_dotenv-0.20.0-py3-none-any.whl\n",
      "Collecting pyparsing==2.4.7 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\daanish mittal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from roboflow) (3.3.4)\n",
      "Collecting PyYAML>=5.3.1 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/d5/fb4f7a3c96af89c214387af42c76117d2c2a0a40576e217632548a6e1aff/PyYAML-6.0.1-cp36-cp36m-win_amd64.whl\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl\n",
      "Collecting supervision (from roboflow)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"RovqaIFPpcekpUVWjRke\")\n",
    "project = rf.workspace(\"tank-5yib6\").project(\"tank_edges\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco-segmentation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoB31yi4AoYs"
   },
   "source": [
    "### Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HopUGOyW853G"
   },
   "source": [
    "When you use Detectron2, before you actually train the model you need to [register it](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-coco-format-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:35.787965Z",
     "start_time": "2024-06-25T08:05:35.780944Z"
    },
    "id": "KbI2PNEZF3sU"
   },
   "outputs": [],
   "source": [
    "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
    "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:38.778124Z",
     "start_time": "2024-06-25T08:05:38.650598Z"
    },
    "id": "jntOI8GJG2ks"
   },
   "outputs": [],
   "source": [
    "# TRAIN SET\n",
    "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
    "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
    "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TRAIN_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# TEST SET\n",
    "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
    "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
    "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TEST_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# VALID SET\n",
    "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
    "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
    "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=VALID_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=VALID_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCY1UWNCtnq"
   },
   "source": [
    "We can now confirm that our custom dataset was correctly registered using [MetadataCatalog](https://detectron2.readthedocs.io/en/latest/modules/data.html#detectron2.data.MetadataCatalog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:42.883439Z",
     "start_time": "2024-06-25T08:05:42.865442Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1668003586610,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "LR8ha4EHCkA-",
    "outputId": "6506603a-3742-43ee-af5d-7f842426d25d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tank_edges-train', 'tank_edges-test', 'tank_edges-valid']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    data_set\n",
    "    for data_set\n",
    "    in MetadataCatalog.list()\n",
    "    if data_set.startswith(DATA_SET_NAME)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpU2L3UL922"
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Bd_-oCA90a"
   },
   "source": [
    "Let's take a look at single entry from out train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:47.307052Z",
     "start_time": "2024-06-25T08:05:45.996186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1668003725711,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "eE0anblvMGJx",
    "outputId": "b5db94b3-faf0-4c64-9717-fa906c4b76db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:01:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 01:01:22 d2.data.datasets.coco]: \u001b[0mLoaded 180 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\train\\_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "\n",
    "dataset_entry = dataset_train[0]\n",
    "image = cv2.imread(dataset_entry[\"file_name\"])\n",
    "\n",
    "visualizer = Visualizer(\n",
    "    image[:, :, ::-1],\n",
    "    metadata=metadata,\n",
    "    scale=0.5,\n",
    "    instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "\n",
    "out = visualizer.draw_dataset_dict(dataset_entry)\n",
    "cv2.imshow(\"visualize\",out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GavGRHy2M7Hb"
   },
   "source": [
    "## Train Model Using Custom COCO Format Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ3g-l56NMOY"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.228994Z",
     "start_time": "2024-06-25T08:03:04.203266Z"
    },
    "id": "krCm2L_lNC83"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "MAX_ITER = 2000\n",
    "EVAL_PERIOD = 300\n",
    "BASE_LR = 0.001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# OUTPUT DIRa\n",
    "OUTPUT_DIR_PATH = os.path.join(\n",
    "    DATA_SET_NAME,\n",
    "    ARCHITECTURE,\n",
    "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.291051Z",
     "start_time": "2024-06-25T08:03:04.233685Z"
    },
    "id": "lxQU8JrgOD73"
   },
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "# cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "# cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "# cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "# cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "# cfg.SOLVER.BASE_LR = BASE_LR\n",
    "# cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "# cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  # Default batch size per image\n",
    "\n",
    "# Adjusting batch size and image size for GPU with 6GB VRAM\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # Overall batch size\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)  # Adjusted to fit memory constraints\n",
    "cfg.INPUT.MIN_SIZE_TEST = 800\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1333\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.DATALOADER.NUM_WORKERS = 3\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n",
    "\n",
    "# Save config for future reference\n",
    "with open(os.path.join(OUTPUT_DIR_PATH, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch-_5aCuXWj9"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:15.015389Z",
     "start_time": "2024-06-25T08:03:04.296073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961595,
     "status": "ok",
     "timestamp": 1668005381143,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "7S8y2W2AQvJq",
    "outputId": "36fe2d26-1118-4748-fff1-18a86d873970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/30 01:03:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:03:55 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 01:03:55 d2.data.datasets.coco]: \u001b[0mLoaded 180 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\train\\_annotations.coco.json\n",
      "\u001b[32m[06/30 01:03:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 180 images left.\n",
      "\u001b[32m[06/30 01:03:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[06/30 01:03:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[06/30 01:03:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 01:03:55 d2.data.common]: \u001b[0mSerializing 180 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 01:03:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[32m[06/30 01:03:55 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:03:55 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[06/30 01:03:55 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/30 01:03:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[06/30 01:04:48 d2.utils.events]: \u001b[0m eta: 1:22:07  iter: 19  total_loss: 2.296  loss_cls: 1.361  loss_box_reg: 0.2658  loss_mask: 0.6846  loss_rpn_cls: 0.00204  loss_rpn_loc: 0.002668    time: 2.5426  last_time: 2.9995  data_time: 0.1222  last_data_time: 0.0017   lr: 1.9981e-05  max_mem: 5719M\n",
      "\u001b[32m[06/30 01:05:51 d2.utils.events]: \u001b[0m eta: 1:34:17  iter: 39  total_loss: 1.618  loss_cls: 0.8273  loss_box_reg: 0.2199  loss_mask: 0.5762  loss_rpn_cls: 0.007008  loss_rpn_loc: 0.002509    time: 2.8544  last_time: 3.1060  data_time: 0.0017  last_data_time: 0.0015   lr: 3.9961e-05  max_mem: 5719M\n",
      "\u001b[32m[06/30 01:06:47 d2.utils.events]: \u001b[0m eta: 1:32:44  iter: 59  total_loss: 1.023  loss_cls: 0.3645  loss_box_reg: 0.2358  loss_mask: 0.4276  loss_rpn_cls: 0.00607  loss_rpn_loc: 0.002897    time: 2.8278  last_time: 2.7016  data_time: 0.0018  last_data_time: 0.0019   lr: 5.9941e-05  max_mem: 5720M\n",
      "\u001b[32m[06/30 01:07:38 d2.utils.events]: \u001b[0m eta: 1:28:45  iter: 79  total_loss: 0.756  loss_cls: 0.2176  loss_box_reg: 0.2426  loss_mask: 0.2981  loss_rpn_cls: 0.0008363  loss_rpn_loc: 0.002515    time: 2.7579  last_time: 2.2948  data_time: 0.0018  last_data_time: 0.0017   lr: 7.9921e-05  max_mem: 5734M\n",
      "\u001b[32m[06/30 01:08:37 d2.utils.events]: \u001b[0m eta: 1:30:29  iter: 99  total_loss: 0.6302  loss_cls: 0.1692  loss_box_reg: 0.2254  loss_mask: 0.2205  loss_rpn_cls: 0.0005349  loss_rpn_loc: 0.001852    time: 2.7967  last_time: 3.5115  data_time: 0.0017  last_data_time: 0.0014   lr: 9.9901e-05  max_mem: 5734M\n",
      "\u001b[32m[06/30 01:09:32 d2.utils.events]: \u001b[0m eta: 1:29:32  iter: 119  total_loss: 0.4748  loss_cls: 0.1216  loss_box_reg: 0.2353  loss_mask: 0.1341  loss_rpn_cls: 0.001822  loss_rpn_loc: 0.002138    time: 2.7913  last_time: 3.6069  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00011988  max_mem: 5735M\n",
      "\u001b[32m[06/30 01:10:24 d2.utils.events]: \u001b[0m eta: 1:27:21  iter: 139  total_loss: 0.4544  loss_cls: 0.08952  loss_box_reg: 0.2297  loss_mask: 0.1022  loss_rpn_cls: 0.00017  loss_rpn_loc: 0.002197    time: 2.7602  last_time: 3.9859  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00013986  max_mem: 5735M\n",
      "\u001b[32m[06/30 01:11:18 d2.utils.events]: \u001b[0m eta: 1:23:40  iter: 159  total_loss: 0.3603  loss_cls: 0.05967  loss_box_reg: 0.2278  loss_mask: 0.0749  loss_rpn_cls: 0.0001529  loss_rpn_loc: 0.002331    time: 2.7554  last_time: 2.3672  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00015984  max_mem: 5751M\n",
      "\u001b[32m[06/30 01:12:15 d2.utils.events]: \u001b[0m eta: 1:24:08  iter: 179  total_loss: 0.3062  loss_cls: 0.04155  loss_box_reg: 0.1846  loss_mask: 0.06432  loss_rpn_cls: 6.903e-05  loss_rpn_loc: 0.002836    time: 2.7667  last_time: 2.6169  data_time: 0.0017  last_data_time: 0.0013   lr: 0.00017982  max_mem: 5779M\n",
      "\u001b[32m[06/30 01:13:01 d2.utils.events]: \u001b[0m eta: 1:21:16  iter: 199  total_loss: 0.2133  loss_cls: 0.02781  loss_box_reg: 0.1291  loss_mask: 0.0551  loss_rpn_cls: 5.85e-05  loss_rpn_loc: 0.003603    time: 2.7214  last_time: 0.8792  data_time: 0.0017  last_data_time: 0.0014   lr: 0.0001998  max_mem: 5794M\n",
      "\u001b[32m[06/30 01:13:56 d2.utils.events]: \u001b[0m eta: 1:20:10  iter: 219  total_loss: 0.1574  loss_cls: 0.02062  loss_box_reg: 0.08539  loss_mask: 0.04746  loss_rpn_cls: 6.258e-05  loss_rpn_loc: 0.003163    time: 2.7212  last_time: 3.8620  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00021978  max_mem: 5794M\n",
      "\u001b[32m[06/30 01:14:49 d2.utils.events]: \u001b[0m eta: 1:19:13  iter: 239  total_loss: 0.1419  loss_cls: 0.02283  loss_box_reg: 0.07909  loss_mask: 0.04097  loss_rpn_cls: 3.326e-05  loss_rpn_loc: 0.002407    time: 2.7173  last_time: 4.0358  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00023976  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:15:37 d2.utils.events]: \u001b[0m eta: 1:16:22  iter: 259  total_loss: 0.1194  loss_cls: 0.01925  loss_box_reg: 0.05929  loss_mask: 0.03999  loss_rpn_cls: 2.655e-05  loss_rpn_loc: 0.002269    time: 2.6914  last_time: 1.2215  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025974  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:16:36 d2.utils.events]: \u001b[0m eta: 1:16:01  iter: 279  total_loss: 0.1173  loss_cls: 0.02407  loss_box_reg: 0.05592  loss_mask: 0.03768  loss_rpn_cls: 1.024e-05  loss_rpn_loc: 0.001758    time: 2.7105  last_time: 2.2919  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00027972  max_mem: 5808M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:17:32 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 01:17:32 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 01:17:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 01:17:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 01:17:32 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 01:17:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:17:32 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 01:17:32 d2.utils.events]: \u001b[0m eta: 1:16:26  iter: 299  total_loss: 0.1061  loss_cls: 0.01904  loss_box_reg: 0.04682  loss_mask: 0.04048  loss_rpn_cls: 1.267e-05  loss_rpn_loc: 0.00201    time: 2.7163  last_time: 1.8812  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0002997  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:18:31 d2.utils.events]: \u001b[0m eta: 1:15:40  iter: 319  total_loss: 0.118  loss_cls: 0.02091  loss_box_reg: 0.05784  loss_mask: 0.03427  loss_rpn_cls: 4.008e-06  loss_rpn_loc: 0.001913    time: 2.7312  last_time: 2.8814  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00031968  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:19:27 d2.utils.events]: \u001b[0m eta: 1:15:03  iter: 339  total_loss: 0.1046  loss_cls: 0.01911  loss_box_reg: 0.05111  loss_mask: 0.03387  loss_rpn_cls: 3.959e-06  loss_rpn_loc: 0.001851    time: 2.7347  last_time: 3.0988  data_time: 0.0016  last_data_time: 0.0017   lr: 0.00033966  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:20:19 d2.utils.events]: \u001b[0m eta: 1:14:00  iter: 359  total_loss: 0.09802  loss_cls: 0.01762  loss_box_reg: 0.03878  loss_mask: 0.03173  loss_rpn_cls: 1.186e-05  loss_rpn_loc: 0.001736    time: 2.7279  last_time: 3.6216  data_time: 0.0018  last_data_time: 0.0023   lr: 0.00035964  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:21:05 d2.utils.events]: \u001b[0m eta: 1:12:50  iter: 379  total_loss: 0.09269  loss_cls: 0.01704  loss_box_reg: 0.04541  loss_mask: 0.03705  loss_rpn_cls: 1.232e-06  loss_rpn_loc: 0.001637    time: 2.7033  last_time: 1.7421  data_time: 0.0018  last_data_time: 0.0019   lr: 0.00037962  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:22:11 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 399  total_loss: 0.1014  loss_cls: 0.01871  loss_box_reg: 0.04532  loss_mask: 0.02946  loss_rpn_cls: 1.942e-06  loss_rpn_loc: 0.001609    time: 2.7350  last_time: 5.2510  data_time: 0.0017  last_data_time: 0.0016   lr: 0.0003996  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:23:02 d2.utils.events]: \u001b[0m eta: 1:11:18  iter: 419  total_loss: 0.09714  loss_cls: 0.01718  loss_box_reg: 0.04133  loss_mask: 0.0345  loss_rpn_cls: 7.591e-06  loss_rpn_loc: 0.001421    time: 2.7257  last_time: 1.1625  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00041958  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:23:51 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 439  total_loss: 0.08786  loss_cls: 0.01547  loss_box_reg: 0.04014  loss_mask: 0.0284  loss_rpn_cls: 3.673e-06  loss_rpn_loc: 0.001472    time: 2.7141  last_time: 1.1499  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00043956  max_mem: 5808M\n",
      "\u001b[32m[06/30 01:24:47 d2.utils.events]: \u001b[0m eta: 1:09:22  iter: 459  total_loss: 0.09647  loss_cls: 0.01665  loss_box_reg: 0.04432  loss_mask: 0.02884  loss_rpn_cls: 1.153e-06  loss_rpn_loc: 0.001765    time: 2.7175  last_time: 4.9968  data_time: 0.0019  last_data_time: 0.0030   lr: 0.00045954  max_mem: 5822M\n",
      "\u001b[32m[06/30 01:25:41 d2.utils.events]: \u001b[0m eta: 1:08:28  iter: 479  total_loss: 0.07727  loss_cls: 0.01774  loss_box_reg: 0.0339  loss_mask: 0.02591  loss_rpn_cls: 1.473e-06  loss_rpn_loc: 0.001306    time: 2.7166  last_time: 2.9602  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00047952  max_mem: 5822M\n",
      "\u001b[32m[06/30 01:26:34 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 499  total_loss: 0.09208  loss_cls: 0.01538  loss_box_reg: 0.04084  loss_mask: 0.03302  loss_rpn_cls: 6.621e-07  loss_rpn_loc: 0.001233    time: 2.7142  last_time: 3.7291  data_time: 0.0016  last_data_time: 0.0013   lr: 0.0004995  max_mem: 5822M\n",
      "\u001b[32m[06/30 01:27:33 d2.utils.events]: \u001b[0m eta: 1:07:03  iter: 519  total_loss: 0.08532  loss_cls: 0.01605  loss_box_reg: 0.03811  loss_mask: 0.029  loss_rpn_cls: 6.791e-07  loss_rpn_loc: 0.001435    time: 2.7230  last_time: 1.9827  data_time: 0.0018  last_data_time: 0.0015   lr: 0.00051948  max_mem: 5822M\n",
      "\u001b[32m[06/30 01:28:23 d2.utils.events]: \u001b[0m eta: 1:05:53  iter: 539  total_loss: 0.07948  loss_cls: 0.01484  loss_box_reg: 0.03262  loss_mask: 0.03013  loss_rpn_cls: 2.118e-06  loss_rpn_loc: 0.001492    time: 2.7150  last_time: 2.3101  data_time: 0.0018  last_data_time: 0.0015   lr: 0.00053946  max_mem: 5822M\n",
      "\u001b[32m[06/30 01:29:23 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 559  total_loss: 0.08372  loss_cls: 0.01473  loss_box_reg: 0.03919  loss_mask: 0.02887  loss_rpn_cls: 1.419e-06  loss_rpn_loc: 0.001229    time: 2.7244  last_time: 2.1734  data_time: 0.0016  last_data_time: 0.0019   lr: 0.00055944  max_mem: 5822M\n",
      "\u001b[32m[06/30 01:30:12 d2.utils.events]: \u001b[0m eta: 1:04:10  iter: 579  total_loss: 0.07444  loss_cls: 0.01246  loss_box_reg: 0.03267  loss_mask: 0.02804  loss_rpn_cls: 1.332e-06  loss_rpn_loc: 0.001588    time: 2.7151  last_time: 3.2928  data_time: 0.0017  last_data_time: 0.0012   lr: 0.00057942  max_mem: 5826M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:31:05 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 01:31:05 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 01:31:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 01:31:05 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 01:31:05 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 01:31:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:31:05 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 01:31:05 d2.utils.events]: \u001b[0m eta: 1:03:16  iter: 599  total_loss: 0.07623  loss_cls: 0.01428  loss_box_reg: 0.03277  loss_mask: 0.03049  loss_rpn_cls: 9.868e-07  loss_rpn_loc: 0.001151    time: 2.7129  last_time: 0.8745  data_time: 0.0017  last_data_time: 0.0015   lr: 0.0005994  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:31:59 d2.utils.events]: \u001b[0m eta: 1:02:22  iter: 619  total_loss: 0.07834  loss_cls: 0.01315  loss_box_reg: 0.03309  loss_mask: 0.02896  loss_rpn_cls: 7.01e-07  loss_rpn_loc: 0.001316    time: 2.7131  last_time: 2.3689  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00061938  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:32:55 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 639  total_loss: 0.07697  loss_cls: 0.01242  loss_box_reg: 0.03001  loss_mask: 0.02732  loss_rpn_cls: 1.34e-06  loss_rpn_loc: 0.001328    time: 2.7154  last_time: 3.2738  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00063936  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:33:52 d2.utils.events]: \u001b[0m eta: 1:00:48  iter: 659  total_loss: 0.07135  loss_cls: 0.01389  loss_box_reg: 0.03515  loss_mask: 0.02367  loss_rpn_cls: 2.135e-06  loss_rpn_loc: 0.001384    time: 2.7191  last_time: 2.7236  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00065934  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:34:45 d2.utils.events]: \u001b[0m eta: 0:59:43  iter: 679  total_loss: 0.07516  loss_cls: 0.01191  loss_box_reg: 0.03117  loss_mask: 0.02685  loss_rpn_cls: 2.976e-06  loss_rpn_loc: 0.00129    time: 2.7178  last_time: 2.2917  data_time: 0.0016  last_data_time: 0.0020   lr: 0.00067932  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:35:38 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 699  total_loss: 0.07528  loss_cls: 0.01321  loss_box_reg: 0.03229  loss_mask: 0.02891  loss_rpn_cls: 9.482e-07  loss_rpn_loc: 0.001308    time: 2.7149  last_time: 2.6740  data_time: 0.0016  last_data_time: 0.0019   lr: 0.0006993  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:36:31 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 719  total_loss: 0.06903  loss_cls: 0.01157  loss_box_reg: 0.02962  loss_mask: 0.02535  loss_rpn_cls: 1.427e-06  loss_rpn_loc: 0.001271    time: 2.7140  last_time: 3.1884  data_time: 0.0018  last_data_time: 0.0022   lr: 0.00071928  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:37:29 d2.utils.events]: \u001b[0m eta: 0:57:01  iter: 739  total_loss: 0.05953  loss_cls: 0.01062  loss_box_reg: 0.02595  loss_mask: 0.02232  loss_rpn_cls: 9.762e-06  loss_rpn_loc: 0.001213    time: 2.7178  last_time: 3.3563  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00073926  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:38:31 d2.utils.events]: \u001b[0m eta: 0:56:26  iter: 759  total_loss: 0.06523  loss_cls: 0.01076  loss_box_reg: 0.02821  loss_mask: 0.02624  loss_rpn_cls: 3.191e-06  loss_rpn_loc: 0.001158    time: 2.7281  last_time: 2.1361  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00075924  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:39:20 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 779  total_loss: 0.07035  loss_cls: 0.01114  loss_box_reg: 0.03007  loss_mask: 0.02474  loss_rpn_cls: 2.518e-06  loss_rpn_loc: 0.001218    time: 2.7211  last_time: 2.4584  data_time: 0.0016  last_data_time: 0.0014   lr: 0.00077922  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:40:09 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 799  total_loss: 0.06419  loss_cls: 0.01  loss_box_reg: 0.03078  loss_mask: 0.02437  loss_rpn_cls: 9.746e-07  loss_rpn_loc: 0.0009971    time: 2.7142  last_time: 2.4819  data_time: 0.0017  last_data_time: 0.0013   lr: 0.0007992  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:40:58 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 819  total_loss: 0.06849  loss_cls: 0.009459  loss_box_reg: 0.02899  loss_mask: 0.02434  loss_rpn_cls: 1.239e-06  loss_rpn_loc: 0.001259    time: 2.7074  last_time: 2.1753  data_time: 0.0016  last_data_time: 0.0014   lr: 0.00081918  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:41:51 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 839  total_loss: 0.06  loss_cls: 0.00875  loss_box_reg: 0.02254  loss_mask: 0.02292  loss_rpn_cls: 4.245e-06  loss_rpn_loc: 0.001239    time: 2.7066  last_time: 2.8612  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00083916  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:42:45 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 859  total_loss: 0.06592  loss_cls: 0.0104  loss_box_reg: 0.02523  loss_mask: 0.03005  loss_rpn_cls: 1.249e-06  loss_rpn_loc: 0.001118    time: 2.7061  last_time: 3.7427  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00085914  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:43:37 d2.utils.events]: \u001b[0m eta: 0:50:39  iter: 879  total_loss: 0.06681  loss_cls: 0.01085  loss_box_reg: 0.03085  loss_mask: 0.02427  loss_rpn_cls: 8.078e-07  loss_rpn_loc: 0.001178    time: 2.7037  last_time: 2.4548  data_time: 0.0018  last_data_time: 0.0015   lr: 0.00087912  max_mem: 5826M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:44:31 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 01:44:31 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 01:44:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 01:44:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 01:44:31 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 01:44:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:44:31 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 01:44:31 d2.utils.events]: \u001b[0m eta: 0:49:45  iter: 899  total_loss: 0.06568  loss_cls: 0.01043  loss_box_reg: 0.0291  loss_mask: 0.02146  loss_rpn_cls: 1.251e-06  loss_rpn_loc: 0.001128    time: 2.7038  last_time: 2.0678  data_time: 0.0017  last_data_time: 0.0019   lr: 0.0008991  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:45:21 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 919  total_loss: 0.05934  loss_cls: 0.009738  loss_box_reg: 0.02709  loss_mask: 0.02181  loss_rpn_cls: 1.22e-06  loss_rpn_loc: 0.0009829    time: 2.6998  last_time: 3.5089  data_time: 0.0018  last_data_time: 0.0016   lr: 0.00091908  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:46:23 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 939  total_loss: 0.06574  loss_cls: 0.01042  loss_box_reg: 0.02555  loss_mask: 0.02723  loss_rpn_cls: 1.115e-06  loss_rpn_loc: 0.001097    time: 2.7075  last_time: 3.8318  data_time: 0.0019  last_data_time: 0.0022   lr: 0.00093906  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:47:21 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 959  total_loss: 0.06432  loss_cls: 0.009548  loss_box_reg: 0.02818  loss_mask: 0.02287  loss_rpn_cls: 2.059e-06  loss_rpn_loc: 0.001449    time: 2.7118  last_time: 3.0720  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00095904  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:48:17 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 979  total_loss: 0.06967  loss_cls: 0.01015  loss_box_reg: 0.03043  loss_mask: 0.02654  loss_rpn_cls: 2.495e-06  loss_rpn_loc: 0.00112    time: 2.7139  last_time: 2.8402  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00097902  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:49:01 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 999  total_loss: 0.05881  loss_cls: 0.008458  loss_box_reg: 0.02767  loss_mask: 0.02175  loss_rpn_cls: 1.839e-06  loss_rpn_loc: 0.0009294    time: 2.7039  last_time: 2.2917  data_time: 0.0016  last_data_time: 0.0017   lr: 0.000999  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:49:56 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 1019  total_loss: 0.06809  loss_cls: 0.009967  loss_box_reg: 0.02784  loss_mask: 0.0258  loss_rpn_cls: 1.808e-06  loss_rpn_loc: 0.001041    time: 2.7045  last_time: 4.2456  data_time: 0.0018  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:50:54 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 1039  total_loss: 0.06548  loss_cls: 0.008013  loss_box_reg: 0.03285  loss_mask: 0.02129  loss_rpn_cls: 8.459e-07  loss_rpn_loc: 0.0009455    time: 2.7083  last_time: 3.4023  data_time: 0.0017  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:51:47 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 1059  total_loss: 0.06334  loss_cls: 0.0102  loss_box_reg: 0.03167  loss_mask: 0.0203  loss_rpn_cls: 2.442e-06  loss_rpn_loc: 0.0007998    time: 2.7070  last_time: 2.4129  data_time: 0.0019  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:52:42 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 1079  total_loss: 0.06351  loss_cls: 0.01065  loss_box_reg: 0.0272  loss_mask: 0.02257  loss_rpn_cls: 1.916e-06  loss_rpn_loc: 0.001164    time: 2.7083  last_time: 2.1732  data_time: 0.0017  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:53:39 d2.utils.events]: \u001b[0m eta: 0:40:54  iter: 1099  total_loss: 0.06056  loss_cls: 0.008339  loss_box_reg: 0.02446  loss_mask: 0.02216  loss_rpn_cls: 7.432e-06  loss_rpn_loc: 0.000857    time: 2.7105  last_time: 3.2875  data_time: 0.0017  last_data_time: 0.0017   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:54:34 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 1119  total_loss: 0.06186  loss_cls: 0.007545  loss_box_reg: 0.02442  loss_mask: 0.02462  loss_rpn_cls: 3.062e-06  loss_rpn_loc: 0.001006    time: 2.7115  last_time: 2.0064  data_time: 0.0019  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:55:27 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 1139  total_loss: 0.0667  loss_cls: 0.009147  loss_box_reg: 0.02985  loss_mask: 0.02212  loss_rpn_cls: 1.302e-06  loss_rpn_loc: 0.001075    time: 2.7103  last_time: 3.2530  data_time: 0.0016  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:56:20 d2.utils.events]: \u001b[0m eta: 0:38:15  iter: 1159  total_loss: 0.06016  loss_cls: 0.01068  loss_box_reg: 0.02736  loss_mask: 0.02019  loss_rpn_cls: 2.749e-06  loss_rpn_loc: 0.001024    time: 2.7088  last_time: 0.9923  data_time: 0.0017  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:57:16 d2.utils.events]: \u001b[0m eta: 0:37:16  iter: 1179  total_loss: 0.05571  loss_cls: 0.008612  loss_box_reg: 0.024  loss_mask: 0.01956  loss_rpn_cls: 6.097e-06  loss_rpn_loc: 0.0008066    time: 2.7103  last_time: 2.0716  data_time: 0.0018  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:58:13 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 01:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 01:58:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 01:58:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 01:58:13 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 01:58:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:58:13 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 01:58:13 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 1199  total_loss: 0.0573  loss_cls: 0.008099  loss_box_reg: 0.02214  loss_mask: 0.02255  loss_rpn_cls: 2.588e-06  loss_rpn_loc: 0.001057    time: 2.7131  last_time: 2.5007  data_time: 0.0017  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 01:59:09 d2.utils.events]: \u001b[0m eta: 0:35:34  iter: 1219  total_loss: 0.05762  loss_cls: 0.008828  loss_box_reg: 0.02347  loss_mask: 0.02413  loss_rpn_cls: 5.348e-06  loss_rpn_loc: 0.0008628    time: 2.7142  last_time: 3.8534  data_time: 0.0016  last_data_time: 0.0024   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:00:06 d2.utils.events]: \u001b[0m eta: 0:34:40  iter: 1239  total_loss: 0.04823  loss_cls: 0.007086  loss_box_reg: 0.01905  loss_mask: 0.02183  loss_rpn_cls: 6.651e-06  loss_rpn_loc: 0.0008595    time: 2.7162  last_time: 3.8780  data_time: 0.0017  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:01:12 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 1259  total_loss: 0.05938  loss_cls: 0.008203  loss_box_reg: 0.02478  loss_mask: 0.02172  loss_rpn_cls: 4.164e-06  loss_rpn_loc: 0.001118    time: 2.7254  last_time: 3.2820  data_time: 0.0016  last_data_time: 0.0017   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:02:14 d2.utils.events]: \u001b[0m eta: 0:33:15  iter: 1279  total_loss: 0.05598  loss_cls: 0.008455  loss_box_reg: 0.02109  loss_mask: 0.02297  loss_rpn_cls: 1.873e-06  loss_rpn_loc: 0.0008033    time: 2.7315  last_time: 4.1040  data_time: 0.0016  last_data_time: 0.0017   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:03:05 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 1299  total_loss: 0.05613  loss_cls: 0.008925  loss_box_reg: 0.02279  loss_mask: 0.01994  loss_rpn_cls: 2.39e-06  loss_rpn_loc: 0.000914    time: 2.7286  last_time: 2.9043  data_time: 0.0017  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:03:57 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 1319  total_loss: 0.05631  loss_cls: 0.008673  loss_box_reg: 0.02182  loss_mask: 0.02089  loss_rpn_cls: 1.868e-06  loss_rpn_loc: 0.00112    time: 2.7271  last_time: 1.1560  data_time: 0.0017  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:04:53 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 1339  total_loss: 0.04648  loss_cls: 0.006166  loss_box_reg: 0.0184  loss_mask: 0.01981  loss_rpn_cls: 1.493e-06  loss_rpn_loc: 0.0007897    time: 2.7283  last_time: 2.4535  data_time: 0.0018  last_data_time: 0.0020   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:05:48 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 1359  total_loss: 0.05102  loss_cls: 0.008628  loss_box_reg: 0.02152  loss_mask: 0.02042  loss_rpn_cls: 1.984e-06  loss_rpn_loc: 0.0008626    time: 2.7286  last_time: 3.0156  data_time: 0.0019  last_data_time: 0.0023   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:06:42 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 1379  total_loss: 0.05582  loss_cls: 0.008511  loss_box_reg: 0.02117  loss_mask: 0.02107  loss_rpn_cls: 3.031e-06  loss_rpn_loc: 0.0008783    time: 2.7281  last_time: 2.8682  data_time: 0.0017  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:07:42 d2.utils.events]: \u001b[0m eta: 0:27:40  iter: 1399  total_loss: 0.05337  loss_cls: 0.008351  loss_box_reg: 0.02357  loss_mask: 0.02037  loss_rpn_cls: 2.681e-06  loss_rpn_loc: 0.0007646    time: 2.7316  last_time: 3.3733  data_time: 0.0019  last_data_time: 0.0017   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:08:32 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 1419  total_loss: 0.05271  loss_cls: 0.008567  loss_box_reg: 0.02193  loss_mask: 0.02008  loss_rpn_cls: 5.225e-06  loss_rpn_loc: 0.0007297    time: 2.7284  last_time: 1.7810  data_time: 0.0017  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:09:22 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 1439  total_loss: 0.05085  loss_cls: 0.008073  loss_box_reg: 0.0215  loss_mask: 0.01893  loss_rpn_cls: 2.919e-06  loss_rpn_loc: 0.001014    time: 2.7256  last_time: 2.7104  data_time: 0.0017  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:10:20 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 1459  total_loss: 0.05828  loss_cls: 0.009419  loss_box_reg: 0.02311  loss_mask: 0.02166  loss_rpn_cls: 6.355e-06  loss_rpn_loc: 0.0008626    time: 2.7276  last_time: 1.8757  data_time: 0.0017  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:11:20 d2.utils.events]: \u001b[0m eta: 0:24:02  iter: 1479  total_loss: 0.04834  loss_cls: 0.006152  loss_box_reg: 0.01996  loss_mask: 0.01808  loss_rpn_cls: 4.428e-06  loss_rpn_loc: 0.000891    time: 2.7314  last_time: 1.3675  data_time: 0.0017  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:12:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 02:12:16 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 02:12:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 02:12:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 02:12:16 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 02:12:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:12:16 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 02:12:16 d2.utils.events]: \u001b[0m eta: 0:23:06  iter: 1499  total_loss: 0.05332  loss_cls: 0.00775  loss_box_reg: 0.02062  loss_mask: 0.02049  loss_rpn_cls: 4.39e-06  loss_rpn_loc: 0.000938    time: 2.7322  last_time: 3.3150  data_time: 0.0016  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:13:15 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 1519  total_loss: 0.04806  loss_cls: 0.006023  loss_box_reg: 0.02181  loss_mask: 0.01866  loss_rpn_cls: 5.151e-06  loss_rpn_loc: 0.0009412    time: 2.7354  last_time: 2.1983  data_time: 0.0016  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:14:11 d2.utils.events]: \u001b[0m eta: 0:21:18  iter: 1539  total_loss: 0.04753  loss_cls: 0.007017  loss_box_reg: 0.01985  loss_mask: 0.01703  loss_rpn_cls: 4.483e-06  loss_rpn_loc: 0.0006909    time: 2.7362  last_time: 3.0681  data_time: 0.0018  last_data_time: 0.0020   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:15:09 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 1559  total_loss: 0.0476  loss_cls: 0.007604  loss_box_reg: 0.01781  loss_mask: 0.01869  loss_rpn_cls: 4.941e-06  loss_rpn_loc: 0.0009833    time: 2.7380  last_time: 3.8814  data_time: 0.0017  last_data_time: 0.0019   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:15:57 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 1579  total_loss: 0.04834  loss_cls: 0.00665  loss_box_reg: 0.02023  loss_mask: 0.01852  loss_rpn_cls: 3.518e-06  loss_rpn_loc: 0.0008604    time: 2.7340  last_time: 2.9794  data_time: 0.0017  last_data_time: 0.0025   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:16:51 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 1599  total_loss: 0.0452  loss_cls: 0.006499  loss_box_reg: 0.01927  loss_mask: 0.01799  loss_rpn_cls: 3.688e-06  loss_rpn_loc: 0.0008414    time: 2.7335  last_time: 1.0656  data_time: 0.0017  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:17:48 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 1619  total_loss: 0.05283  loss_cls: 0.006549  loss_box_reg: 0.02425  loss_mask: 0.01905  loss_rpn_cls: 4.168e-06  loss_rpn_loc: 0.0006782    time: 2.7345  last_time: 2.3009  data_time: 0.0016  last_data_time: 0.0013   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:18:46 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 1639  total_loss: 0.05221  loss_cls: 0.009036  loss_box_reg: 0.02339  loss_mask: 0.01824  loss_rpn_cls: 5.837e-06  loss_rpn_loc: 0.0009153    time: 2.7368  last_time: 3.5340  data_time: 0.0016  last_data_time: 0.0017   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:19:40 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 1659  total_loss: 0.04395  loss_cls: 0.005643  loss_box_reg: 0.01928  loss_mask: 0.01608  loss_rpn_cls: 3.78e-06  loss_rpn_loc: 0.0008444    time: 2.7365  last_time: 3.3417  data_time: 0.0016  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:20:39 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 1679  total_loss: 0.0441  loss_cls: 0.007169  loss_box_reg: 0.01954  loss_mask: 0.01785  loss_rpn_cls: 3.945e-06  loss_rpn_loc: 0.0008119    time: 2.7390  last_time: 2.2935  data_time: 0.0018  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:21:25 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 1699  total_loss: 0.05417  loss_cls: 0.008376  loss_box_reg: 0.02382  loss_mask: 0.01878  loss_rpn_cls: 6.999e-06  loss_rpn_loc: 0.001023    time: 2.7335  last_time: 3.4258  data_time: 0.0017  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:22:15 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 1719  total_loss: 0.05565  loss_cls: 0.009207  loss_box_reg: 0.02174  loss_mask: 0.02067  loss_rpn_cls: 8.306e-06  loss_rpn_loc: 0.0009117    time: 2.7310  last_time: 2.5930  data_time: 0.0018  last_data_time: 0.0022   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:23:16 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 1739  total_loss: 0.04369  loss_cls: 0.006553  loss_box_reg: 0.01905  loss_mask: 0.01647  loss_rpn_cls: 9.611e-06  loss_rpn_loc: 0.000774    time: 2.7344  last_time: 1.7411  data_time: 0.0017  last_data_time: 0.0014   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:24:11 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 1759  total_loss: 0.04546  loss_cls: 0.007456  loss_box_reg: 0.01767  loss_mask: 0.01735  loss_rpn_cls: 4.99e-06  loss_rpn_loc: 0.0008205    time: 2.7348  last_time: 2.4554  data_time: 0.0017  last_data_time: 0.0019   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:24:57 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 1779  total_loss: 0.05321  loss_cls: 0.006829  loss_box_reg: 0.02257  loss_mask: 0.02143  loss_rpn_cls: 7.944e-06  loss_rpn_loc: 0.0007634    time: 2.7302  last_time: 2.0323  data_time: 0.0017  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:25:44 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 02:25:44 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 02:25:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 02:25:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 02:25:44 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 02:25:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:25:44 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[06/30 02:25:44 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 1799  total_loss: 0.04413  loss_cls: 0.006339  loss_box_reg: 0.01856  loss_mask: 0.01716  loss_rpn_cls: 4.836e-06  loss_rpn_loc: 0.0008288    time: 2.7259  last_time: 1.5533  data_time: 0.0017  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:26:43 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1819  total_loss: 0.04383  loss_cls: 0.007794  loss_box_reg: 0.01903  loss_mask: 0.01751  loss_rpn_cls: 3.568e-06  loss_rpn_loc: 0.0006692    time: 2.7279  last_time: 4.0580  data_time: 0.0018  last_data_time: 0.0024   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:27:35 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1839  total_loss: 0.04164  loss_cls: 0.005677  loss_box_reg: 0.01812  loss_mask: 0.01913  loss_rpn_cls: 4.734e-06  loss_rpn_loc: 0.0008124    time: 2.7268  last_time: 2.8386  data_time: 0.0015  last_data_time: 0.0012   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:28:28 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 1859  total_loss: 0.04244  loss_cls: 0.006276  loss_box_reg: 0.01694  loss_mask: 0.01947  loss_rpn_cls: 4.504e-06  loss_rpn_loc: 0.0007854    time: 2.7261  last_time: 2.8829  data_time: 0.0017  last_data_time: 0.0017   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:29:12 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1879  total_loss: 0.0492  loss_cls: 0.00842  loss_box_reg: 0.01913  loss_mask: 0.01984  loss_rpn_cls: 3.811e-06  loss_rpn_loc: 0.0007414    time: 2.7202  last_time: 2.8507  data_time: 0.0016  last_data_time: 0.0015   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:30:07 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 1899  total_loss: 0.04446  loss_cls: 0.007835  loss_box_reg: 0.01828  loss_mask: 0.01786  loss_rpn_cls: 5.363e-06  loss_rpn_loc: 0.0007524    time: 2.7205  last_time: 2.4677  data_time: 0.0018  last_data_time: 0.0027   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:31:01 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 1919  total_loss: 0.03959  loss_cls: 0.006357  loss_box_reg: 0.01557  loss_mask: 0.01674  loss_rpn_cls: 6.786e-06  loss_rpn_loc: 0.0007273    time: 2.7207  last_time: 5.0951  data_time: 0.0016  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:31:54 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 1939  total_loss: 0.04902  loss_cls: 0.008073  loss_box_reg: 0.02161  loss_mask: 0.01727  loss_rpn_cls: 1.899e-06  loss_rpn_loc: 0.0006954    time: 2.7196  last_time: 2.5312  data_time: 0.0015  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:32:48 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1959  total_loss: 0.04697  loss_cls: 0.007148  loss_box_reg: 0.01996  loss_mask: 0.01732  loss_rpn_cls: 4.41e-06  loss_rpn_loc: 0.0007939    time: 2.7195  last_time: 2.3437  data_time: 0.0019  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:33:42 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 1979  total_loss: 0.04619  loss_cls: 0.007423  loss_box_reg: 0.02053  loss_mask: 0.01707  loss_rpn_cls: 4.927e-06  loss_rpn_loc: 0.0009393    time: 2.7194  last_time: 1.8920  data_time: 0.0018  last_data_time: 0.0016   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:34:41 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.04329  loss_cls: 0.00527  loss_box_reg: 0.01849  loss_mask: 0.01728  loss_rpn_cls: 3.479e-06  loss_rpn_loc: 0.0007971    time: 2.7212  last_time: 1.5734  data_time: 0.0016  last_data_time: 0.0018   lr: 0.001  max_mem: 5826M\n",
      "\u001b[32m[06/30 02:34:41 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 1:30:36 (2.7212 s / it)\n",
      "\u001b[32m[06/30 02:34:41 d2.engine.hooks]: \u001b[0mTotal training time: 1:30:38 (0:00:01 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:34:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/30 02:34:41 d2.data.datasets.coco]: \u001b[0mLoaded 9 images in COCO format from d:\\Tank_proj\\tank_edge\\tank_edges-1\\test\\_annotations.coco.json\n",
      "\u001b[32m[06/30 02:34:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/30 02:34:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[06/30 02:34:41 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/30 02:34:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:34:41 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XMPKQ28GRna"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flInE1L-XTfx"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:30.387236Z",
     "start_time": "2024-06-25T08:07:28.649281Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2265,
     "status": "ok",
     "timestamp": 1668005909534,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "vsByFDFbQwLi",
    "outputId": "db8479c0-a286-4e83-e064-9ae4ebad3aba"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:56.682926Z",
     "start_time": "2024-06-25T08:07:33.893951Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "hmAcBbpXX-Rh"
   },
   "outputs": [],
   "source": [
    "dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)\n",
    "\n",
    "for d in dataset_valid:\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "\n",
    "    visualizer = Visualizer(\n",
    "        img[:, :, ::-1],\n",
    "        metadata=metadata,\n",
    "        scale=0.8,\n",
    "        instance_mode=ColorMode.IMAGE_BW\n",
    "    )\n",
    "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(\"validation\",out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.97\n",
    "      # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Visualize the results\n",
    "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Display the image\n",
    "    result_image = out.get_image()[:, :, ::-1]\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # Display the frame\n",
    "        result_frame = out.get_image()[:, :, ::-1]\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "# config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/config.yaml\"\n",
    "# weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_quadrilaterals_and_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/path_detect/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m predictor \u001b[38;5;241m=\u001b[39m load_model(config_file, weights_file)\n\u001b[1;32m---> 88\u001b[0m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 77\u001b[0m, in \u001b[0;36mprocess_folder\u001b[1;34m(predictor, folder_path)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m---> 77\u001b[0m         \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mov\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     79\u001b[0m         process_video(predictor, file_path)\n",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(predictor, image_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m predictor(image)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Draw quadrilaterals and masks on the image\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m result_image \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_quadrilaterals_and_masks\u001b[49m(image, outputs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[0;32m     51\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, result_image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'draw_quadrilaterals_and_masks' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import numpy as np\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.97  # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def draw_quadrilaterals(image, outputs, deformation_threshold=0.05):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    for mask in masks:\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a quadrilateral\n",
    "            epsilon = deformation_threshold * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Ensure it's a quadrilateral (4 sides)\n",
    "            if len(approx) == 4:\n",
    "                # Draw the quadrilateral\n",
    "                cv2.polylines(image, [approx], True, (0, 255, 0), 2)\n",
    "                \n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Draw quadrilaterals and masks on the image\n",
    "    result_image = draw_quadrilaterals_and_masks(image, outputs)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        result_frame = draw_quadrilaterals_and_masks(frame, outputs)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daanish Mittal\\anaconda3\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved result for D:/path_detect/test\\IMG1551952615468_jpg.rf.18ba64b8924724efc330d01981c585bd.jpg to D:/path_detect/output\\IMG1551952615468_jpg.rf.18ba64b8924724efc330d01981c585bd.jpg\n",
      "Saved result for D:/path_detect/test\\IMG1554039051734_jpg.rf.347e3b8c0f42e174cf14976b3a98d14c.jpg to D:/path_detect/output\\IMG1554039051734_jpg.rf.347e3b8c0f42e174cf14976b3a98d14c.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-25 at 23.15.50_4d2547a6.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-25 at 23.15.50_4d2547a6.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-25 at 23.43.27_aa0561da.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-25 at 23.43.27_aa0561da.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-25 at 23.49.54_963bf197.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-25 at 23.49.54_963bf197.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-28 at 16.00.55_072c0a4e.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-28 at 16.00.55_072c0a4e.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Image 2024-06-28 at 16.01.12_0993b44b.jpg to D:/path_detect/output\\WhatsApp Image 2024-06-28 at 16.01.12_0993b44b.jpg\n",
      "Saved result for D:/path_detect/test\\WhatsApp Video 2024-06-16 at 3.26.mp4 to D:/path_detect/output\\WhatsApp Video 2024-06-16 at 3.26.mp4\n",
      "Saved result for D:/path_detect/test\\WhatsApp Video 2024-06-26 at 13.39.29_71c34361.mp4 to D:/path_detect/output\\WhatsApp Video 2024-06-26 at 13.39.29_71c34361.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import numpy as np\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.95  # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def draw_quadrilaterals(image, outputs):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    for mask in masks:\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a quadrilateral\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Calculate the area of the mask and the quadrilateral\n",
    "            mask_area = cv2.contourArea(contour)\n",
    "            quad_area = cv2.contourArea(approx)\n",
    "            \n",
    "            # Check if mask_area is zero (handle edge case)\n",
    "            if mask_area <= 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the percentage of the mask area outside the quadrilateral\n",
    "            outside_area = mask_area - quad_area\n",
    "            outside_percentage = outside_area / mask_area if mask_area > 0 else 0\n",
    "            \n",
    "            # Determine the color of the quadrilateral\n",
    "            color = (0, 255, 0) if outside_percentage <= 0.12 else (0, 0, 255)\n",
    "            \n",
    "            if len(approx) >= 4:\n",
    "                cv2.polylines(image, [approx], True, color, 2)\n",
    "                \n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image(predictor, image_path, output_folder):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Draw quadrilaterals on the image\n",
    "    result_image = draw_quadrilaterals(image, outputs)\n",
    "    \n",
    "    # Save the result image\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "    print(f'Saved result for {image_path} to {output_path}')\n",
    "\n",
    "def process_video(predictor, video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_path = os.path.join(output_folder, os.path.basename(video_path))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        result_frame = draw_quadrilaterals(frame, outputs)\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(result_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f'Saved result for {video_path} to {output_path}')\n",
    "\n",
    "def process_folder(predictor, folder_path, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path, output_folder)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path, output_folder)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "output_folder = \"D:/path_detect/output\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ramp_edges(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 300, 250, apertureSize=3)\n",
    "\n",
    "    # Create a mask to remove boundary edges\n",
    "    height, width = edges.shape\n",
    "    mask = np.ones_like(edges)\n",
    "    border = 10  # Adjust this value to change the border size\n",
    "    mask[:border, :] = 0\n",
    "    mask[-border:, :] = 0\n",
    "    mask[:, :border] = 0\n",
    "    mask[:, -border:] = 0\n",
    "\n",
    "    # Apply the mask to remove boundary edges\n",
    "    edges = cv2.bitwise_and(edges, edges, mask=mask)\n",
    "\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1.1, np.pi / 180,200)\n",
    "\n",
    "\n",
    "    return lines\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    # Draw the lines on the image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def process_video(video_source=0):\n",
    "    # Open the video source (0 for webcam, or a filename)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect ramp edges\n",
    "        lines = detect_ramp_edges(frame)\n",
    "\n",
    "        # Draw detected lines on the frame\n",
    "        frame_with_lines = draw_lines(frame, lines)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Detected Ramp Edges', frame_with_lines)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('D:/path_detect/video1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ramp_edges(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 100, 200, apertureSize=3)\n",
    "\n",
    "    # Create a mask to remove boundary edges\n",
    "    height, width = edges.shape\n",
    "    mask = np.ones_like(edges)\n",
    "    border = 10  # Adjust this value to change the border size\n",
    "    mask[:border, :] = 0\n",
    "    mask[-border:, :] = 0\n",
    "    mask[:, :border] = 0\n",
    "    mask[:, -border:] = 0\n",
    "\n",
    "    # Apply the mask to remove boundary edges\n",
    "    edges = cv2.bitwise_and(edges, edges, mask=mask)\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1.1, np.pi / 180, 200)\n",
    "\n",
    "    return lines\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    # Draw the lines on the image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def process_video(video_source=0):\n",
    "    # Open the video source (0 for webcam, or a filename)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect ramp edges\n",
    "        lines = detect_ramp_edges(frame)\n",
    "\n",
    "        # Draw detected lines on the frame\n",
    "        frame_with_lines = draw_lines(frame, lines)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Detected Ramp Edges', frame_with_lines)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video()  # Default is the webcam, pass a video file path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1Wkuq4DLHD7MG5HgpEqiytvEjvNK2sYAx",
     "timestamp": 1719261218111
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
