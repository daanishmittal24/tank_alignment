{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZBUwM3tyFWS"
   },
   "source": [
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MJ8SshpLaU3"
   },
   "source": [
    "## Install Detectron2 and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:27.100950Z",
     "start_time": "2024-06-25T07:59:43.324225Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51415,
     "status": "ok",
     "timestamp": 1719261763571,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "fM1JmUCQLdKp",
    "outputId": "cb684e1a-65eb-4798-eb32-28ef5b785883"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V8w1ew59buh"
   },
   "source": [
    "Now is a good time to confirm that we have the right versions of the libraries at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4612,
     "status": "error",
     "timestamp": 1719261915922,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "sqCNglJXRro5",
    "outputId": "3f148ff1-b579-4dfa-c1f0-adb5bdda4c98"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"iopath<0.1.10,>=0.1.7\"\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "import pkg_resources\n",
    "print(\"detectron2:\", pkg_resources.get_distribution(\"detectron2\").version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:00:40.273497Z",
     "start_time": "2024-06-25T08:00:37.778861Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "error",
     "timestamp": 1719261789459,
     "user": {
      "displayName": "Daanish Mittal",
      "userId": "09086078631529623014"
     },
     "user_tz": -330
    },
    "id": "DIEKfPKFmW54",
    "outputId": "1eae8bc5-084a-4dd2-bcdd-00efdcfc6330"
   },
   "outputs": [],
   "source": [
    "# COMMON LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# TRAINING\n",
    "from detectron2.engine import DefaultTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOszeLVlErvk"
   },
   "source": [
    "## Run a Pre-trained Detectron2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:01:49.176003Z",
     "start_time": "2024-06-25T08:00:40.278498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 2681,
     "status": "ok",
     "timestamp": 1668002463033,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "T8sfLDV7FTYD",
    "outputId": "0e8eea7a-6407-4cb5-a7b8-6f4997bacde0"
   },
   "outputs": [],
   "source": [
    "# !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "# image = cv2.imread(\"./input.jpg\")\n",
    "# cv2.imshow('Display Window', image)  # 'Display Window' is the name of the window\n",
    "# cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "# cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:05.116019Z",
     "start_time": "2024-06-25T08:01:49.193280Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFkJOTWvxu6G"
   },
   "source": [
    "## COCO Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:02:42.536499Z",
     "start_time": "2024-06-25T08:02:25.897211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14044,
     "status": "ok",
     "timestamp": 1668003461405,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "grFIdy8ynP-7",
    "outputId": "d05be873-4ac3-4d10-d88b-fa053a263c90"
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"RovqaIFPpcekpUVWjRke\")\n",
    "project = rf.workspace(\"tank-5yib6\").project(\"tank_edges\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco-segmentation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoB31yi4AoYs"
   },
   "source": [
    "### Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HopUGOyW853G"
   },
   "source": [
    "When you use Detectron2, before you actually train the model you need to [register it](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-coco-format-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:35.787965Z",
     "start_time": "2024-06-25T08:05:35.780944Z"
    },
    "id": "KbI2PNEZF3sU"
   },
   "outputs": [],
   "source": [
    "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
    "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:38.778124Z",
     "start_time": "2024-06-25T08:05:38.650598Z"
    },
    "id": "jntOI8GJG2ks"
   },
   "outputs": [],
   "source": [
    "# TRAIN SET\n",
    "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
    "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
    "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TRAIN_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# TEST SET\n",
    "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
    "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
    "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TEST_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
    ")\n",
    "\n",
    "# VALID SET\n",
    "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
    "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
    "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=VALID_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=VALID_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCY1UWNCtnq"
   },
   "source": [
    "We can now confirm that our custom dataset was correctly registered using [MetadataCatalog](https://detectron2.readthedocs.io/en/latest/modules/data.html#detectron2.data.MetadataCatalog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:42.883439Z",
     "start_time": "2024-06-25T08:05:42.865442Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1668003586610,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "LR8ha4EHCkA-",
    "outputId": "6506603a-3742-43ee-af5d-7f842426d25d"
   },
   "outputs": [],
   "source": [
    "[\n",
    "    data_set\n",
    "    for data_set\n",
    "    in MetadataCatalog.list()\n",
    "    if data_set.startswith(DATA_SET_NAME)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpU2L3UL922"
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Bd_-oCA90a"
   },
   "source": [
    "Let's take a look at single entry from out train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:05:47.307052Z",
     "start_time": "2024-06-25T08:05:45.996186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1668003725711,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "eE0anblvMGJx",
    "outputId": "b5db94b3-faf0-4c64-9717-fa906c4b76db"
   },
   "outputs": [],
   "source": [
    "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "\n",
    "dataset_entry = dataset_train[0]\n",
    "image = cv2.imread(dataset_entry[\"file_name\"])\n",
    "\n",
    "visualizer = Visualizer(\n",
    "    image[:, :, ::-1],\n",
    "    metadata=metadata,\n",
    "    scale=0.5,\n",
    "    instance_mode=ColorMode.IMAGE_BW\n",
    ")\n",
    "\n",
    "out = visualizer.draw_dataset_dict(dataset_entry)\n",
    "cv2.imshow(\"visualize\",out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GavGRHy2M7Hb"
   },
   "source": [
    "## Train Model Using Custom COCO Format Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ3g-l56NMOY"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.228994Z",
     "start_time": "2024-06-25T08:03:04.203266Z"
    },
    "id": "krCm2L_lNC83"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "MAX_ITER = 3000\n",
    "EVAL_PERIOD = 200\n",
    "BASE_LR = 0.0001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# OUTPUT DIRa\n",
    "OUTPUT_DIR_PATH = os.path.join(\n",
    "    DATA_SET_NAME,\n",
    "    ARCHITECTURE,\n",
    "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:04.291051Z",
     "start_time": "2024-06-25T08:03:04.233685Z"
    },
    "id": "lxQU8JrgOD73"
   },
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "# cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "# cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "# cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "# cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "# cfg.SOLVER.BASE_LR = BASE_LR\n",
    "# cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "# cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
    "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 # Default batch size per image\n",
    "\n",
    "# Adjusting batch size and image size for GPU with 6GB VRAM\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # Overall batch size\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)  # Adjusted to fit memory constraints\n",
    "cfg.INPUT.MIN_SIZE_TEST = 800\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1333\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.DATALOADER.NUM_WORKERS = 3\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n",
    "\n",
    "# Save config for future reference\n",
    "with open(os.path.join(OUTPUT_DIR_PATH, \"config.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch-_5aCuXWj9"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:03:15.015389Z",
     "start_time": "2024-06-25T08:03:04.296073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961595,
     "status": "ok",
     "timestamp": 1668005381143,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "7S8y2W2AQvJq",
    "outputId": "36fe2d26-1118-4748-fff1-18a86d873970"
   },
   "outputs": [],
   "source": [
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XMPKQ28GRna"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flInE1L-XTfx"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:30.387236Z",
     "start_time": "2024-06-25T08:07:28.649281Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2265,
     "status": "ok",
     "timestamp": 1668005909534,
     "user": {
      "displayName": "Piotr Skalski",
      "userId": "04309230031174164349"
     },
     "user_tz": -60
    },
    "id": "vsByFDFbQwLi",
    "outputId": "db8479c0-a286-4e83-e064-9ae4ebad3aba"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T08:07:56.682926Z",
     "start_time": "2024-06-25T08:07:33.893951Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "hmAcBbpXX-Rh"
   },
   "outputs": [],
   "source": [
    "dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)\n",
    "\n",
    "for d in dataset_valid:\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "\n",
    "    visualizer = Visualizer(\n",
    "\n",
    "        img[:, :, ::-1],\n",
    "        metadata=metadata,\n",
    "        scale=0.8,\n",
    "        instance_mode=ColorMode.IMAGE_BW\n",
    "    )\n",
    "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(\"validation\",out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)  # Waits for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Closes the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.97\n",
    "      # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Visualize the results\n",
    "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Display the image\n",
    "    result_image = out.get_image()[:, :, ::-1]\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(predictor.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # Display the frame\n",
    "        result_frame = out.get_image()[:, :, ::-1]\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "# config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/config.yaml\"\n",
    "# weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-28-12-40-23/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import numpy as np\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.97  # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def draw_quadrilaterals(image, outputs, deformation_threshold=0.05):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    for mask in masks:\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a quadrilateral\n",
    "            epsilon = deformation_threshold * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Ensure it's a quadrilateral (4 sides)\n",
    "            if len(approx) == 4:\n",
    "                # Draw the quadrilateral\n",
    "                cv2.polylines(image, [approx], True, (0, 255, 0), 2)\n",
    "                \n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image(predictor, image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Draw quadrilaterals and masks on the image\n",
    "    result_image = draw_quadrilaterals_and_masks(image, outputs)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(f'Result for {image_path}', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video(predictor, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        result_frame = draw_quadrilaterals_and_masks(frame, outputs)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow(f'Result for a frame in {video_path}', result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_folder(predictor, folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import numpy as np\n",
    "\n",
    "def load_model(config_file, weights_file):\n",
    "    # Load the configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.WEIGHTS = weights_file\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.95  # Set a custom testing threshold\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def draw_quadrilaterals(image, outputs):\n",
    "    masks = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy()\n",
    "    for mask in masks:\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a quadrilateral\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Calculate the area of the mask and the quadrilateral\n",
    "            mask_area = cv2.contourArea(contour)\n",
    "            quad_area = cv2.contourArea(approx)\n",
    "            \n",
    "            # Check if mask_area is zero (handle edge case)\n",
    "            if mask_area <= 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the percentage of the mask area outside the quadrilateral\n",
    "            outside_area = mask_area - quad_area\n",
    "            outside_percentage = outside_area / mask_area if mask_area > 0 else 0\n",
    "            \n",
    "            # Determine the color of the quadrilateral\n",
    "            color = (0, 255, 0) if outside_percentage <= 0.12 else (0, 0, 255)\n",
    "            \n",
    "            if len(approx) >= 4:\n",
    "                cv2.polylines(image, [approx], True, color, 2)\n",
    "                \n",
    "    return image\n",
    "\n",
    "\n",
    "def process_image(predictor, image_path, output_folder):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Draw quadrilaterals on the image\n",
    "    result_image = draw_quadrilaterals(image, outputs)\n",
    "    \n",
    "    # Save the result image\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "    print(f'Saved result for {image_path} to {output_path}')\n",
    "\n",
    "def process_video(predictor, video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_path = os.path.join(output_folder, os.path.basename(video_path))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        result_frame = draw_quadrilaterals(frame, outputs)\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(result_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f'Saved result for {video_path} to {output_path}')\n",
    "\n",
    "def process_folder(predictor, folder_path, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "                process_image(predictor, file_path, output_folder)\n",
    "            elif file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                process_video(predictor, file_path, output_folder)\n",
    "\n",
    "# Example usage\n",
    "config_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/config.yaml\"\n",
    "weights_file = \"D:/path_detect/tank/mask_rcnn_R_101_FPN_3x/2024-06-25-16-10-19/model_final.pth\"\n",
    "\n",
    "input_folder = \"D:/path_detect/test\"\n",
    "output_folder = \"D:/path_detect/output\"\n",
    "\n",
    "predictor = load_model(config_file, weights_file)\n",
    "process_folder(predictor, input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ramp_edges(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 300, 250, apertureSize=3)\n",
    "\n",
    "    # Create a mask to remove boundary edges\n",
    "    height, width = edges.shape\n",
    "    mask = np.ones_like(edges)\n",
    "    border = 10  # Adjust this value to change the border size\n",
    "    mask[:border, :] = 0\n",
    "    mask[-border:, :] = 0\n",
    "    mask[:, :border] = 0\n",
    "    mask[:, -border:] = 0\n",
    "\n",
    "    # Apply the mask to remove boundary edges\n",
    "    edges = cv2.bitwise_and(edges, edges, mask=mask)\n",
    "\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1.1, np.pi / 180,200)\n",
    "\n",
    "\n",
    "    return lines\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    # Draw the lines on the image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def process_video(video_source=0):\n",
    "    # Open the video source (0 for webcam, or a filename)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect ramp edges\n",
    "        lines = detect_ramp_edges(frame)\n",
    "\n",
    "        # Draw detected lines on the frame\n",
    "        frame_with_lines = draw_lines(frame, lines)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Detected Ramp Edges', frame_with_lines)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('D:/path_detect/video1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ramp_edges(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 100, 200, apertureSize=3)\n",
    "\n",
    "    # Create a mask to remove boundary edges\n",
    "    height, width = edges.shape\n",
    "    mask = np.ones_like(edges)\n",
    "    border = 10  # Adjust this value to change the border size\n",
    "    mask[:border, :] = 0\n",
    "    mask[-border:, :] = 0\n",
    "    mask[:, :border] = 0\n",
    "    mask[:, -border:] = 0\n",
    "\n",
    "    # Apply the mask to remove boundary edges\n",
    "    edges = cv2.bitwise_and(edges, edges, mask=mask)\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1.1, np.pi / 180, 200)\n",
    "\n",
    "    return lines\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    # Draw the lines on the image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def process_video(video_source=0):\n",
    "    # Open the video source (0 for webcam, or a filename)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect ramp edges\n",
    "        lines = detect_ramp_edges(frame)\n",
    "\n",
    "        # Draw detected lines on the frame\n",
    "        frame_with_lines = draw_lines(frame, lines)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Detected Ramp Edges', frame_with_lines)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video()  # Default is the webcam, pass a video file path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1Wkuq4DLHD7MG5HgpEqiytvEjvNK2sYAx",
     "timestamp": 1719261218111
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
